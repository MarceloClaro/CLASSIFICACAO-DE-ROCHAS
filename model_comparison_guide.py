"""
Script de Demonstra√ß√£o: Compara√ß√£o de Modelos
Demonstra an√°lise de efici√™ncia para m√∫ltiplos modelos (ResNet18, ResNet50, DenseNet121)
"""

import streamlit as st
import torch
from performance_analyzer import PerformanceAnalyzer

def create_comparison_section():
    """
    Cria se√ß√£o de compara√ß√£o entre m√∫ltiplos modelos
    """
    st.write("---")
    st.write("## üî¨ Compara√ß√£o entre Modelos")
    st.write("An√°lise comparativa cient√≠fica entre diferentes arquiteturas")
    
    # Explica√ß√£o
    with st.expander("‚ÑπÔ∏è Sobre a Compara√ß√£o de Modelos"):
        st.write("""
        ### Por que comparar modelos?
        
        A escolha do modelo adequado depende de m√∫ltiplos fatores:
        
        1. **Acur√°cia**: Qualidade das predi√ß√µes
        2. **Velocidade**: Tempo de infer√™ncia
        3. **Mem√≥ria**: Recursos computacionais necess√°rios
        4. **Complexidade**: N√∫mero de par√¢metros
        
        ### Modelos Dispon√≠veis:
        
        - **ResNet18**: Mais leve e r√°pido (11M par√¢metros)
        - **ResNet50**: Balanceado (25M par√¢metros)
        - **DenseNet121**: Mais profundo e preciso (8M par√¢metros)
        
        ### M√©tricas de Compara√ß√£o:
        
        - **Trade-off Acur√°cia/Velocidade**: Modelos mais complexos geralmente s√£o mais lentos
        - **Trade-off Acur√°cia/Mem√≥ria**: Modelos maiores precisam de mais recursos
        - **Score de Efici√™ncia**: M√©trica composta que balanceia todos os fatores
        """)
    
    # Tabela comparativa te√≥rica
    st.write("### üìä Compara√ß√£o Te√≥rica")
    
    comparison_data = {
        'Modelo': ['ResNet18', 'ResNet50', 'DenseNet121'],
        'Par√¢metros': ['11.7M', '25.6M', '8.0M'],
        'Camadas': ['18', '50', '121'],
        'Velocidade Esperada': ['‚ö°‚ö°‚ö° R√°pido', '‚ö°‚ö° M√©dio', '‚ö° Lento'],
        'Acur√°cia Esperada': ['‚≠ê‚≠ê Boa', '‚≠ê‚≠ê‚≠ê √ìtima', '‚≠ê‚≠ê‚≠ê √ìtima'],
        'Uso de Mem√≥ria': ['üíæ Baixo', 'üíæüíæ M√©dio', 'üíæ Baixo'],
    }
    
    import pandas as pd
    df_comparison = pd.DataFrame(comparison_data)
    st.table(df_comparison)
    
    # Guia de sele√ß√£o
    st.write("### üéØ Guia de Sele√ß√£o")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("""
        **Use ResNet18 quando:**
        - Prioridade √© velocidade
        - Recursos limitados
        - Aplica√ß√£o em tempo real
        - Dataset pequeno/m√©dio
        """)
    
    with col2:
        st.success("""
        **Use ResNet50 quando:**
        - Balanceamento de qualidade e velocidade
        - Recursos moderados dispon√≠veis
        - Maior acur√°cia necess√°ria
        - Dataset m√©dio/grande
        """)
    
    with col3:
        st.warning("""
        **Use DenseNet121 quando:**
        - M√°xima acur√°cia √© prioridade
        - Efici√™ncia de par√¢metros importante
        - Pode esperar mais tempo
        - Dataset grande e complexo
        """)
    
    # Recomenda√ß√µes baseadas em cen√°rios
    st.write("### üí° Recomenda√ß√µes por Caso de Uso")
    
    scenarios = {
        'üè• Diagn√≥stico M√©dico': {
            'modelo': 'DenseNet121 ou ResNet50',
            'raz√£o': 'Acur√°cia √© cr√≠tica, tempo de infer√™ncia menos relevante'
        },
        'üì± Aplicativo Mobile': {
            'modelo': 'ResNet18',
            'raz√£o': 'Recursos limitados, necessita ser r√°pido e leve'
        },
        'üè≠ Controle de Qualidade Industrial': {
            'modelo': 'ResNet50',
            'raz√£o': 'Balanceamento entre acur√°cia e velocidade para linha de produ√ß√£o'
        },
        'üéì Pesquisa Acad√™mica': {
            'modelo': 'DenseNet121',
            'raz√£o': 'Maximizar m√©tricas para publica√ß√£o Qualis A1'
        },
        '‚òÅÔ∏è Cloud/API': {
            'modelo': 'ResNet50',
            'raz√£o': 'Bom balanceamento com escalabilidade'
        }
    }
    
    for scenario, info in scenarios.items():
        with st.expander(f"{scenario}"):
            st.write(f"**Modelo Recomendado:** {info['modelo']}")
            st.write(f"**Justificativa:** {info['raz√£o']}")
    
    # Exemplo de an√°lise comparativa
    st.write("### üìà Exemplo de An√°lise Comparativa")
    st.write("Ap√≥s treinar modelos, voc√™ ver√° gr√°ficos como:")
    
    st.code("""
    # Exemplo de resultado de compara√ß√£o:
    
    Modelo          Acur√°cia    Tempo (ms)    Mem√≥ria (MB)    Score
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ResNet18        0.925       15.2          45.2            0.852
    ResNet50        0.948       32.7          98.5            0.831
    DenseNet121     0.952       45.8          32.1            0.798
    
    An√°lise:
    - ResNet50 tem melhor balanceamento geral
    - ResNet18 √© o mais r√°pido
    - DenseNet121 tem melhor acur√°cia mas √© mais lento
    """, language='text')
    
    # Dicas para otimiza√ß√£o
    st.write("### ‚öôÔ∏è Dicas de Otimiza√ß√£o")
    
    tips = [
        "Use **Fine-Tuning** apenas quando necess√°rio (aumenta tempo mas melhora acur√°cia)",
        "Ajuste o **batch size** conforme mem√≥ria dispon√≠vel (maior = mais r√°pido)",
        "Considere **quantiza√ß√£o** para deployment em produ√ß√£o",
        "Use **early stopping** para evitar treinar desnecessariamente",
        "Teste com **dados aumentados** para melhorar generaliza√ß√£o"
    ]
    
    for i, tip in enumerate(tips, 1):
        st.write(f"{i}. {tip}")

def create_metrics_explanation():
    """
    Cria se√ß√£o explicativa sobre as m√©tricas
    """
    st.write("---")
    st.write("## üìö Entendendo as M√©tricas")
    
    with st.expander("üéØ M√©tricas de Classifica√ß√£o"):
        st.write("""
        ### Acur√°cia (Accuracy)
        Percentual de predi√ß√µes corretas sobre o total.
        
        `Acur√°cia = (TP + TN) / (TP + TN + FP + FN)`
        
        **Quando usar**: Bom para datasets balanceados
        **Limita√ß√£o**: Pode ser enganosa em datasets desbalanceados
        
        ---
        
        ### Precis√£o (Precision)
        Das amostras preditas como positivas, quantas realmente s√£o?
        
        `Precis√£o = TP / (TP + FP)`
        
        **Quando usar**: Quando custo de falso positivo √© alto
        **Exemplo**: Spam detection (n√£o queremos marcar emails leg√≠timos como spam)
        
        ---
        
        ### Recall (Sensibilidade)
        Das amostras realmente positivas, quantas foram identificadas?
        
        `Recall = TP / (TP + FN)`
        
        **Quando usar**: Quando custo de falso negativo √© alto
        **Exemplo**: Diagn√≥stico m√©dico (n√£o queremos perder casos de doen√ßa)
        
        ---
        
        ### F1-Score
        M√©dia harm√¥nica entre Precis√£o e Recall.
        
        `F1 = 2 * (Precis√£o * Recall) / (Precis√£o + Recall)`
        
        **Quando usar**: Quando precis√£o e recall s√£o igualmente importantes
        **Vantagem**: Balanceia ambas as m√©tricas
        
        ---
        
        ### AUC-ROC
        √Årea sob a curva ROC (Receiver Operating Characteristic).
        
        **Interpreta√ß√£o**:
        - 0.5: Classificador aleat√≥rio
        - 0.7-0.8: Razo√°vel
        - 0.8-0.9: Bom
        - > 0.9: Excelente
        
        **Vantagem**: Independente do threshold escolhido
        """)
    
    with st.expander("‚ö° M√©tricas de Efici√™ncia"):
        st.write("""
        ### Tempo de Infer√™ncia
        Tempo necess√°rio para processar uma amostra.
        
        **Medido em**: Milissegundos (ms)
        **Objetivo**: Menor √© melhor
        
        **Benchmarks**:
        - < 10ms: Excelente (tempo real)
        - 10-50ms: Bom (aplica√ß√µes interativas)
        - 50-200ms: Aceit√°vel (batch processing)
        - > 200ms: Lento (otimiza√ß√£o recomendada)
        
        ---
        
        ### Throughput
        N√∫mero de amostras processadas por segundo.
        
        **Medido em**: Amostras/segundo
        **Objetivo**: Maior √© melhor
        
        **C√°lculo**: `Throughput = 1 / Tempo_Infer√™ncia`
        
        ---
        
        ### Uso de Mem√≥ria
        Recursos de mem√≥ria necess√°rios.
        
        **Componentes**:
        - **Modelo**: Par√¢metros e buffers
        - **Sistema**: RAM total usada
        - **GPU**: VRAM quando dispon√≠vel
        
        **Otimiza√ß√£o**:
        - Quantiza√ß√£o (reduz precis√£o)
        - Pruning (remove pesos pequenos)
        - Knowledge distillation (modelo menor)
        """)
    
    with st.expander("üèÜ Score de Efici√™ncia"):
        st.write("""
        ### Score Composto
        M√©trica √∫nica que combina m√∫ltiplos aspectos:
        
        `Score = 0.5 * Acur√°cia + 0.3 * Efici√™ncia_Tempo + 0.2 * Efici√™ncia_Mem√≥ria`
        
        ### Pesos Justificados:
        - **50% Acur√°cia**: Principal objetivo do modelo
        - **30% Tempo**: Importante para experi√™ncia do usu√°rio
        - **20% Mem√≥ria**: Relevante para deployment
        
        ### Interpreta√ß√£o:
        - **‚â• 0.80**: ü•á Excelente - Public√°vel em Qualis A1
        - **0.60-0.79**: ü•à Bom - Aceit√°vel para maioria das aplica√ß√µes
        - **< 0.60**: ü•â Requer otimiza√ß√£o
        
        ### Ajustando Pesos:
        Voc√™ pode modificar os pesos conforme sua aplica√ß√£o:
        - Tempo real: Aumentar peso do tempo
        - Edge computing: Aumentar peso da mem√≥ria
        - Pesquisa: Focar apenas em acur√°cia
        """)

if __name__ == "__main__":
    st.set_page_config(page_title="Compara√ß√£o de Modelos", page_icon="üî¨", layout="wide")
    
    st.title("üî¨ Guia de Compara√ß√£o e An√°lise de Modelos")
    st.write("Documenta√ß√£o completa para an√°lise cient√≠fica de qualidade Qualis A1")
    
    create_comparison_section()
    create_metrics_explanation()
    
    st.write("---")
    st.success("""
    üí° **Dica**: Para uma an√°lise completa, treine m√∫ltiplos modelos com os mesmos dados
    e compare os resultados usando as m√©tricas apresentadas neste guia.
    """)
