# Vision Transformer e Melhorias AvanÃ§adas - DocumentaÃ§Ã£o Completa

## ğŸ¯ VisÃ£o Geral

Este documento descreve todas as melhorias implementadas no sistema de classificaÃ§Ã£o de imagens, focando em:
1. **AdiÃ§Ã£o de Vision Transformers** (ViT e Swin)
2. **Reinforcement Learning** para ajuste dinÃ¢mico
3. **Agentes CrewAI** para pesquisa inteligente
4. **TÃ©cnicas avanÃ§adas de regularizaÃ§Ã£o**

---

## ğŸ¤– Novos Modelos: Vision Transformers

### Por que Vision Transformers?

Os modelos CNN tradicionais (ResNet, DenseNet) usam convoluÃ§Ãµes que capturam padrÃµes **locais**. Vision Transformers usam mecanismos de **atenÃ§Ã£o** para capturar relaÃ§Ãµes **globais** na imagem, o que pode resultar em melhor desempenho, especialmente para:
- Imagens com padrÃµes complexos e distribuÃ­dos
- Datasets onde contexto global Ã© importante
- Tarefas que requerem entendimento de relaÃ§Ãµes entre regiÃµes distantes

### Modelos DisponÃ­veis

#### 1. **ViT-B/16** (torchvision)
- **Arquitetura**: Vision Transformer Base, patches 16x16
- **ParÃ¢metros**: ~86M
- **Uso**: Boa performance geral, versÃ£o oficial do PyTorch
- **RecomendaÃ§Ã£o**: Dataset mÃ©dio a grande (>1000 imagens)

#### 2. **ViT-B/32** (torchvision)
- **Arquitetura**: Vision Transformer Base, patches 32x32
- **ParÃ¢metros**: ~88M
- **Uso**: Mais rÃ¡pido que ViT-B/16, menos preciso
- **RecomendaÃ§Ã£o**: Quando velocidade Ã© prioridade

#### 3. **ViT-L/16** (torchvision)
- **Arquitetura**: Vision Transformer Large, patches 16x16
- **ParÃ¢metros**: ~307M
- **Uso**: MÃ¡xima precisÃ£o, requer muita memÃ³ria GPU
- **RecomendaÃ§Ã£o**: Dataset grande (>5000 imagens), GPU potente

#### 4. **ViT-B/16-timm** (timm - NOVO! ğŸ†•)
- **Arquitetura**: Vision Transformer Base da biblioteca timm
- **ParÃ¢metros**: ~86M
- **Uso**: **VersÃ£o mais robusta e melhor treinada que torchvision**
- **Vantagem**: PrÃ©-treinamento superior, melhor generalizaÃ§Ã£o
- **RecomendaÃ§Ã£o**: **PRIMEIRA ESCOLHA para ViT Base**

#### 5. **ViT-L/16-timm** (timm - NOVO! ğŸ†•)
- **Arquitetura**: Vision Transformer Large da biblioteca timm
- **ParÃ¢metros**: ~307M
- **Uso**: **VersÃ£o melhorada do ViT Large**
- **Vantagem**: Melhor desempenho que versÃ£o torchvision
- **RecomendaÃ§Ã£o**: Para mÃ¡xima precisÃ£o com dataset grande

#### 6. **Swin-T** (Swin Transformer Tiny - NOVO! ğŸ†•)
- **Arquitetura**: Swin Transformer com arquitetura hierÃ¡rquica
- **ParÃ¢metros**: ~28M
- **Uso**: **Melhor eficiÃªncia que ViT, performance superior em muitos casos**
- **Vantagem**: AtenÃ§Ã£o em janelas (window-based), computacionalmente eficiente
- **RecomendaÃ§Ã£o**: **EXCELENTE ESCOLHA para datasets mÃ©dios**

#### 7. **Swin-B** (Swin Transformer Base - NOVO! ğŸ†•)
- **Arquitetura**: Swin Transformer Base
- **ParÃ¢metros**: ~88M
- **Uso**: **State-of-the-art performance, arquitetura hierÃ¡rquica**
- **Vantagem**: Melhor que ViT-B em muitos benchmarks
- **RecomendaÃ§Ã£o**: **PRIMEIRA ESCOLHA para mÃ¡xima performance**

### ComparaÃ§Ã£o: CNN vs Vision Transformer

| CaracterÃ­stica | CNN (ResNet, DenseNet) | Vision Transformer (ViT, Swin) |
|----------------|------------------------|--------------------------------|
| **PadrÃµes** | Locais e hierÃ¡rquicos | Globais e relaÃ§Ãµes de longo alcance |
| **Inductive Bias** | Forte (convoluÃ§Ãµes) | Fraco (atenÃ§Ã£o) |
| **Dados NecessÃ¡rios** | Menor (500+ imagens) | Maior (1000+ imagens) |
| **MemÃ³ria GPU** | Menor | Maior |
| **Velocidade** | Mais rÃ¡pido | Mais lento |
| **Performance** | Boa | Potencialmente melhor com dados suficientes |
| **Robustez a OclusÃ£o** | Boa | Excelente (atenÃ§Ã£o global) |

---

## ğŸ¯ Reinforcement Learning para Ajuste DinÃ¢mico

### O que Ã©?

Um sistema de **Q-Learning** que ajusta automaticamente a **learning rate** durante o treinamento baseado no desempenho de validaÃ§Ã£o.

### Como Funciona?

1. **Estado**: Definido por tendÃªncias de perda e acurÃ¡cia
   - `improving_improving`: Perda e acurÃ¡cia melhorando
   - `improving_degrading`: Perda melhorando, acurÃ¡cia piorando
   - `degrading_improving`: Perda piorando, acurÃ¡cia melhorando
   - `degrading_degrading`: Ambos piorando

2. **AÃ§Ãµes**: 3 possÃ­veis aÃ§Ãµes
   - `increase_lr`: Aumenta LR em 20%
   - `decrease_lr`: Diminui LR em 20%
   - `keep_lr`: MantÃ©m LR atual

3. **Recompensa**: Calculada baseada em melhoria de desempenho
   ```python
   reward = (prev_loss - current_loss) * 10 + (current_acc - prev_acc) * 100
   ```

4. **Q-Learning**: Atualiza Q-values para aprender polÃ­tica Ã³tima
   ```python
   Q(s,a) â† Q(s,a) + Î±[r + Î³Â·max(Q(s',a')) - Q(s,a)]
   ```

### Vantagens

- âœ… **Adaptativo**: Ajusta LR automaticamente sem intervenÃ§Ã£o manual
- âœ… **Inteligente**: Aprende a melhor estratÃ©gia durante o treinamento
- âœ… **Robusto**: Pode recuperar de platÃ´s de treinamento
- âœ… **Transparente**: Mostra aÃ§Ãµes e recompensas em tempo real

### Quando Usar?

- ğŸ¯ Datasets desafiadores onde LR fixo nÃ£o funciona bem
- ğŸ¯ Treinamentos longos (>20 Ã©pocas)
- ğŸ¯ Quando vocÃª nÃ£o tem certeza da melhor LR
- âš ï¸ **NÃƒO usar** com OneCycleLR (conflito de estratÃ©gias)

### Exemplo de Output

```
Ã‰poca 10/50
Perda de Treino: 0.4521 | AcurÃ¡cia de Treino: 0.8234
Perda de ValidaÃ§Ã£o: 0.4892 | AcurÃ¡cia de ValidaÃ§Ã£o: 0.8156
ğŸ¯ RL Action: decrease_lr | New LR: 0.000080 | Reward: 0.1245
```

---

## ğŸ¤– Agente CrewAI para Pesquisa Inteligente

### O que Ã©?

Um **agente inteligente** que pesquisa na web as melhores estratÃ©gias de treinamento para seu modelo e tipo de dataset.

### Como Funciona?

1. **Agente ML Researcher**: Especialista em otimizaÃ§Ã£o de deep learning
2. **Pesquisa Web**: Busca papers, artigos e best practices
3. **RecomendaÃ§Ãµes**: Fornece insights sobre:
   - Learning rate Ã³tima
   - Melhores tÃ©cnicas de augmentation
   - Batch size recomendado
   - Scheduler mais adequado
   - Armadilhas comuns a evitar

### ConfiguraÃ§Ã£o

âš ï¸ **Requer API Keys** (opcional):
- OpenAI API Key para o agente
- Serper API Key para busca web

### Vantagens

- ğŸ“š Acesso a conhecimento atualizado
- ğŸ“ RecomendaÃ§Ãµes baseadas em pesquisa cientÃ­fica
- ğŸ’¡ Insights que vocÃª pode nÃ£o conhecer
- ğŸš€ Acelera experimentaÃ§Ã£o

### Quando Usar?

- ğŸ†• Novo tipo de dataset que vocÃª nunca trabalhou
- ğŸ¯ Quer maximizar performance
- ğŸ“– Quer aprender melhores prÃ¡ticas
- âš ï¸ **EXPERIMENTAL** - ainda em desenvolvimento

---

## âœ¨ Label Smoothing

### O que Ã©?

TÃ©cnica que **suaviza** os rÃ³tulos para prevenir **overconfidence** do modelo.

### Como Funciona?

Em vez de usar rÃ³tulos one-hot (0, 1), usa distribuiÃ§Ã£o suavizada:
```
Original: [0, 1, 0, 0]  (100% confiante)
Suavizado: [0.025, 0.925, 0.025, 0.025]  (92.5% confiante)
```

### FÃ³rmula

```
y_smooth = (1 - Îµ) * y_true + Îµ / K
```
Onde:
- Îµ = smoothing factor (geralmente 0.1)
- K = nÃºmero de classes

### Vantagens

- âœ… **Melhora GeneralizaÃ§Ã£o**: Modelo menos overconfident
- âœ… **Reduz Overfitting**: Especialmente com poucos dados
- âœ… **Essencial para ViT**: Vision Transformers beneficiam muito
- âœ… **CalibraÃ§Ã£o**: Probabilidades mais calibradas

### Valores Recomendados

| Dataset | Smoothing |
|---------|-----------|
| Pequeno (<500) | 0.15-0.2 |
| MÃ©dio (500-2000) | 0.1-0.15 |
| Grande (>2000) | 0.05-0.1 |
| Vision Transformer | 0.1-0.2 |
| CNN | 0.05-0.1 |

---

## ğŸ“Š Exponential Moving Average (EMA)

### O que Ã©?

MantÃ©m uma **mÃ©dia mÃ³vel exponencial** dos pesos do modelo durante o treinamento.

### Como Funciona?

```python
shadow_weight = decay * shadow_weight + (1 - decay) * current_weight
```

A cada passo de otimizaÃ§Ã£o, os pesos "shadow" sÃ£o atualizados suavemente. No final do treinamento, usamos os pesos EMA em vez dos pesos finais.

### Vantagens

- âœ… **Estabilidade**: Pesos finais mais estÃ¡veis
- âœ… **GeneralizaÃ§Ã£o**: Geralmente melhor performance no teste
- âœ… **Robustez**: Menos sensÃ­vel a flutuaÃ§Ãµes de treinamento
- âœ… **State-of-the-art**: Usado em modelos SOTA

### ParÃ¢metros

- **Decay**: 0.999 (padrÃ£o)
  - Maior = mais suavizaÃ§Ã£o
  - Menor = mais reativo

### Quando Usar?

- âœ… **SEMPRE** - especialmente com ViT
- âœ… Treinamentos longos
- âœ… Learning rates altas
- âœ… Quando busca mÃ¡xima performance

---

## âš¡ Gradient Clipping

### O que Ã©?

Limita a **norma dos gradientes** para prevenir **exploding gradients**.

### Como Funciona?

```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

Se a norma dos gradientes exceder 1.0, eles sÃ£o escalonados proporcionalmente.

### Por que Ã© Importante?

- **Vision Transformers**: Especialmente sensÃ­veis a gradientes explosivos
- **Estabilidade**: Treinamento mais estÃ¡vel
- **ConvergÃªncia**: Melhor convergÃªncia em modelos grandes

### Vantagens

- âœ… **Essencial para ViT**: Quase obrigatÃ³rio
- âœ… **Estabilidade**: Previne NaN e divergÃªncia
- âœ… **Sem custo**: Overhead computacional mÃ­nimo
- âœ… **Best Practice**: Usado em todos os modelos modernos

### Quando Usar?

- âœ… **SEMPRE com Vision Transformers**
- âœ… Modelos grandes (>50M parÃ¢metros)
- âœ… Learning rates altas
- âœ… Training instÃ¡vel

---

## ğŸ¨ Melhorias em Data Augmentation (app5.py)

### TransformaÃ§Ãµes Aprimoradas

#### Antes (Standard Simples)
```python
RandomApply([
    RandomHorizontalFlip(),
    RandomRotation(90),
    ColorJitter(0.2, 0.2, 0.2, 0.1),
    ...
], p=0.5)
```

#### Depois (Standard Robusto)
```python
RandomHorizontalFlip(p=0.5)
RandomVerticalFlip(p=0.2)
RandomRotation(degrees=30)
ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15)
RandomResizedCrop(224, scale=(0.7, 1.0))
RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1))
GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))  # NOVO
RandomErasing(p=0.2, scale=(0.02, 0.15))  # NOVO
```

### Novas TransformaÃ§Ãµes

1. **GaussianBlur**: Simula variaÃ§Ãµes de foco
2. **RandomErasing**: Simula oclusÃµes parciais
3. **ParÃ¢metros Mais Agressivos**: Maior variabilidade

### Vantagens

- âœ… **Mais Robustez**: Modelo lida melhor com variaÃ§Ãµes
- âœ… **Menos Overfitting**: Mais diversidade de dados
- âœ… **Melhor GeneralizaÃ§Ã£o**: Performance em imagens reais

---

## ğŸ“‹ Guia de Uso PrÃ¡tico

### CenÃ¡rio 1: Dataset Pequeno (<500 imagens)

**RecomendaÃ§Ãµes:**
- **Modelo**: DenseNet121 ou Swin-T
- **Augmentation**: mixup ou cutmix
- **Label Smoothing**: 0.15-0.2
- **EMA**: âœ… Ativado
- **Gradient Clipping**: âœ… Ativado
- **RL**: âš ï¸ Opcional
- **Learning Rate**: 0.0001
- **Batch Size**: 8-16
- **Epochs**: 100-200

### CenÃ¡rio 2: Dataset MÃ©dio (500-2000 imagens)

**RecomendaÃ§Ãµes:**
- **Modelo**: ResNet50 ou Swin-T
- **Augmentation**: standard
- **Label Smoothing**: 0.1
- **EMA**: âœ… Ativado
- **Gradient Clipping**: âœ… Ativado
- **RL**: âœ… Ativado
- **Learning Rate**: 0.0001
- **Batch Size**: 16-32
- **Epochs**: 50-100

### CenÃ¡rio 3: Dataset Grande (>2000 imagens) com GPU Potente

**RecomendaÃ§Ãµes:**
- **Modelo**: ViT-B/16-timm ou Swin-B
- **Augmentation**: standard
- **Label Smoothing**: 0.1
- **EMA**: âœ… Ativado
- **Gradient Clipping**: âœ… Ativado
- **RL**: âœ… Ativado
- **Scheduler**: OneCycleLR
- **Learning Rate**: 0.0001
- **Batch Size**: 32-64
- **Epochs**: 30-50

### CenÃ¡rio 4: MÃ¡xima Performance (CompetiÃ§Ã£o)

**RecomendaÃ§Ãµes:**
- **Modelo**: Ensemble de Swin-B + ViT-L/16-timm
- **Augmentation**: mixup + cutmix alternado
- **Label Smoothing**: 0.1
- **EMA**: âœ… Ativado (decay=0.9999)
- **Gradient Clipping**: âœ… Ativado
- **RL**: âœ… Ativado
- **Scheduler**: CosineAnnealingLR com warmup
- **Fine-tuning**: âœ… Completo
- **Learning Rate**: 0.00005
- **Batch Size**: MÃ¡ximo possÃ­vel
- **Epochs**: 100+
- **TTA**: Test-Time Augmentation na inferÃªncia

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Problema: Out of Memory (OOM)

**SoluÃ§Ãµes:**
1. Reduzir batch size (16 â†’ 8 â†’ 4)
2. Usar modelo menor (ViT-L â†’ ViT-B â†’ Swin-T)
3. Usar gradient accumulation (nÃ£o implementado ainda)
4. Reduzir resoluÃ§Ã£o de imagem

### Problema: Treinamento InstÃ¡vel (Loss = NaN)

**SoluÃ§Ãµes:**
1. âœ… Ativar Gradient Clipping
2. Reduzir learning rate (0.001 â†’ 0.0001)
3. Aumentar warmup steps
4. Verificar dados (valores invÃ¡lidos, dimensÃµes)

### Problema: Overfitting Severo

**SoluÃ§Ãµes:**
1. Aumentar label smoothing (0.1 â†’ 0.15)
2. Usar mixup ou cutmix
3. Aumentar L2 regularization
4. Aumentar dropout
5. Mais data augmentation
6. Early stopping mais agressivo

### Problema: Underfitting

**SoluÃ§Ãµes:**
1. Modelo maior (ResNet18 â†’ ResNet50 â†’ ViT)
2. Mais Ã©pocas
3. Learning rate maior
4. Menos regularizaÃ§Ã£o
5. Fine-tuning completo

### Problema: ConvergÃªncia Lenta

**SoluÃ§Ãµes:**
1. âœ… Ativar RL para ajuste dinÃ¢mico
2. Usar OneCycleLR scheduler
3. Aumentar learning rate inicial
4. Verificar gradient flow
5. Usar otimizador AdamW

---

## ğŸ“š ReferÃªncias CientÃ­ficas

### Vision Transformers
- Dosovitskiy et al. (2021). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
- Liu et al. (2021). "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"
- Touvron et al. (2021). "Training data-efficient image transformers"

### Label Smoothing
- Szegedy et al. (2016). "Rethinking the Inception Architecture for Computer Vision"
- MÃ¼ller et al. (2019). "When Does Label Smoothing Help?"

### EMA
- Polyak & Juditsky (1992). "Acceleration of Stochastic Approximation by Averaging"
- Tarvainen & Valpola (2017). "Mean teachers are better role models"

### Reinforcement Learning for Hyperparameters
- Li et al. (2017). "Learning to Optimize"
- Baker et al. (2017). "Designing Neural Network Architectures using Reinforcement Learning"

---

## ğŸš€ PrÃ³ximas Melhorias Planejadas

### Fase 5: MÃ©tricas AvanÃ§adas
- [ ] Expected Calibration Error (ECE)
- [ ] Maximum Calibration Error (MCE)
- [ ] Ensemble predictions
- [ ] Per-class anÃ¡lise detalhada

### Fase 6: Augmentation AvanÃ§ado
- [ ] RandAugment
- [ ] TrivialAugment
- [ ] AutoAugment
- [ ] Test-Time Augmentation (TTA)

### Fase 7: EficiÃªncia
- [ ] Gradient Accumulation
- [ ] Mixed Precision Training (FP16)
- [ ] Model pruning
- [ ] Knowledge distillation

### Fase 8: Scheduler AvanÃ§ado
- [ ] Warmup para todos os schedulers
- [ ] Polynomial decay
- [ ] Plateau-based adjustment
- [ ] Cyclical learning rates

---

## âœ… Como Testar as Melhorias

### Experimento Baseline
1. Treinar ResNet50 sem melhorias
2. ConfiguraÃ§Ã£o: standard augmentation, sem label smoothing, sem EMA
3. Registrar: acurÃ¡cia final, loss, tempo

### Experimento com Melhorias
1. Treinar ResNet50 com todas as melhorias
2. ConfiguraÃ§Ã£o: standard augmentation, label smoothing=0.1, EMA ativado, gradient clipping
3. Comparar com baseline

### Experimento Vision Transformer
1. Treinar Swin-T com melhorias
2. Comparar com ResNet50 baseline
3. Avaliar se ViT melhora resultados

### MÃ©tricas de ComparaÃ§Ã£o
- **AcurÃ¡cia**: Final test accuracy
- **ConvergÃªncia**: Ã‰pocas para atingir 90% de acurÃ¡cia
- **Estabilidade**: VariÃ¢ncia da loss nas Ãºltimas 10 Ã©pocas
- **CalibraÃ§Ã£o**: DiferenÃ§a entre confianÃ§a e acurÃ¡cia

---

## ğŸ’¡ Dicas e Best Practices

### âœ… DO (FaÃ§a)
- Sempre use Gradient Clipping com ViT
- Sempre use EMA - quase sem custo, grande benefÃ­cio
- Use Label Smoothing para melhorar generalizaÃ§Ã£o
- Experimente RL em treinamentos longos
- Use Swin Transformers em vez de ViT quando possÃ­vel
- Monitore overfitting com grÃ¡ficos train/val
- Salve mÃºltiplos checkpoints

### âŒ DON'T (NÃ£o FaÃ§a)
- NÃ£o use RL + OneCycleLR juntos
- NÃ£o use ViT em datasets muito pequenos (<500)
- NÃ£o ignore warnings de OOM - ajuste batch size
- NÃ£o use Label Smoothing > 0.3
- NÃ£o desative Gradient Clipping com ViT
- NÃ£o use fine-tuning sem dados suficientes

---

## ğŸ“ Suporte e Contato

**Projeto Geomaker + IA**
- Email: marceloclaro@gmail.com
- WhatsApp: (88) 981587145
- Instagram: [@marceloclaro.geomaker](https://www.instagram.com/marceloclaro.geomaker/)
- DOI: https://doi.org/10.5281/zenodo.13910277

---

**Ãšltima atualizaÃ§Ã£o**: 2024  
**VersÃ£o**: 5.0 (com Vision Transformers, RL, CrewAI, EMA, Label Smoothing)  

> "The best way to predict the future is to invent it." - Alan Kay
