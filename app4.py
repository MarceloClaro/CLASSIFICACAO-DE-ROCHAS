import os

# Disable CrewAI telemetry to avoid signal handler errors in non-main threads (Streamlit)
os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'

import zipfile
import shutil
import tempfile
import random
import time
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image, ImageEnhance
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms, models, datasets
from sklearn.cluster import AgglomerativeClustering, KMeans
from sklearn.metrics import (adjusted_rand_score, normalized_mutual_info_score,
                             confusion_matrix, classification_report,
                             roc_auc_score, roc_curve)
from sklearn.preprocessing import label_binarize
from sklearn.decomposition import PCA
import streamlit as st
import gc
import logging
import base64
import io
# Importa√ß√µes adicionais para Grad-CAM
from torchcam.methods import SmoothGradCAMpp, GradCAM, GradCAMpp, LayerCAM
from torchvision.transforms.functional import normalize, resize, to_pil_image
import cv2
# Importar otimizadores avan√ßados
try:
    import torch_optimizer as optim_advanced
    ADVANCED_OPTIMIZERS_AVAILABLE = True
except ImportError:
    ADVANCED_OPTIMIZERS_AVAILABLE = False

# Importar timm para Vision Transformers
try:
    import timm
    TIMM_AVAILABLE = True
except ImportError:
    TIMM_AVAILABLE = False

# Importar CrewAI para agentes inteligentes
try:
    from crewai import Agent, Task, Crew, Process
    from crewai_tools import WebsiteSearchTool, SerperDevTool
    from langchain.llms import OpenAI
    CREWAI_AVAILABLE = True
except ImportError:
    CREWAI_AVAILABLE = False

# Importar APIs com suporte de vis√£o
try:
    # Prioritize stable google-generativeai package (recommended)
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
    GEMINI_NEW_API = False  # Stable google-generativeai package
except ImportError:
    # Fallback to new beta package if stable not available
    try:
        import google.genai as genai
        GEMINI_AVAILABLE = True
        GEMINI_NEW_API = True  # Beta google-genai package
    except ImportError:
        GEMINI_AVAILABLE = False
        GEMINI_NEW_API = False

try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False

# Import multi-agent system
try:
    from multi_agent_system import ManagerAgent
    MULTI_AGENT_AVAILABLE = True
except ImportError:
    MULTI_AGENT_AVAILABLE = False

# Import new advanced modules from app5
try:
    import sys
    # Force module reload to avoid Streamlit caching issues
    # Note: This is necessary because Streamlit's module system can cache imports
    # incorrectly, leading to KeyError exceptions. This is different from function
    # caching and cannot be solved with @st.cache decorators.
    if 'visualization_3d' in sys.modules:
        del sys.modules['visualization_3d']
    from visualization_3d import visualize_pca_3d, visualize_activation_heatmap_3d, create_interactive_3d_visualization
    VISUALIZATION_3D_AVAILABLE = True
except (ImportError, KeyError, ModuleNotFoundError) as e:
    VISUALIZATION_3D_AVAILABLE = False
    # print(f"Warning: visualization_3d not available: {e}")

try:
    # Force module reload to avoid Streamlit caching issues
    if 'ai_chat_module' in sys.modules:
        del sys.modules['ai_chat_module']
    from ai_chat_module import AIAnalyzer, describe_gradcam_regions, get_gemini_model_path
    AI_CHAT_AVAILABLE = True
except (ImportError, KeyError, ModuleNotFoundError) as e:
    AI_CHAT_AVAILABLE = False
    # print(f"Warning: ai_chat_module not available: {e}")
    # Define fallback function if module not available
    def get_gemini_model_path(model_name: str, use_new_api: bool = False) -> str:
        """Fallback: Get the correct model path for Gemini API calls."""
        clean_name = model_name.replace('models/', '')
        if use_new_api:
            return f'models/{clean_name}'
        else:
            return clean_name

try:
    # Force module reload to avoid Streamlit caching issues
    if 'academic_references' in sys.modules:
        del sys.modules['academic_references']
    from academic_references import AcademicReferenceFetcher, format_references_for_display
    ACADEMIC_REF_AVAILABLE = True
except (ImportError, KeyError, ModuleNotFoundError) as e:
    ACADEMIC_REF_AVAILABLE = False
    # print(f"Warning: academic_references not available: {e}")

try:
    from genetic_interpreter import GeneticDiagnosticInterpreter
    GENETIC_INTERP_AVAILABLE = True
except ImportError:
    GENETIC_INTERP_AVAILABLE = False

# Constants
CONVERGENCE_CHECK_EPOCHS = 5  # Number of recent epochs to check for convergence stability

# Valid model lists (based on official Google Gemini Cookbook)
# Reference: https://github.com/google-gemini/cookbook
VALID_GEMINI_MODELS = [
    'gemini-2.5-flash',  # ‚≠ê Recommended - fast and efficient with multimodal support
    'gemini-2.5-flash-lite',  # Even faster version
    'gemini-2.5-pro',  # Advanced model with thinking capabilities
    'gemini-3-flash-preview',  # Preview of next generation
    'gemini-3-pro-preview',  # Advanced preview
    # Legacy models (for backwards compatibility, but not recommended)
    'gemini-1.5-pro-latest',
    'gemini-1.5-flash-latest',
    'gemini-1.0-pro-latest',
    'gemini-pro',
    'gemini-1.0-pro-vision-latest'
]

VALID_GROQ_MODELS = [
    'meta-llama/llama-4-scout-17b-16e-instruct',
    'meta-llama/llama-4-maverick-17b-128e-instruct',
    'mixtral-8x7b-32768',
    'llama-3.1-70b-versatile',
    'llama-3.1-8b-instant'
]

def validate_model_name(model_name, provider):
    """
    Validate and sanitize model name to ensure deprecated models are not used.
    Based on official Google Gemini Cookbook: https://github.com/google-gemini/cookbook
    
    Args:
        model_name: The model name from session state or user input
        provider: The AI provider ('Gemini', 'gemini', 'Groq', 'groq')
    
    Returns:
        str: Valid model name or default model for the provider
    """
    if not model_name:
        # Return default model if none specified
        # Normalize provider to lowercase for comparison
        provider_lower = provider.lower() if provider else ''
        return 'gemini-2.5-flash' if provider_lower == 'gemini' else 'mixtral-8x7b-32768'
    
    # Normalize provider to lowercase for case-insensitive comparison
    provider_lower = provider.lower() if provider else ''
    
    # Check if model is in valid list
    if provider_lower == 'gemini':
        if model_name in VALID_GEMINI_MODELS:
            return model_name
        else:
            # Model is deprecated or invalid, return recommended default
            return 'gemini-2.5-flash'
    elif provider_lower == 'groq':
        if model_name in VALID_GROQ_MODELS:
            return model_name
        else:
            # Model is invalid, return default
            return 'mixtral-8x7b-32768'
    else:
        # Unknown provider, return the model as-is
        return model_name

# Definir o dispositivo (CPU ou GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Configura√ß√µes para tornar os gr√°ficos mais bonitos
sns.set_style('whitegrid')

def set_seed(seed):
    """
    Define a seed para garantir a reprodutibilidade.
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)  # Definir a seed para reprodutibilidade

# ImageNet normalization values
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

def denormalize_image(tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD):
    """
    Denormaliza um tensor de imagem normalizado com valores ImageNet.
    
    Args:
        tensor: Tensor de imagem (C, H, W) ou array numpy (H, W, C)
        mean: M√©dia usada na normaliza√ß√£o
        std: Desvio padr√£o usado na normaliza√ß√£o
    
    Returns:
        Array numpy (H, W, C) com valores no intervalo [0, 1]
    """
    if isinstance(tensor, torch.Tensor):
        # Convert tensor to numpy
        image = tensor.permute(1, 2, 0).cpu().numpy()
    else:
        image = tensor
    
    # Denormalize
    mean = np.array(mean)
    std = np.array(std)
    image = std * image + mean
    
    # Clip to valid range
    image = np.clip(image, 0, 1)
    
    return image

# ==================== STATISTICAL ANALYSIS MODULE ====================

class StatisticalAnalyzer:
    """
    Classe para an√°lise estat√≠stica avan√ßada de predi√ß√µes do modelo.
    Inclui intervalos de confian√ßa, testes de signific√¢ncia, bootstrap, etc.
    """
    
    @staticmethod
    def calculate_confidence_interval(probabilities, confidence_level=0.95):
        """
        Calcula intervalos de confian√ßa para as probabilidades usando m√©todo normal.
        
        Args:
            probabilities: Array de probabilidades
            confidence_level: N√≠vel de confian√ßa (padr√£o 0.95 para 95%)
        
        Returns:
            Dict com intervalo inferior e superior
        """
        from scipy import stats
        
        mean = np.mean(probabilities)
        std_error = stats.sem(probabilities)
        margin_error = std_error * stats.t.ppf((1 + confidence_level) / 2, len(probabilities) - 1)
        
        return {
            'mean': mean,
            'lower': max(0, mean - margin_error),
            'upper': min(1, mean + margin_error),
            'margin_error': margin_error
        }
    
    @staticmethod
    def bootstrap_validation(model, image_tensor, n_iterations=100, dropout_rate=0.1):
        """
        Realiza valida√ß√£o bootstrap atrav√©s de m√∫ltiplas predi√ß√µes com dropout.
        
        Args:
            model: Modelo treinado
            image_tensor: Tensor da imagem
            n_iterations: N√∫mero de itera√ß√µes bootstrap
            dropout_rate: Taxa de dropout para varia√ß√£o
        
        Returns:
            Dict com estat√≠sticas bootstrap
        """
        model.train()  # Ativa dropout
        predictions = []
        probabilities_per_class = []
        
        with torch.no_grad():
            for _ in range(n_iterations):
                output = model(image_tensor)
                probs = torch.nn.functional.softmax(output, dim=1)
                predictions.append(probs.cpu().numpy()[0])
        
        predictions = np.array(predictions)
        mean_probs = np.mean(predictions, axis=0)
        std_probs = np.std(predictions, axis=0)
        
        model.eval()  # Volta para modo de avalia√ß√£o
        
        return {
            'mean_probabilities': mean_probs,
            'std_probabilities': std_probs,
            'predictions_distribution': predictions,
            'confidence_bootstrap': np.max(mean_probs),
            'uncertainty': np.max(std_probs)
        }
    
    @staticmethod
    def significance_test(prob1, prob2, predictions_dist):
        """
        Testa se h√° diferen√ßa significativa entre duas probabilidades.
        
        Args:
            prob1: Probabilidade da classe 1
            prob2: Probabilidade da classe 2
            predictions_dist: Distribui√ß√£o de predi√ß√µes do bootstrap
        
        Returns:
            Dict com resultado do teste
        """
        from scipy import stats
        
        # Teste t pareado
        diff = predictions_dist[:, 0] - predictions_dist[:, 1] if predictions_dist.shape[1] > 1 else None
        
        if diff is not None:
            t_stat, p_value = stats.ttest_1samp(diff, 0)
            significant = p_value < 0.05
        else:
            t_stat, p_value, significant = None, None, None
        
        return {
            'probability_diff': abs(prob1 - prob2),
            't_statistic': t_stat,
            'p_value': p_value,
            'significant': significant,
            'interpretation': 'Diferen√ßa significativa' if significant else 'Diferen√ßa n√£o significativa'
        }

class DiagnosticAnalyzer:
    """
    Classe para an√°lise diagn√≥stica diferencial e crit√©rios de exclus√£o.
    """
    
    @staticmethod
    def differential_diagnosis(probabilities, classes, top_k=3, threshold=0.1):
        """
        Lista diagn√≥sticos diferenciais principais baseado nas probabilidades.
        
        Args:
            probabilities: Array de probabilidades para cada classe
            classes: Lista de nomes das classes
            top_k: N√∫mero de diagn√≥sticos principais a retornar
            threshold: Limiar m√≠nimo de probabilidade para considerar
        
        Returns:
            Lista de diagn√≥sticos diferenciais
        """
        # Ordenar por probabilidade
        sorted_indices = np.argsort(probabilities)[::-1]
        
        differentials = []
        for i in range(min(top_k, len(sorted_indices))):
            idx = sorted_indices[i]
            prob = probabilities[idx]
            
            if prob >= threshold:
                differentials.append({
                    'rank': i + 1,
                    'class': classes[idx],
                    'probability': prob,
                    'confidence_level': DiagnosticAnalyzer._interpret_confidence(prob)
                })
        
        return differentials
    
    @staticmethod
    def _interpret_confidence(prob):
        """Interpreta o n√≠vel de confian√ßa"""
        if prob >= 0.9:
            return 'Muito Alto'
        elif prob >= 0.75:
            return 'Alto'
        elif prob >= 0.5:
            return 'Moderado'
        elif prob >= 0.3:
            return 'Baixo'
        else:
            return 'Muito Baixo'
    
    @staticmethod
    def exclusion_criteria(probabilities, classes, exclusion_threshold=0.05):
        """
        Aplica crit√©rios de exclus√£o baseados em probabilidades muito baixas.
        
        Args:
            probabilities: Array de probabilidades
            classes: Lista de classes
            exclusion_threshold: Limiar abaixo do qual classes s√£o exclu√≠das
        
        Returns:
            Dict com classes exclu√≠das e raz√µes
        """
        excluded = []
        
        for i, (prob, class_name) in enumerate(zip(probabilities, classes)):
            if prob < exclusion_threshold:
                excluded.append({
                    'class': class_name,
                    'probability': prob,
                    'reason': f'Probabilidade muito baixa (< {exclusion_threshold:.1%})'
                })
        
        return {
            'excluded_count': len(excluded),
            'excluded_classes': excluded,
            'remaining_count': len(classes) - len(excluded)
        }
    
    @staticmethod
    def distinctive_features(activation_map, threshold_percentile=75):
        """
        Identifica caracter√≠sticas distintivas baseadas no mapa de ativa√ß√£o.
        
        Args:
            activation_map: Mapa de ativa√ß√£o do Grad-CAM
            threshold_percentile: Percentil para identificar regi√µes importantes
        
        Returns:
            Dict com informa√ß√µes sobre caracter√≠sticas distintivas
        """
        if activation_map is None:
            return None
        
        threshold = np.percentile(activation_map, threshold_percentile)
        important_regions = activation_map > threshold
        
        return {
            'high_activation_percentage': (np.sum(important_regions) / important_regions.size) * 100,
            'max_activation': np.max(activation_map),
            'mean_activation': np.mean(activation_map),
            'activation_concentration': np.std(activation_map),
            'interpretation': DiagnosticAnalyzer._interpret_activation_pattern(
                (np.sum(important_regions) / important_regions.size) * 100
            )
        }
    
    @staticmethod
    def _interpret_activation_pattern(percentage):
        """Interpreta o padr√£o de ativa√ß√£o"""
        if percentage > 30:
            return 'Caracter√≠sticas dispersas - m√∫ltiplas regi√µes importantes'
        elif percentage > 15:
            return 'Caracter√≠sticas moderadamente focadas'
        elif percentage > 5:
            return 'Caracter√≠sticas altamente focadas - regi√£o espec√≠fica'
        else:
            return 'Caracter√≠sticas muito concentradas - aten√ß√£o localizada'

class UncertaintyAnalyzer:
    """
    Classe para quantifica√ß√£o de incerteza e an√°lise de risco.
    """
    
    @staticmethod
    def quantify_uncertainty(bootstrap_results, entropy_weight=0.5):
        """
        Quantifica fontes de incerteza na predi√ß√£o.
        
        Args:
            bootstrap_results: Resultados do bootstrap
            entropy_weight: Peso para a entropia na incerteza total
        
        Returns:
            Dict com an√°lise de incerteza
        """
        mean_probs = bootstrap_results['mean_probabilities']
        std_probs = bootstrap_results['std_probabilities']
        
        # Incerteza aleat√≥ria (epist√™mica) - varia√ß√£o das predi√ß√µes
        aleatoric_uncertainty = np.mean(std_probs)
        
        # Incerteza do modelo (entropia)
        entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-10))
        max_entropy = np.log(len(mean_probs))
        normalized_entropy = entropy / max_entropy
        
        # Incerteza total
        total_uncertainty = (1 - entropy_weight) * aleatoric_uncertainty + entropy_weight * normalized_entropy
        
        return {
            'aleatoric_uncertainty': aleatoric_uncertainty,
            'model_entropy': entropy,
            'normalized_entropy': normalized_entropy,
            'total_uncertainty': total_uncertainty,
            'uncertainty_level': UncertaintyAnalyzer._classify_uncertainty(total_uncertainty),
            'sources': {
                'model_variation': aleatoric_uncertainty,
                'prediction_ambiguity': normalized_entropy
            }
        }
    
    @staticmethod
    def _classify_uncertainty(uncertainty):
        """Classifica o n√≠vel de incerteza"""
        if uncertainty < 0.1:
            return 'Muito Baixa'
        elif uncertainty < 0.2:
            return 'Baixa'
        elif uncertainty < 0.4:
            return 'Moderada'
        elif uncertainty < 0.6:
            return 'Alta'
        else:
            return 'Muito Alta'
    
    @staticmethod
    def assess_error_impact(top_probabilities, classes, risk_categories=None):
        """
        Avalia o impacto de poss√≠veis erros de classifica√ß√£o.
        
        Args:
            top_probabilities: Probabilidades das top classes
            classes: Nomes das classes
            risk_categories: Dict mapeando classes para n√≠veis de risco (opcional)
        
        Returns:
            Dict com avalia√ß√£o de impacto
        """
        if risk_categories is None:
            # Risco padr√£o baseado apenas na confian√ßa
            risk_categories = {cls: 'medium' for cls in classes}
        
        # Calcular probabilidade de erro
        error_probability = 1 - np.max(top_probabilities)
        
        # Avaliar impacto
        predicted_class = classes[np.argmax(top_probabilities)]
        risk_level = risk_categories.get(predicted_class, 'medium')
        
        return {
            'error_probability': error_probability,
            'predicted_class_risk': risk_level,
            'impact_score': error_probability * UncertaintyAnalyzer._risk_weight(risk_level),
            'recommendation': UncertaintyAnalyzer._generate_recommendation(
                error_probability, risk_level
            )
        }
    
    @staticmethod
    def _risk_weight(risk_level):
        """Retorna peso do n√≠vel de risco"""
        weights = {'low': 1, 'medium': 2, 'high': 3, 'critical': 5}
        return weights.get(risk_level.lower(), 2)
    
    @staticmethod
    def _generate_recommendation(error_prob, risk_level):
        """Gera recomenda√ß√£o baseada em erro e risco"""
        if error_prob > 0.3 and risk_level in ['high', 'critical']:
            return '‚ö†Ô∏è ATEN√á√ÉO: Alta probabilidade de erro em categoria de alto risco. Recomenda-se valida√ß√£o adicional.'
        elif error_prob > 0.5:
            return '‚ö†Ô∏è Confian√ßa baixa. Considere an√°lise complementar ou consulta especializada.'
        elif error_prob > 0.3:
            return '‚ÑπÔ∏è Confian√ßa moderada. Monitoramento recomendado.'
        else:
            return '‚úÖ Confian√ßa adequada. Resultado confi√°vel.'
    
    @staticmethod
    def safety_margin(confidence, min_acceptable=0.7, target=0.9):
        """
        Estabelece margem de seguran√ßa para a predi√ß√£o.
        
        Args:
            confidence: Confian√ßa da predi√ß√£o
            min_acceptable: Confian√ßa m√≠nima aceit√°vel
            target: Confian√ßa alvo desejada
        
        Returns:
            Dict com an√°lise de margem de seguran√ßa
        """
        margin_to_minimum = confidence - min_acceptable
        margin_to_target = target - confidence
        
        status = 'safe' if confidence >= min_acceptable else 'unsafe'
        meets_target = confidence >= target
        
        return {
            'confidence': confidence,
            'min_acceptable': min_acceptable,
            'target': target,
            'margin_to_minimum': margin_to_minimum,
            'margin_to_target': margin_to_target,
            'status': status,
            'meets_target': meets_target,
            'safety_score': min(1.0, confidence / target),
            'interpretation': UncertaintyAnalyzer._interpret_safety(
                margin_to_minimum, meets_target
            )
        }
    
    @staticmethod
    def _interpret_safety(margin, meets_target):
        """Interpreta a margem de seguran√ßa"""
        if margin < 0:
            return 'üî¥ ABAIXO DO M√çNIMO ACEIT√ÅVEL - N√£o recomendado para uso'
        elif margin < 0.1:
            return 'üü° MARGEM CR√çTICA - Usar com extrema cautela'
        elif meets_target:
            return 'üü¢ MARGEM ADEQUADA - Confian√ßa alvo atingida'
        else:
            return 'üü¢ MARGEM ACEIT√ÅVEL - Dentro dos par√¢metros seguros'
    
    @staticmethod
    def clinical_impact_assessment(confidence, class_name, differential_diagnoses):
        """
        Avalia o impacto cl√≠nico/pr√°tico da predi√ß√£o.
        
        Args:
            confidence: Confian√ßa da predi√ß√£o principal
            class_name: Nome da classe predita
            differential_diagnoses: Lista de diagn√≥sticos diferenciais
        
        Returns:
            Dict com avalia√ß√£o de impacto cl√≠nico
        """
        # Calcular ambiguidade diagn√≥stica
        if len(differential_diagnoses) > 1:
            top2_diff = differential_diagnoses[0]['probability'] - differential_diagnoses[1]['probability']
        else:
            top2_diff = 1.0
        
        # Determinar a√ß√£o recomendada
        if confidence >= 0.9 and top2_diff > 0.3:
            action = 'Proceder com diagn√≥stico prim√°rio'
            priority = 'Normal'
        elif confidence >= 0.75 and top2_diff > 0.2:
            action = 'Considerar diagn√≥stico prim√°rio com monitoramento'
            priority = 'M√©dia'
        elif len(differential_diagnoses) > 1 and differential_diagnoses[1]['probability'] > 0.3:
            action = 'Investigar diagn√≥sticos diferenciais - m√∫ltiplas possibilidades'
            priority = 'Alta'
        else:
            action = 'An√°lise complementar necess√°ria'
            priority = 'Alta'
        
        return {
            'primary_diagnosis': class_name,
            'diagnostic_confidence': confidence,
            'differential_count': len(differential_diagnoses),
            'diagnostic_ambiguity': 1 - top2_diff if len(differential_diagnoses) > 1 else 0,
            'recommended_action': action,
            'priority_level': priority,
            'requires_specialist': confidence < 0.75 or (
                len(differential_diagnoses) > 1 and differential_diagnoses[1]['probability'] > 0.3
            )
        }

# Enhanced image preprocessing class
class EnhancedImagePreprocessor:
    """Classe para melhorar o tratamento de imagens antes do treinamento"""
    
    @staticmethod
    def enhance_image_quality(image):
        """Aplica melhorias de qualidade na imagem"""
        # Ajustar contraste
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.2)
        
        # Ajustar nitidez
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.1)
        
        # Ajustar brilho levemente
        enhancer = ImageEnhance.Brightness(image)
        image = enhancer.enhance(1.05)
        
        return image

def get_augmentation_transforms(augmentation_type='standard'):
    """
    Retorna transforma√ß√µes de acordo com o tipo de aumento de dados
    
    Args:
        augmentation_type: 'none', 'standard', 'mixup', 'cutmix'
    """
    if augmentation_type == 'none':
        # Sem aumento de dados - apenas transforma√ß√µes b√°sicas
        train_transform = transforms.Compose([
            transforms.Lambda(EnhancedImagePreprocessor.enhance_image_quality),
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
        ])
    else:
        # Standard ou base para mixup/cutmix
        train_transform = transforms.Compose([
            transforms.Lambda(EnhancedImagePreprocessor.enhance_image_quality),
            transforms.RandomApply([
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(degrees=90),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
                transforms.RandomAffine(degrees=0, shear=10),
            ], p=0.5),
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
        ])
    
    return train_transform

# Transforma√ß√µes para valida√ß√£o e teste com normaliza√ß√£o ImageNet
test_transforms = transforms.Compose([
    transforms.Lambda(EnhancedImagePreprocessor.enhance_image_quality),
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

# Implementa√ß√£o de Mixup
def mixup_data(x, y, alpha=1.0):
    """Aplica Mixup ao batch de dados"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Calcula a loss para Mixup"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# Implementa√ß√£o de CutMix
def cutmix_data(x, y, alpha=1.0):
    """Aplica CutMix ao batch de dados"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)

    # Gerar bbox
    W = x.size()[2]
    H = x.size()[3]
    cut_rat = np.sqrt(1. - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)

    # Centro do box
    cx = np.random.randint(0, W)
    cy = np.random.randint(0, H)

    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)

    x_cutmix = x.clone()
    x_cutmix[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]

    # Ajustar lambda com a √°rea real
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    y_a, y_b = y, y[index]
    return x_cutmix, y_a, y_b, lam

# Definir as transforma√ß√µes padr√£o para compatibilidade com c√≥digo existente
train_transforms = get_augmentation_transforms('standard')

# Dataset personalizado
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

def seed_worker(worker_id):
    """
    Fun√ß√£o para definir a seed em cada worker do DataLoader.
    """
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

def visualize_data(dataset, classes):
    """
    Exibe algumas imagens do conjunto de dados com suas classes.
    """
    st.write("### üìä Visualiza√ß√£o de algumas imagens do conjunto de dados original:")
    fig, axes = plt.subplots(1, 5, figsize=(15, 3))
    for i in range(5):
        idx = np.random.randint(len(dataset))
        image, label = dataset[idx]
        image = np.array(image)  # Converter a imagem PIL em array NumPy
        axes[i].imshow(image)
        axes[i].set_title(classes[label])
        axes[i].axis('off')
    st.pyplot(fig)
    plt.close(fig)

def plot_class_distribution(dataset, classes, title="Distribui√ß√£o das Classes"):
    """
    Exibe a distribui√ß√£o das classes no conjunto de dados e mostra os valores quantitativos.
    """
    # Extrair os r√≥tulos das classes para todas as imagens no dataset
    labels = [label for _, label in dataset]
    
    # Contagem de cada classe
    class_counts = np.bincount(labels)
    
    # Plotar o gr√°fico com as contagens
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.countplot(x=labels, hue=labels, ax=ax, palette="Set2", legend=False)
    
    # Adicionar os nomes das classes no eixo X
    ax.set_xticks(range(len(classes)))
    ax.set_xticklabels(classes, rotation=45, ha='right')
    
    # Adicionar as contagens acima das barras
    for i, count in enumerate(class_counts):
        ax.text(i, count, str(count), ha='center', va='bottom', fontweight='bold')
    
    ax.set_title(title)
    ax.set_xlabel("Classes")
    ax.set_ylabel("N√∫mero de Imagens")
    
    st.pyplot(fig)
    plt.close(fig)
    
    return class_counts

def show_augmented_images(dataset, transform, classes, num_augmentations=5):
    """
    Mostra imagens originais e suas vers√µes aumentadas.
    """
    st.write("### üîÑ Exemplos de Imagens Aumentadas (Data Augmentation)")
    st.write("Cada linha mostra uma imagem original seguida de suas vers√µes aumentadas:")
    
    # Selecionar 3 imagens aleat√≥rias
    num_samples = 3
    for sample_idx in range(num_samples):
        idx = np.random.randint(len(dataset))
        original_image, label = dataset[idx]
        
        # Criar figura com 1 original + num_augmentations aumentadas
        fig, axes = plt.subplots(1, num_augmentations + 1, figsize=(15, 3))
        
        # Mostrar imagem original
        axes[0].imshow(np.array(original_image))
        axes[0].set_title(f'Original\n{classes[label]}')
        axes[0].axis('off')
        axes[0].set_facecolor('#e6f2ff')
        
        # Mostrar imagens aumentadas
        for i in range(1, num_augmentations + 1):
            augmented_image = transform(original_image)
            # Desnormalizar para visualiza√ß√£o usando a fun√ß√£o helper
            augmented_np = denormalize_image(augmented_image)
            
            axes[i].imshow(augmented_np)
            axes[i].set_title(f'Aumentada {i}')
            axes[i].axis('off')
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)

def calculate_dataset_statistics(dataset, classes):
    """
    Calcula estat√≠sticas do dataset incluindo m√©dia, desvio padr√£o, etc.
    """
    st.write("### üìà Estat√≠sticas do Dataset")
    
    # Contagem por classe
    labels = [label for _, label in dataset]
    class_counts = np.bincount(labels)
    
    # Criar dataframe com estat√≠sticas
    stats_data = {
        'Classe': classes,
        'Quantidade': class_counts,
        'Percentual (%)': [f"{(count/len(dataset)*100):.2f}" for count in class_counts]
    }
    
    df_stats = pd.DataFrame(stats_data)
    
    st.write("#### Distribui√ß√£o de Classes:")
    # Fixed: Removed width=None parameter as it's no longer supported in Streamlit
    st.dataframe(df_stats)
    
    # Estat√≠sticas gerais
    st.write("#### Estat√≠sticas Gerais:")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total de Imagens", len(dataset))
    
    with col2:
        st.metric("N√∫mero de Classes", len(classes))
    
    with col3:
        st.metric("Imagens por Classe (M√©dia)", f"{np.mean(class_counts):.1f}")
    
    with col4:
        st.metric("Desvio Padr√£o", f"{np.std(class_counts):.1f}")
    
    # Verificar balanceamento
    min_count = np.min(class_counts)
    max_count = np.max(class_counts)
    imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
    
    if imbalance_ratio > 1.5:
        st.warning(f"‚ö†Ô∏è Dataset desbalanceado detectado! Raz√£o: {imbalance_ratio:.2f}x (Classe mais frequente / Classe menos frequente)")
        st.info("üí° Recomenda√ß√£o: Considere usar 'Perda Ponderada para Classes Desbalanceadas' nas configura√ß√µes.")
    else:
        st.success(f"‚úÖ Dataset relativamente balanceado. Raz√£o: {imbalance_ratio:.2f}x")
    
    return df_stats

def visualize_pca_features(features, labels, classes, n_components=2):
    """
    Visualiza features usando PCA.
    """
    st.write(f"### üî¨ An√°lise PCA ({n_components} Componentes)")
    
    # Aplicar PCA
    pca = PCA(n_components=n_components)
    features_pca = pca.fit_transform(features)
    
    # Mostrar vari√¢ncia explicada
    explained_var = pca.explained_variance_ratio_
    st.write(f"**Vari√¢ncia Explicada:** {explained_var[0]*100:.2f}% (PC1), {explained_var[1]*100:.2f}% (PC2)")
    st.write(f"**Vari√¢ncia Total Explicada:** {sum(explained_var)*100:.2f}%")
    
    # Criar visualiza√ß√£o
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Mapear labels para nomes de classes
    labels_named = [classes[label] for label in labels]
    
    # Criar scatter plot
    scatter = sns.scatterplot(
        x=features_pca[:, 0], 
        y=features_pca[:, 1], 
        hue=labels_named,
        palette="tab10",
        ax=ax,
        s=100,
        alpha=0.7,
        edgecolor='black',
        linewidth=0.5
    )
    
    ax.set_xlabel(f'Componente Principal 1 ({explained_var[0]*100:.1f}%)')
    ax.set_ylabel(f'Componente Principal 2 ({explained_var[1]*100:.1f}%)')
    ax.set_title('Visualiza√ß√£o PCA das Features Extra√≠das')
    ax.legend(title='Classes', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close(fig)
    
    return features_pca, explained_var

def get_model(model_name, num_classes, dropout_p=0.5, fine_tune=False):
    """
    Retorna o modelo pr√©-treinado selecionado, incluindo CNNs e Vision Transformers.
    
    Args:
        model_name: Nome do modelo (ResNet18, ResNet50, DenseNet121, ViT-B/16, ViT-B/32, ViT-L/16, Swin-T, Swin-B)
        num_classes: N√∫mero de classes
        dropout_p: Taxa de dropout
        fine_tune: Se deve fazer fine-tuning completo
    
    Returns:
        model: Modelo PyTorch configurado
    """
    # CNNs Tradicionais
    if model_name == 'ResNet18':
        model = models.resnet18(weights='DEFAULT')
    elif model_name == 'ResNet50':
        model = models.resnet50(weights='DEFAULT')
    elif model_name == 'DenseNet121':
        model = models.densenet121(weights='DEFAULT')
    # Vision Transformers (torchvision)
    elif model_name == 'ViT-B/16':
        model = models.vit_b_16(weights='DEFAULT')
    elif model_name == 'ViT-B/32':
        model = models.vit_b_32(weights='DEFAULT')
    elif model_name == 'ViT-L/16':
        model = models.vit_l_16(weights='DEFAULT')
    # Vision Transformers e Swin (timm - mais robustos)
    elif model_name == 'ViT-B/16-timm' and TIMM_AVAILABLE:
        model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes, drop_rate=dropout_p)
        if not fine_tune:
            for name, param in model.named_parameters():
                if 'head' not in name:
                    param.requires_grad = False
        return model.to(device)
    elif model_name == 'ViT-L/16-timm' and TIMM_AVAILABLE:
        model = timm.create_model('vit_large_patch16_224', pretrained=True, num_classes=num_classes, drop_rate=dropout_p)
        if not fine_tune:
            for name, param in model.named_parameters():
                if 'head' not in name:
                    param.requires_grad = False
        return model.to(device)
    elif model_name == 'Swin-T' and TIMM_AVAILABLE:
        model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes, drop_rate=dropout_p)
        if not fine_tune:
            for name, param in model.named_parameters():
                if 'head' not in name:
                    param.requires_grad = False
        return model.to(device)
    elif model_name == 'Swin-B' and TIMM_AVAILABLE:
        model = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=num_classes, drop_rate=dropout_p)
        if not fine_tune:
            for name, param in model.named_parameters():
                if 'head' not in name:
                    param.requires_grad = False
        return model.to(device)
    else:
        st.error(f"Modelo '{model_name}' n√£o suportado ou timm n√£o est√° dispon√≠vel.")
        return None

    if not fine_tune:
        for param in model.parameters():
            param.requires_grad = False

    # Configurar camada de sa√≠da baseada no tipo de modelo
    if model_name.startswith('ResNet'):
        num_ftrs = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(p=dropout_p),
            nn.Linear(num_ftrs, num_classes)
        )
        # Ensure final layer requires grad
        for param in model.fc.parameters():
            param.requires_grad = True
    elif model_name.startswith('DenseNet'):
        num_ftrs = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Dropout(p=dropout_p),
            nn.Linear(num_ftrs, num_classes)
        )
        # Ensure final layer requires grad
        for param in model.classifier.parameters():
            param.requires_grad = True
    elif model_name.startswith('ViT'):
        # Vision Transformers usam 'heads' ao inv√©s de 'fc' ou 'classifier'
        num_ftrs = model.heads.head.in_features
        model.heads.head = nn.Sequential(
            nn.Dropout(p=dropout_p),
            nn.Linear(num_ftrs, num_classes)
        )
        # Ensure final layer requires grad
        for param in model.heads.head.parameters():
            param.requires_grad = True
    else:
        st.error("Tipo de modelo n√£o suportado para configura√ß√£o.")
        return None

    model = model.to(device)
    return model

# ============= MELHORIAS AVAN√áADAS =============

# 1. Label Smoothing Loss
class LabelSmoothingCrossEntropy(nn.Module):
    """
    Label smoothing cross entropy loss.
    Previne overconfident predictions e melhora generaliza√ß√£o.
    """
    def __init__(self, smoothing=0.1, weight=None):
        super().__init__()
        self.smoothing = smoothing
        self.weight = weight
    
    def forward(self, pred, target):
        n_classes = pred.size(-1)
        log_preds = torch.nn.functional.log_softmax(pred, dim=-1)
        
        # Create smoothed distribution
        with torch.no_grad():
            true_dist = torch.zeros_like(log_preds)
            true_dist.fill_(self.smoothing / (n_classes - 1))
            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)
        
        # Apply class weights if provided
        if self.weight is not None:
            # Weight each sample based on its target class
            sample_weights = self.weight[target]
            loss = torch.sum(-true_dist * log_preds, dim=-1) * sample_weights
            return loss.mean()
        else:
            return torch.mean(torch.sum(-true_dist * log_preds, dim=-1))

# 2. Exponential Moving Average (EMA) para pesos do modelo
class ModelEMA:
    """
    Mant√©m m√©dia m√≥vel exponencial dos pesos do modelo.
    Melhora generaliza√ß√£o e estabilidade.
    """
    def __init__(self, model, decay=0.999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self.register()

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.backup[name] = param.data.clone()
                param.data = self.shadow[name]

    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                param.data = self.backup[name]
        self.backup = {}

# 3. Agente CrewAI para buscar informa√ß√µes de treinamento
class TrainingResearchAgent:
    """
    Agente inteligente que busca informa√ß√µes na web para melhorar o treinamento.
    """
    def __init__(self, use_crewai=False):
        self.use_crewai = use_crewai and CREWAI_AVAILABLE
        self.insights = []
        
    def research_training_strategies(self, model_name, dataset_type):
        """
        Pesquisa estrat√©gias de treinamento para o modelo e tipo de dataset.
        """
        if not self.use_crewai:
            # Retornar insights padr√£o
            return {
                'learning_rate': 0.0001,
                'batch_size': 16,
                'augmentation': 'standard',
                'scheduler': 'CosineAnnealingLR',
                'insights': ['Using default configuration']
            }
        
        try:
            # Definir agentes CrewAI
            researcher = Agent(
                role='ML Training Researcher',
                goal=f'Find optimal training strategies for {model_name} on {dataset_type} images',
                backstory='Expert in deep learning optimization and hyperparameter tuning',
                verbose=True,
                allow_delegation=False
            )
            
            # Definir tarefa
            research_task = Task(
                description=f'''
                Research and recommend:
                1. Optimal learning rate for {model_name}
                2. Best data augmentation strategies for {dataset_type}
                3. Recommended batch size and scheduler
                4. Common pitfalls to avoid
                ''',
                agent=researcher,
                expected_output='Training recommendations in JSON format'
            )
            
            # Executar crew
            crew = Crew(
                agents=[researcher],
                tasks=[research_task],
                verbose=2,
                process=Process.sequential
            )
            
            result = crew.kickoff()
            self.insights.append(result)
            
            return {
                'research': result,
                'insights': self.insights
            }
            
        except Exception as e:
            st.warning(f"CrewAI research failed: {e}. Using default config.")
            return {
                'learning_rate': 0.0001,
                'batch_size': 16,
                'augmentation': 'standard',
                'scheduler': 'CosineAnnealingLR',
                'insights': [f'Error: {e}']
            }

# 4. Reinforcement Learning para ajuste din√¢mico de hiperpar√¢metros
class ReinforcementLearningTrainer:
    """
    Usa RL para ajustar hiperpar√¢metros durante o treinamento.
    Implementa Q-Learning simples para ajustar learning rate e batch size.
    """
    def __init__(self, initial_lr=0.001, lr_range=(0.00001, 0.01)):
        self.lr = initial_lr
        self.lr_range = lr_range
        self.q_table = {}  # Estado -> A√ß√£o -> Q-value
        self.alpha = 0.1  # Learning rate do RL
        self.gamma = 0.9  # Discount factor
        self.epsilon = 0.2  # Exploration rate
        self.actions = ['increase_lr', 'decrease_lr', 'keep_lr']
        self.performance_history = []
        
    def get_state(self, val_loss, val_acc, epoch):
        """
        Define o estado baseado em perda e acur√°cia de valida√ß√£o.
        """
        if len(self.performance_history) == 0:
            # First epoch - use neutral state
            return "initial_epoch_0"
        
        prev = self.performance_history[-1]
        loss_trend = 'improving' if val_loss < prev['loss'] else 'degrading'
        acc_trend = 'improving' if val_acc > prev['acc'] else 'degrading'
        
        return f"{loss_trend}_{acc_trend}_epoch{epoch % 10}"
    
    def choose_action(self, state):
        """
        Escolhe a√ß√£o usando epsilon-greedy.
        """
        if np.random.random() < self.epsilon:
            return np.random.choice(self.actions)
        
        if state not in self.q_table:
            self.q_table[state] = {action: 0.0 for action in self.actions}
        
        return max(self.q_table[state], key=self.q_table[state].get)
    
    def update_q_value(self, state, action, reward, next_state):
        """
        Atualiza Q-value usando Q-learning.
        """
        if state not in self.q_table:
            self.q_table[state] = {action: 0.0 for action in self.actions}
        if next_state not in self.q_table:
            self.q_table[next_state] = {action: 0.0 for action in self.actions}
        
        old_q = self.q_table[state][action]
        next_max_q = max(self.q_table[next_state].values())
        new_q = old_q + self.alpha * (reward + self.gamma * next_max_q - old_q)
        self.q_table[state][action] = new_q
    
    def adjust_learning_rate(self, action):
        """
        Ajusta learning rate baseado na a√ß√£o.
        """
        if action == 'increase_lr':
            self.lr = min(self.lr * 1.2, self.lr_range[1])
        elif action == 'decrease_lr':
            self.lr = max(self.lr * 0.8, self.lr_range[0])
        # 'keep_lr' n√£o faz nada
        
        return self.lr
    
    def compute_reward(self, val_loss, val_acc):
        """
        Computa recompensa baseado no desempenho.
        """
        if len(self.performance_history) == 0:
            reward = 0.0
        else:
            prev = self.performance_history[-1]
            loss_improvement = prev['loss'] - val_loss
            acc_improvement = val_acc - prev['acc']
            reward = loss_improvement * 10 + acc_improvement * 100
        
        self.performance_history.append({'loss': val_loss, 'acc': val_acc})
        return reward
    
    def step(self, val_loss, val_acc, epoch, optimizer):
        """
        Executa um passo de RL: escolhe a√ß√£o, ajusta LR, computa recompensa.
        """
        state = self.get_state(val_loss, val_acc, epoch)
        action = self.choose_action(state)
        new_lr = self.adjust_learning_rate(action)
        
        # Atualizar learning rate no otimizador
        for param_group in optimizer.param_groups:
            param_group['lr'] = new_lr
        
        reward = self.compute_reward(val_loss, val_acc)
        next_state = self.get_state(val_loss, val_acc, epoch + 1)
        self.update_q_value(state, action, reward, next_state)
        
        return {
            'action': action,
            'new_lr': new_lr,
            'reward': reward,
            'state': state
        }

def train_model(data_dir, num_classes, model_name, fine_tune, epochs, learning_rate, batch_size, train_split, valid_split, use_weighted_loss, l2_lambda, l1_lambda, patience, optimizer_name='Adam', scheduler_name='None', augmentation_type='standard', label_smoothing=0.1, use_gradient_clipping=True, use_ema=True, use_rl=False, use_crewai=False):
    """
    Fun√ß√£o principal para treinamento do modelo com melhorias avan√ßadas.
    
    Args:
        data_dir: Diret√≥rio com os dados
        num_classes: N√∫mero de classes
        model_name: Nome do modelo
        fine_tune: Se deve fazer fine-tuning completo
        epochs: N√∫mero de √©pocas
        learning_rate: Taxa de aprendizagem
        batch_size: Tamanho do lote
        train_split: Propor√ß√£o de treino
        valid_split: Propor√ß√£o de valida√ß√£o
        use_weighted_loss: Se deve usar perda ponderada
        l2_lambda: Regulariza√ß√£o L2 (weight decay)
        l1_lambda: Regulariza√ß√£o L1
        patience: Paci√™ncia para early stopping
        optimizer_name: Nome do otimizador (Adam, AdamW, SGD, Ranger, Lion)
        scheduler_name: Nome do scheduler (None, CosineAnnealingLR, OneCycleLR)
        augmentation_type: Tipo de aumento de dados (none, standard, mixup, cutmix)
        label_smoothing: Suaviza√ß√£o de labels (0.0-0.3, padr√£o 0.1)
        use_gradient_clipping: Se deve usar gradient clipping
        use_ema: Se deve usar Exponential Moving Average nos pesos
        use_rl: Se deve usar Reinforcement Learning para ajuste din√¢mico
        use_crewai: Se deve usar CrewAI para pesquisa de estrat√©gias
    
    Returns:
        tuple: (model, classes) ou None em caso de erro
    """
    set_seed(42)

    # Carregar o dataset original sem transforma√ß√µes
    full_dataset = datasets.ImageFolder(root=data_dir)
    
    # ========== CONTAGEM INICIAL DOS DADOS ==========
    st.write("## üìä AN√ÅLISE INICIAL DO DATASET")
    st.write(f"### üî¢ **Contagem Inicial: {len(full_dataset)} imagens**")
    
    # Exibir estat√≠sticas detalhadas
    stats_df = calculate_dataset_statistics(full_dataset, full_dataset.classes)
    
    # Exibir algumas imagens do dataset original
    visualize_data(full_dataset, full_dataset.classes)
    
    # Plotar distribui√ß√£o inicial
    st.write("### üìä Distribui√ß√£o Inicial das Classes")
    initial_class_counts = plot_class_distribution(full_dataset, full_dataset.classes, 
                                                    title="Distribui√ß√£o INICIAL das Classes (Sem Aumento de Dados)")

    # ========== T√âCNICA DE AUMENTO DE DADOS ==========
    st.write("---")
    st.write("## üîÑ APLICA√á√ÉO DA T√âCNICA DE AUMENTO DE DADOS")
    st.write(f"**T√©cnica Selecionada:** `{augmentation_type}`")
    
    if augmentation_type == 'none':
        st.info("‚ÑπÔ∏è Nenhuma t√©cnica de aumento de dados foi selecionada. As imagens ser√£o usadas como est√£o.")
    elif augmentation_type == 'standard':
        st.info("‚ÑπÔ∏è T√©cnica Standard: Aplica√ß√£o de transforma√ß√µes aleat√≥rias (rota√ß√£o, flip, crop, jitter, etc.)")
    elif augmentation_type == 'mixup':
        st.info("‚ÑπÔ∏è T√©cnica Mixup: Mistura linear de pares de imagens e seus r√≥tulos")
    elif augmentation_type == 'cutmix':
        st.info("‚ÑπÔ∏è T√©cnica CutMix: Recorte e colagem de regi√µes entre imagens diferentes")
    
    # Obter transforma√ß√µes baseadas no tipo de augmenta√ß√£o
    train_transform = get_augmentation_transforms(augmentation_type)
    
    # Mostrar exemplos de imagens aumentadas
    if augmentation_type != 'none':
        show_augmented_images(full_dataset, train_transform, full_dataset.classes, num_augmentations=4)
    
    # ========== ESTIMATIVA AP√ìS AUMENTO ==========
    st.write("---")
    st.write("## üìà ESTIMATIVA AP√ìS AUMENTO DE DADOS")
    
    # Calcular estimativa de imagens ap√≥s aumento
    # Durante o treinamento, cada √©poca gera vers√µes aumentadas
    if augmentation_type == 'none':
        augmentation_multiplier = 1
        st.write(f"### üî¢ **Total Estimado: {len(full_dataset)} imagens** (sem aumento)")
    else:
        # Com augmentation, cada √©poca gera vers√µes diferentes
        # Estimativa conservadora: cada imagem pode gerar de 3-5 varia√ß√µes por √©poca
        augmentation_multiplier = 4  # M√©dia estimada
        total_estimated = len(full_dataset) * augmentation_multiplier * epochs
        st.write(f"### üî¢ **Total de Imagens Original: {len(full_dataset)}**")
        st.write(f"### üî¢ **Multiplicador Estimado por √âpoca: ~{augmentation_multiplier}x**")
        st.write(f"### üî¢ **Total Estimado Durante {epochs} √âpocas: ~{total_estimated:,} imagens aumentadas**")
        st.info(f"üí° **Explica√ß√£o:** Durante o treinamento, cada uma das {len(full_dataset)} imagens originais ser√° " +
                f"transformada aleatoriamente a cada √©poca, gerando aproximadamente {augmentation_multiplier}x varia√ß√µes √∫nicas " +
                f"ao longo de {epochs} √©pocas, totalizando cerca de {total_estimated:,} imagens processadas.")
    
    st.write("---")
    
    # Criar o dataset personalizado com aumento de dados
    train_dataset = CustomDataset(full_dataset, transform=train_transform)
    valid_dataset = CustomDataset(full_dataset, transform=test_transforms)
    test_dataset = CustomDataset(full_dataset, transform=test_transforms)

    # Dividir os √≠ndices para treino, valida√ß√£o e teste
    dataset_size = len(full_dataset)
    indices = list(range(dataset_size))
    np.random.shuffle(indices)

    train_end = int(train_split * dataset_size)
    valid_end = int((train_split + valid_split) * dataset_size)

    train_indices = indices[:train_end]
    valid_indices = indices[train_end:valid_end]
    test_indices = indices[valid_end:]

    train_dataset = torch.utils.data.Subset(train_dataset, train_indices)
    valid_dataset = torch.utils.data.Subset(valid_dataset, valid_indices)
    test_dataset = torch.utils.data.Subset(test_dataset, test_indices)

    # Dataloaders
    g = torch.Generator()
    g.manual_seed(42)

    # Inicializar agentes inteligentes se habilitados
    research_agent = None
    rl_trainer = None
    
    if use_crewai:
        st.write("ü§ñ **Inicializando Agente CrewAI para pesquisa de estrat√©gias...**")
        research_agent = TrainingResearchAgent(use_crewai=True)
        research_results = research_agent.research_training_strategies(model_name, "rock classification")
        if research_results and 'insights' in research_results:
            st.info(f"üìö **Insights do Agente:** {research_results['insights']}")
    
    if use_rl:
        if scheduler_name != 'None':
            st.warning("‚ö†Ô∏è **Aten√ß√£o:** RL est√° ativo junto com um scheduler. O RL pode entrar em conflito com o scheduler. Considere desativar um deles.")
        st.write("üéØ **Inicializando Reinforcement Learning para ajuste din√¢mico...**")
        rl_trainer = ReinforcementLearningTrainer(initial_lr=learning_rate)
    
    if use_weighted_loss:
        targets = [full_dataset.targets[i] for i in train_indices]
        class_counts = np.bincount(targets)
        class_counts = class_counts + 1e-6  # Para evitar divis√£o por zero
        class_weights = 1.0 / class_counts
        class_weights = torch.FloatTensor(class_weights).to(device)
        if label_smoothing > 0:
            criterion = LabelSmoothingCrossEntropy(smoothing=label_smoothing, weight=class_weights)
            st.info(f"‚ú® **Usando Label Smoothing ({label_smoothing}) com pesos de classe**")
        else:
            criterion = nn.CrossEntropyLoss(weight=class_weights)
    else:
        if label_smoothing > 0:
            criterion = LabelSmoothingCrossEntropy(smoothing=label_smoothing)
            st.info(f"‚ú® **Usando Label Smoothing ({label_smoothing})**")
        else:
            criterion = nn.CrossEntropyLoss()

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)
    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)

    # Carregar o modelo
    model = get_model(model_name, num_classes, dropout_p=0.5, fine_tune=fine_tune)
    if model is None:
        return None

    # Definir o otimizador com L2 regularization (weight_decay)
    trainable_params = filter(lambda p: p.requires_grad, model.parameters())
    
    if optimizer_name == 'Adam':
        optimizer = optim.Adam(trainable_params, lr=learning_rate, weight_decay=l2_lambda)
    elif optimizer_name == 'AdamW':
        optimizer = optim.AdamW(trainable_params, lr=learning_rate, weight_decay=l2_lambda)
    elif optimizer_name == 'SGD':
        optimizer = optim.SGD(trainable_params, lr=learning_rate, weight_decay=l2_lambda, momentum=0.9, nesterov=True)
    elif optimizer_name == 'Ranger' and ADVANCED_OPTIMIZERS_AVAILABLE:
        optimizer = optim_advanced.Ranger(trainable_params, lr=learning_rate, weight_decay=l2_lambda)
    elif optimizer_name == 'Lion' and ADVANCED_OPTIMIZERS_AVAILABLE:
        optimizer = optim_advanced.Lion(trainable_params, lr=learning_rate, weight_decay=l2_lambda)
    else:
        st.warning(f"Otimizador {optimizer_name} n√£o dispon√≠vel. Usando Adam.")
        optimizer = optim.Adam(trainable_params, lr=learning_rate, weight_decay=l2_lambda)
    
    # Configurar Learning Rate Scheduler
    scheduler = None
    if scheduler_name == 'CosineAnnealingLR':
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=learning_rate/100)
    elif scheduler_name == 'OneCycleLR':
        steps_per_epoch = len(train_loader)
        scheduler = optim.lr_scheduler.OneCycleLR(
            optimizer, 
            max_lr=learning_rate*10, 
            epochs=epochs,
            steps_per_epoch=steps_per_epoch,
            pct_start=0.3
        )

    # Listas para armazenar as perdas e acur√°cias
    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []

    # Early Stopping
    best_valid_loss = float('inf')
    epochs_no_improve = 0
    
    # Par√¢metros para Mixup e CutMix
    use_mixup = (augmentation_type == 'mixup')
    use_cutmix = (augmentation_type == 'cutmix')
    mixup_alpha = 1.0
    cutmix_alpha = 1.0
    
    # Cache de par√¢metros para regulariza√ß√£o L1 (otimiza√ß√£o)
    trainable_params_list = list(filter(lambda p: p.requires_grad, model.parameters())) if l1_lambda > 0 else []
    
    # Inicializar EMA se habilitado
    model_ema = None
    if use_ema:
        model_ema = ModelEMA(model, decay=0.999)
        st.info("üìä **Usando Exponential Moving Average (EMA) para pesos do modelo**")

    # Treinamento
    for epoch in range(epochs):
        set_seed(42 + epoch)
        running_loss = 0.0
        running_corrects = 0
        model.train()

        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()
            
            # Aplicar Mixup ou CutMix se selecionado
            if use_mixup:
                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, mixup_alpha)
            elif use_cutmix:
                inputs, labels_a, labels_b, lam = cutmix_data(inputs, labels, cutmix_alpha)
            
            try:
                outputs = model(inputs)
            except Exception as e:
                st.error(f"Erro durante o treinamento: {e}")
                return None

            # Calcular loss
            if use_mixup or use_cutmix:
                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
                _, preds = torch.max(outputs, 1)
            else:
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)
            
            # Adicionar regulariza√ß√£o L1 se configurado
            if l1_lambda > 0:
                l1_reg = torch.tensor(0., device=device)
                for param in trainable_params_list:
                    l1_reg += torch.norm(param, 1)
                loss = loss + l1_lambda * l1_reg
            
            loss.backward()
            
            # Gradient clipping para estabilizar o treinamento
            if use_gradient_clipping:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # Atualizar EMA se habilitado
            if model_ema is not None:
                model_ema.update()
            
            # Atualizar scheduler OneCycleLR a cada batch
            if scheduler_name == 'OneCycleLR' and scheduler is not None:
                scheduler.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data if not (use_mixup or use_cutmix) else preds == labels_a.data)

        epoch_loss = running_loss / len(train_dataset)
        epoch_acc = running_corrects.double() / len(train_dataset)
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc.item())

        # Valida√ß√£o
        model.eval()
        valid_running_loss = 0.0
        valid_running_corrects = 0

        with torch.no_grad():
            for inputs, labels in valid_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)

                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                valid_running_loss += loss.item() * inputs.size(0)
                valid_running_corrects += torch.sum(preds == labels.data)

        valid_epoch_loss = valid_running_loss / len(valid_dataset)
        valid_epoch_acc = valid_running_corrects.double() / len(valid_dataset)
        valid_losses.append(valid_epoch_loss)
        valid_accuracies.append(valid_epoch_acc.item())

        st.write(f'**√âpoca {epoch+1}/{epochs}**')
        st.write(f'Perda de Treino: {epoch_loss:.4f} | Acur√°cia de Treino: {epoch_acc:.4f}')
        st.write(f'Perda de Valida√ß√£o: {valid_epoch_loss:.4f} | Acur√°cia de Valida√ß√£o: {valid_epoch_acc:.4f}')
        
        # Aplicar Reinforcement Learning se habilitado
        if rl_trainer is not None:
            rl_result = rl_trainer.step(valid_epoch_loss, valid_epoch_acc.item(), epoch, optimizer)
            st.write(f"üéØ **RL Action:** {rl_result['action']} | **New LR:** {rl_result['new_lr']:.6f} | **Reward:** {rl_result['reward']:.4f}")

        # Atualizar scheduler CosineAnnealingLR ap√≥s cada √©poca
        if scheduler_name == 'CosineAnnealingLR' and scheduler is not None:
            scheduler.step()

        # Early Stopping
        if valid_epoch_loss < best_valid_loss:
            best_valid_loss = valid_epoch_loss
            epochs_no_improve = 0
            best_model_wts = model.state_dict()
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= patience:
                st.write('Early stopping!')
                model.load_state_dict(best_model_wts)
                break

    # Carregar os melhores pesos do modelo
    model.load_state_dict(best_model_wts)
    
    # Aplicar pesos EMA se habilitado
    if model_ema is not None:
        st.info("üìä **Aplicando pesos EMA ao modelo final...**")
        model_ema.apply_shadow()

    # Gr√°ficos de Perda e Acur√°cia
    plot_metrics(epochs, train_losses, valid_losses, train_accuracies, valid_accuracies)

    # Avalia√ß√£o Final no Conjunto de Teste
    st.write("**Avalia√ß√£o no Conjunto de Teste**")
    compute_metrics(model, test_loader, full_dataset.classes)

    # An√°lise de Erros
    st.write("**An√°lise de Erros**")
    error_analysis(model, test_loader, full_dataset.classes)

    # Liberar mem√≥ria
    del train_loader, valid_loader
    gc.collect()
    
    # Preparar hist√≥rico de treinamento para exporta√ß√£o
    training_history = {
        'epoch': list(range(1, len(train_losses) + 1)),
        'train_loss': train_losses,
        'valid_loss': valid_losses,
        'train_accuracy': train_accuracies,
        'valid_accuracy': valid_accuracies
    }

    return model, full_dataset.classes, training_history

def plot_metrics(epochs, train_losses, valid_losses, train_accuracies, valid_accuracies):
    """
    Plota os gr√°ficos de perda e acur√°cia.
    """
    epochs_range = range(1, len(train_losses)+1)
    fig, ax = plt.subplots(1, 2, figsize=(14, 5))

    # Gr√°fico de Perda
    ax[0].plot(epochs_range, train_losses, label='Treino')
    ax[0].plot(epochs_range, valid_losses, label='Valida√ß√£o')
    ax[0].set_title('Perda por √âpoca')
    ax[0].set_xlabel('√âpocas')
    ax[0].set_ylabel('Perda')
    ax[0].legend()

    # Gr√°fico de Acur√°cia
    ax[1].plot(epochs_range, train_accuracies, label='Treino')
    ax[1].plot(epochs_range, valid_accuracies, label='Valida√ß√£o')
    ax[1].set_title('Acur√°cia por √âpoca')
    ax[1].set_xlabel('√âpocas')
    ax[1].set_ylabel('Acur√°cia')
    ax[1].legend()

    st.pyplot(fig)
    plt.close(fig)

def compute_metrics(model, dataloader, classes):
    """
    Calcula m√©tricas detalhadas e exibe matriz de confus√£o e relat√≥rio de classifica√ß√£o.
    """
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probabilities.cpu().numpy())

    # Relat√≥rio de Classifica√ß√£o
    report = classification_report(all_labels, all_preds, target_names=classes, output_dict=True, zero_division=0)
    st.text("Relat√≥rio de Classifica√ß√£o:")
    st.write(pd.DataFrame(report).transpose())

    # Matriz de Confus√£o Normalizada
    cm = confusion_matrix(all_labels, all_preds, normalize='true')
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes, ax=ax)
    ax.set_xlabel('Predito')
    ax.set_ylabel('Verdadeiro')
    ax.set_title('Matriz de Confus√£o Normalizada')
    st.pyplot(fig)
    plt.close(fig)

    # Curva ROC
    if len(classes) == 2:
        fpr, tpr, thresholds = roc_curve(all_labels, [p[1] for p in all_probs])
        roc_auc = roc_auc_score(all_labels, [p[1] for p in all_probs])
        fig, ax = plt.subplots()
        ax.plot(fpr, tpr, label='AUC = %0.2f' % roc_auc)
        ax.plot([0, 1], [0, 1], 'k--')
        ax.set_xlabel('Taxa de Falsos Positivos')
        ax.set_ylabel('Taxa de Verdadeiros Positivos')
        ax.set_title('Curva ROC')
        ax.legend(loc='lower right')
        st.pyplot(fig)
        plt.close(fig)
    else:
        # Multiclasse
        binarized_labels = label_binarize(all_labels, classes=range(len(classes)))
        roc_auc = roc_auc_score(binarized_labels, np.array(all_probs), average='weighted', multi_class='ovr')
        st.write(f"AUC-ROC M√©dia Ponderada: {roc_auc:.4f}")

def error_analysis(model, dataloader, classes):
    """
    Realiza an√°lise de erros mostrando algumas imagens mal classificadas.
    """
    model.eval()
    misclassified_images = []
    misclassified_labels = []
    misclassified_preds = []

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            incorrect = preds != labels
            if incorrect.any():
                misclassified_images.extend(inputs[incorrect].cpu())
                misclassified_labels.extend(labels[incorrect].cpu())
                misclassified_preds.extend(preds[incorrect].cpu())
                if len(misclassified_images) >= 5:
                    break

    if misclassified_images:
        st.write("Algumas imagens mal classificadas:")
        num_images = min(5, len(misclassified_images))
        fig, axes = plt.subplots(1, num_images, figsize=(15, 3))
        
        # Handle case when only one image (axes is not an array)
        if num_images == 1:
            axes = [axes]
            
        for i in range(num_images):
            image = misclassified_images[i]
            # Denormalize the image for proper display
            image = denormalize_image(image)
            axes[i].imshow(image)
            axes[i].set_title(f"V: {classes[misclassified_labels[i]]}\nP: {classes[misclassified_preds[i]]}")
            axes[i].axis('off')
        st.pyplot(fig)
        plt.close(fig)
    else:
        st.write("Nenhuma imagem mal classificada encontrada.")

def create_export_csv(training_history, classification_results=None, clustering_results=None):
    """
    Cria um DataFrame consolidado com todos os resultados para exporta√ß√£o CSV.
    
    Args:
        training_history: Dict com hist√≥rico de treinamento (epoch, losses, accuracies)
        classification_results: Dict opcional com resultados de classifica√ß√£o de imagens
        clustering_results: Dict opcional com resultados de clustering
    
    Returns:
        pd.DataFrame: DataFrame consolidado para exporta√ß√£o
    """
    # Criar DataFrame do hist√≥rico de treinamento
    df_training = pd.DataFrame(training_history)
    
    # Se houver resultados de classifica√ß√£o, adicionar
    if classification_results:
        df_classification = pd.DataFrame([classification_results])
        # Adicionar colunas vazias de treinamento para manter consist√™ncia
        for col in df_training.columns:
            if col not in df_classification.columns:
                df_classification[col] = None
        df_combined = pd.concat([df_training, df_classification], ignore_index=True)
    else:
        df_combined = df_training
    
    # Se houver resultados de clustering, adicionar
    if clustering_results:
        df_clustering = pd.DataFrame([clustering_results])
        for col in df_combined.columns:
            if col not in df_clustering.columns:
                df_clustering[col] = None
        df_combined = pd.concat([df_combined, df_clustering], ignore_index=True)
    
    return df_combined

def export_to_csv(df, filename="resultados_treinamento.csv"):
    """
    Converte DataFrame para CSV e retorna para download.
    
    Args:
        df: DataFrame para exportar
        filename: Nome do arquivo CSV
    
    Returns:
        str: CSV em formato de string
    """
    return df.to_csv(index=False).encode('utf-8')

def encode_image_to_base64(image):
    """
    Codifica uma imagem PIL para base64.
    
    Args:
        image: PIL Image
    
    Returns:
        str: Imagem codificada em base64
    """
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def optimize_image_for_api(image, max_size=(1024, 1024)):
    """
    Otimiza uma imagem PIL para envio √† API, reduzindo tamanho se necess√°rio.
    
    Args:
        image: PIL Image
        max_size: Tupla (largura, altura) do tamanho m√°ximo
    
    Returns:
        PIL Image otimizada
    """
    if image is None:
        return None
        
    # Se a imagem j√° est√° dentro do tamanho m√°ximo, retornar c√≥pia
    if image.size[0] <= max_size[0] and image.size[1] <= max_size[1]:
        return image.copy()
    
    # Redimensionar mantendo propor√ß√£o
    image_copy = image.copy()
    image_copy.thumbnail(max_size, Image.Resampling.LANCZOS)
    return image_copy

def retry_api_call(func, max_retries=3, initial_delay=2.0, backoff_factor=2.0):
    """
    Wrapper para tentar chamar uma fun√ß√£o de API com retry exponencial.
    Tenta extrair o retry_delay sugerido pela API quando dispon√≠vel.
    
    Args:
        func: Fun√ß√£o a ser executada (deve retornar tupla (sucesso, resultado))
        max_retries: N√∫mero m√°ximo de tentativas
        initial_delay: Atraso inicial em segundos
        backoff_factor: Fator multiplicativo para cada retry
    
    Returns:
        Resultado da fun√ß√£o ou mensagem de erro
    """
    delay = initial_delay
    last_error = None
    
    for attempt in range(max_retries):
        try:
            success, result = func()
            if success:
                return result
            # Se n√£o teve sucesso mas tamb√©m n√£o teve exce√ß√£o, n√£o retry
            return result
        except Exception as e:
            last_error = e
            error_str = str(e).lower()
            
            # Se for erro de quota/rate limit, tentar fazer retry
            if "429" in str(e) or "quota" in error_str or "rate limit" in error_str:
                if attempt < max_retries - 1:
                    # Tentar extrair o retry_delay sugerido pela API
                    suggested_delay = None
                    try:
                        # Procurar por "retry in XXs" ou "retry_delay { seconds: XX }"
                        match = re.search(r'retry in (\d+(?:\.\d+)?)s', str(e))
                        if match:
                            suggested_delay = float(match.group(1))
                        else:
                            match = re.search(r'seconds:\s*(\d+)', str(e))
                            if match:
                                suggested_delay = float(match.group(1))
                    except (ValueError, AttributeError):
                        # If parsing fails, continue with default delay
                        pass
                    
                    # Usar o delay sugerido se for razo√°vel (< 120s), sen√£o usar exponencial backoff
                    if suggested_delay and suggested_delay < 120:
                        actual_delay = min(suggested_delay, 60)  # Cap at 60s for user experience
                    else:
                        actual_delay = delay
                    
                    # Se o delay sugerido for muito longo, n√£o vale a pena retry
                    if suggested_delay and suggested_delay > 60:
                        # N√£o fazer retry, deixar o erro ser tratado pelo caller
                        raise e
                    
                    time.sleep(actual_delay)
                    delay *= backoff_factor
                    continue
            # Para outros erros, n√£o fazer retry
            raise e
    
    # Se esgotou tentativas
    if last_error:
        raise last_error
    return "Erro desconhecido ao tentar chamada de API"

def analyze_image_with_gemini(image, api_key, model_name, class_name, confidence, gradcam_description="", gradcam_image=None, max_retries=2):
    """
    Analisa uma imagem usando Google Gemini com vis√£o computacional.
    
    Args:
        image: PIL Image (imagem original)
        api_key: Chave API do Gemini
        model_name: Nome do modelo Gemini (deve suportar vis√£o)
        class_name: Classe predita pelo modelo
        confidence: Confian√ßa da predi√ß√£o
        gradcam_description: Descri√ß√£o textual do Grad-CAM
        gradcam_image: PIL Image com Grad-CAM sobreposto (opcional)
        max_retries: N√∫mero m√°ximo de tentativas em caso de rate limit
    
    Returns:
        str: An√°lise t√©cnica e forense da imagem
    """
    if not GEMINI_AVAILABLE:
        return "Google Generative AI n√£o est√° dispon√≠vel. Instale com: pip install google-generativeai"
    
    # Otimizar imagens antes de enviar (reduz custos e melhora performance)
    optimized_image = optimize_image_for_api(image, max_size=(1024, 1024))
    optimized_gradcam = optimize_image_for_api(gradcam_image, max_size=(1024, 1024)) if gradcam_image is not None else None
    
    # Construir prompt baseado na disponibilidade de Grad-CAM
    if optimized_gradcam is not None:
        prompt = f"""
Voc√™ √© um especialista em an√°lise de imagens e interpreta√ß√£o t√©cnica e forense.

**Contexto da Classifica√ß√£o:**
- Classe Predita: {class_name}
- Confian√ßa: {confidence:.4f} ({confidence*100:.2f}%)
- An√°lise Grad-CAM: {gradcam_description if gradcam_description else 'Veja a segunda imagem'}

**IMPORTANTE:** Voc√™ receber√° DUAS imagens:
1. **Primeira imagem**: A imagem ORIGINAL classificada
2. **Segunda imagem**: A mesma imagem com sobreposi√ß√£o de Grad-CAM (mapa de calor vermelho-amarelo)

O Grad-CAM (Gradient-weighted Class Activation Mapping) mostra onde a rede neural focou sua "aten√ß√£o" 
para fazer a classifica√ß√£o. Regi√µes em vermelho/amarelo indicam √°reas de alta import√¢ncia para a decis√£o.

Por favor, realize uma an√°lise COMPLETA e DETALHADA das DUAS imagens, incluindo:

1. **Descri√ß√£o Visual da Imagem Original:**
   - Descreva todos os elementos visuais presentes na imagem original
   - Identifique padr√µes, texturas, cores e formas relevantes
   - Analise a qualidade e caracter√≠sticas da imagem

2. **An√°lise do Grad-CAM (Segunda Imagem):**
   - Identifique quais regi√µes da imagem t√™m maior ativa√ß√£o (vermelho/amarelo intenso)
   - Descreva O QUE est√° presente nessas regi√µes de alta ativa√ß√£o
   - Avalie se essas regi√µes fazem sentido para a classifica√ß√£o como "{class_name}"
   - Compare: O modelo est√° focando nas caracter√≠sticas corretas?

3. **Interpreta√ß√£o T√©cnica Integrada:**
   - Avalie se a classifica√ß√£o como "{class_name}" √© compat√≠vel com o que voc√™ observa
   - Relacione as caracter√≠sticas visuais da imagem original com as regi√µes de ativa√ß√£o
   - Analise se a confian√ßa de {confidence*100:.2f}% √© justificada pelas regi√µes focadas
   - Identifique se h√° caracter√≠sticas importantes ignoradas pelo modelo

4. **An√°lise Forense:**
   - Identifique poss√≠veis artefatos ou anomalias nas imagens
   - Avalie a integridade e autenticidade da imagem
   - Verifique se o Grad-CAM est√° focando em artefatos em vez de caracter√≠sticas reais
   - Destaque √°reas de interesse ou preocupa√ß√£o

5. **Recomenda√ß√µes:**
   - Sugira se a classifica√ß√£o deve ser aceita ou revista
   - Baseie-se na correla√ß√£o entre caracter√≠sticas visuais e regi√µes de ativa√ß√£o
   - Recomende an√°lises adicionais se necess√°rio
   - Forne√ßa orienta√ß√µes para melhorar a confian√ßa na classifica√ß√£o

Seja detalhado, t√©cnico e preciso na sua an√°lise. Relacione SEMPRE os dois aspectos: 
o que voc√™ v√™ na imagem original e onde o modelo est√° focando no Grad-CAM.
"""
    else:
        prompt = f"""
Voc√™ √© um especialista em an√°lise de imagens e interpreta√ß√£o t√©cnica e forense.

**Contexto da Classifica√ß√£o:**
- Classe Predita: {class_name}
- Confian√ßa: {confidence:.4f} ({confidence*100:.2f}%)
- An√°lise Grad-CAM: {gradcam_description if gradcam_description else 'N√£o dispon√≠vel'}

Por favor, realize uma an√°lise COMPLETA e DETALHADA da imagem fornecida, incluindo:

1. **Descri√ß√£o Visual Detalhada:**
   - Descreva todos os elementos visuais presentes na imagem
   - Identifique padr√µes, texturas, cores e formas relevantes
   - Analise a qualidade e caracter√≠sticas da imagem

2. **Interpreta√ß√£o T√©cnica:**
   - Avalie se a classifica√ß√£o como "{class_name}" √© compat√≠vel com o que voc√™ observa
   - Identifique caracter√≠sticas espec√≠ficas que suportam ou contradizem a classifica√ß√£o
   - Analise a confian√ßa de {confidence*100:.2f}% em rela√ß√£o aos padr√µes visuais

3. **An√°lise Forense:**
   - Identifique poss√≠veis artefatos ou anomalias na imagem
   - Avalie a integridade e autenticidade da imagem
   - Destaque √°reas de interesse ou preocupa√ß√£o

4. **Recomenda√ß√µes:**
   - Sugira se a classifica√ß√£o deve ser aceita ou revista
   - Recomende an√°lises adicionais se necess√°rio
   - Forne√ßa orienta√ß√µes para melhorar a confian√ßa na classifica√ß√£o

Seja detalhado, t√©cnico e preciso na sua an√°lise.
"""
    
    # Fun√ß√£o interna para fazer a chamada da API
    def make_api_call():
        if GEMINI_NEW_API:
            # New beta google-genai package API
            client = genai.Client(api_key=api_key)
            
            # Convert PIL images to bytes
            img_byte_arr = io.BytesIO()
            optimized_image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()
            
            # Get correct model path for beta API
            model_path = get_gemini_model_path(model_name, use_new_api=True)
            
            # Build content list
            content_parts = [prompt, {"mime_type": "image/png", "data": img_byte_arr}]
            
            # Add Grad-CAM image if available
            if optimized_gradcam is not None:
                gradcam_byte_arr = io.BytesIO()
                optimized_gradcam.save(gradcam_byte_arr, format='PNG')
                gradcam_byte_arr = gradcam_byte_arr.getvalue()
                content_parts.append({"mime_type": "image/png", "data": gradcam_byte_arr})
            
            response = client.models.generate_content(
                model=model_path,
                contents=content_parts
            )
            return (True, response.text)
        else:
            # Stable google-generativeai package API (recommended)
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)
            
            # Build content list
            content_parts = [prompt, optimized_image]
            
            # Add Grad-CAM image if available
            if optimized_gradcam is not None:
                content_parts.append(optimized_gradcam)
            
            response = model.generate_content(content_parts)
            return (True, response.text)
    
    # Tentar fazer a chamada com retry
    try:
        return retry_api_call(make_api_call, max_retries=max_retries, initial_delay=2.0, backoff_factor=2.0)
    except Exception as e:
        error_msg = f"Erro ao analisar com Gemini: {str(e)}\n\n"
        error_type = str(e).lower()
        error_full = str(e)
        
        # Extract specific information from quota errors
        quota_info = {
            'retry_delay': None,
            'quota_metric': None,
            'model': model_name
        }
        
        # Try to parse retry delay
        match = re.search(r'retry in (\d+(?:\.\d+)?)s', error_full)
        if match:
            quota_info['retry_delay'] = float(match.group(1))
        else:
            match = re.search(r'seconds:\s*(\d+)', error_full)
            if match:
                quota_info['retry_delay'] = float(match.group(1))
        
        # Try to parse quota metric
        match = re.search(r'quota_metric:\s*"([^"]+)"', error_full)
        if match:
            quota_info['quota_metric'] = match.group(1)
        
        # Provide helpful guidance based on error type
        if "configure" in error_type:
            error_msg += (
                "üí° Dica: Parece que h√° um problema de configura√ß√£o da API.\n"
                "   Certifique-se de usar: pip install google-generativeai\n"
            )
        elif "404" in str(e) and "not found" in error_type:
            error_msg += (
                "üîç Modelo n√£o encontrado. Use os modelos atuais do Gemini API.\n"
                "   üìö Baseado no cookbook oficial: https://github.com/google-gemini/cookbook\n"
                "   \n"
                "   Modelos recomendados (todos com suporte multimodal/vis√£o):\n"
                "   - gemini-2.0-flash-exp ‚≠ê RECOMENDADO (√∫ltima vers√£o, gr√°tis)\n"
                "   - gemini-1.5-flash (r√°pido e eficiente)\n"
                "   - gemini-1.5-pro (avan√ßado com capacidade de racioc√≠nio)\n"
                "   \n"
                "   ‚ö†Ô∏è Modelos legados (1.0) n√£o s√£o mais recomendados\n"
            )
        elif "api key" in error_type or "401" in str(e) or "403" in str(e):
            error_msg += (
                "üîë Verifique se a API key est√° correta e ativa.\n"
                "   Obtenha sua API key em: https://ai.google.dev/\n"
            )
        elif "quota" in error_type or "rate limit" in error_type or "429" in str(e):
            error_msg += "‚è±Ô∏è **Limite de Quota Atingido**\n\n"
            
            # Specific information about the quota
            if "free_tier" in error_full:
                error_msg += "üìä **Tipo de Quota:** Free Tier (Gratuito)\n"
            
            if quota_info['quota_metric']:
                metric_name = quota_info['quota_metric'].split('/')[-1]
                error_msg += f"üìà **M√©trica Excedida:** {metric_name}\n"
            
            error_msg += f"üî¢ **Modelo Usado:** {quota_info['model']}\n"
            
            if quota_info['retry_delay']:
                minutes = int(quota_info['retry_delay'] / 60)
                seconds = int(quota_info['retry_delay'] % 60)
                if minutes > 0:
                    error_msg += f"‚è≥ **Tempo Sugerido de Espera:** {minutes}min {seconds}s\n"
                else:
                    error_msg += f"‚è≥ **Tempo Sugerido de Espera:** {seconds}s\n"
            
            error_msg += f"\nüîÑ **Tentativas Realizadas:** {max_retries}\n"
            error_msg += "\nüí° **Solu√ß√µes Recomendadas:**\n\n"
            error_msg += "**Op√ß√£o 1 - Usar An√°lise Multi-Agente (RECOMENDADO)** ‚ú®\n"
            error_msg += "   - N√£o requer API externa\n"
            error_msg += "   - Sistema com 15 especialistas virtuais\n"
            error_msg += "   - An√°lise completa e detalhada\n"
            error_msg += "   - Role para baixo e clique em 'Gerar An√°lise Multi-Especialista'\n\n"
            
            error_msg += "**Op√ß√£o 2 - Mudar de Modelo Gemini**\n"
            if "gemini-2.5-pro" in model_name or "gemini-1.5-pro" in model_name:
                error_msg += "   - Tente usar 'gemini-1.5-flash' (mais leve, quota maior)\n"
                error_msg += "   - Ou 'gemini-2.0-flash-exp' (vers√£o experimental gratuita)\n"
            else:
                error_msg += "   - Verifique modelos alternativos dispon√≠veis\n"
            error_msg += "   - Reconfigure na barra lateral\n\n"
            
            error_msg += "**Op√ß√£o 3 - Aguardar e Tentar Novamente**\n"
            if quota_info['retry_delay']:
                if quota_info['retry_delay'] < 120:
                    error_msg += f"   - Aguarde ~{int(quota_info['retry_delay'])}s e tente novamente\n"
                else:
                    error_msg += "   - Aguarde alguns minutos (quota di√°ria pode estar esgotada)\n"
            else:
                error_msg += "   - Aguarde 1-2 minutos e tente novamente\n"
            error_msg += "   - Verifique sua quota em: https://ai.google.dev/\n\n"
            
            error_msg += "**Op√ß√£o 4 - Upgrade do Plano**\n"
            error_msg += "   - Considere upgrade para aumentar limites\n"
            error_msg += "   - Veja detalhes em: https://ai.google.dev/pricing\n"
            
        elif "resource" in error_type and "exhausted" in error_type:
            error_msg += (
                "üí≥ Recursos/cr√©ditos esgotados. Verifique sua conta.\n"
            )
        else:
            error_msg += (
                "üìñ Consulte o guia: API_SETUP_GUIDE.md para mais detalhes.\n"
            )
        
        return error_msg

def analyze_image_with_groq_vision(image, api_key, model_name, class_name, confidence, gradcam_description=""):
    """
    Analisa uma imagem usando Groq com vis√£o computacional.
    Nota: Groq pode ter limita√ß√µes de vis√£o dependendo do modelo.
    
    Args:
        image: PIL Image
        api_key: Chave API do Groq
        model_name: Nome do modelo Groq
        class_name: Classe predita pelo modelo
        confidence: Confian√ßa da predi√ß√£o
        gradcam_description: Descri√ß√£o do Grad-CAM
    
    Returns:
        str: An√°lise t√©cnica e forense da imagem
    """
    if not GROQ_AVAILABLE:
        return "Groq n√£o est√° dispon√≠vel. Instale com: pip install groq"
    
    try:
        # Codificar imagem para base64
        image_base64 = encode_image_to_base64(image)
        
        client = Groq(api_key=api_key)
        
        prompt = f"""
        Voc√™ √© um especialista em an√°lise de imagens e interpreta√ß√£o t√©cnica e forense.
        
        **Contexto da Classifica√ß√£o:**
        - Classe Predita: {class_name}
        - Confian√ßa: {confidence:.4f} ({confidence*100:.2f}%)
        - An√°lise Grad-CAM: {gradcam_description if gradcam_description else 'N√£o dispon√≠vel'}
        
        IMPORTANTE: Com base nas informa√ß√µes fornecidas e na descri√ß√£o visual que voc√™ pode inferir,
        realize uma an√°lise COMPLETA e DETALHADA, incluindo:
        
        1. **Interpreta√ß√£o T√©cnica:**
           - Avalie se a classifica√ß√£o como "{class_name}" parece apropriada
           - Identifique caracter√≠sticas que voc√™ esperaria ver nesta classe
           - Analise a confian√ßa de {confidence*100:.2f}%
        
        2. **An√°lise Forense:**
           - Discuta poss√≠veis pontos de aten√ß√£o na classifica√ß√£o
           - Sugira √°reas que podem precisar de verifica√ß√£o adicional
        
        3. **Recomenda√ß√µes:**
           - Sugira se a classifica√ß√£o deve ser aceita ou revista
           - Recomende an√°lises adicionais se necess√°rio
           - Forne√ßa orienta√ß√µes para melhorar a confian√ßa
        
        Nota: Se o modelo n√£o suporta vis√£o direta, forne√ßa an√°lise baseada no contexto fornecido.
        """
        
        # Tentar com suporte de imagem (alguns modelos Groq podem n√£o suportar)
        try:
            chat_completion = client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}",
                                },
                            },
                        ],
                    }
                ],
                model=model_name,
            )
        except:
            # Fallback: an√°lise apenas com texto se vis√£o n√£o √© suportada
            chat_completion = client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": prompt + "\n\n[NOTA: An√°lise baseada apenas em contexto textual, pois o modelo pode n√£o suportar vis√£o direta]"
                    }
                ],
                model=model_name,
            )
        
        return chat_completion.choices[0].message.content
    
    except Exception as e:
        return f"Erro ao analisar com Groq: {str(e)}"

def generate_gradcam_description(activation_map):
    """
    Gera uma descri√ß√£o textual do mapa de ativa√ß√£o Grad-CAM.
    
    Args:
        activation_map: Mapa de ativa√ß√£o numpy array
    
    Returns:
        str: Descri√ß√£o das regi√µes ativadas
    """
    if activation_map is None:
        return "Grad-CAM n√£o dispon√≠vel"
    
    # Calcular estat√≠sticas do mapa de ativa√ß√£o
    mean_activation = np.mean(activation_map)
    max_activation = np.max(activation_map)
    
    # Encontrar regi√µes de alta ativa√ß√£o (acima de 70% do m√°ximo)
    threshold = 0.7 * max_activation
    high_activation_regions = activation_map > threshold
    num_high_regions = np.sum(high_activation_regions)
    total_pixels = activation_map.size
    percentage_high = (num_high_regions / total_pixels) * 100
    
    description = f"""
    O mapa Grad-CAM mostra:
    - Ativa√ß√£o m√©dia: {mean_activation:.3f}
    - Ativa√ß√£o m√°xima: {max_activation:.3f}
    - Regi√µes de alta ativa√ß√£o: {percentage_high:.1f}% da imagem
    - O modelo focou em {num_high_regions} pixels espec√≠ficos para tomar sua decis√£o
    """
    
    # Analisar distribui√ß√£o espacial
    height, width = activation_map.shape
    center_activation = activation_map[height//4:3*height//4, width//4:3*width//4].mean()
    border_activation = (activation_map[:height//4, :].mean() + 
                        activation_map[3*height//4:, :].mean() + 
                        activation_map[:, :width//4].mean() + 
                        activation_map[:, 3*width//4:].mean()) / 4
    
    if center_activation > border_activation * 1.5:
        description += "\n    - O modelo focou principalmente no CENTRO da imagem"
    elif border_activation > center_activation * 1.5:
        description += "\n    - O modelo focou principalmente nas BORDAS da imagem"
    else:
        description += "\n    - O modelo analisou a imagem de forma DISTRIBU√çDA"
    
    return description

def extract_features(dataset, model, batch_size):
    """
    Extrai caracter√≠sticas de um conjunto de dados usando um modelo pr√©-treinado.
    """
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker)

    features = []
    labels = []

    model.eval()
    with torch.no_grad():
        for inputs, lbls in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            outputs = outputs.view(outputs.size(0), -1)  # Flatten
            features.append(outputs.cpu().numpy())
            labels.extend(lbls.numpy())

    features = np.concatenate(features, axis=0)
    labels = np.array(labels)
    return features, labels

def perform_clustering(features, num_clusters):
    """
    Aplica algoritmos de clustering √†s caracter√≠sticas.
    """
    # Clustering Hier√°rquico
    hierarchical = AgglomerativeClustering(n_clusters=num_clusters)
    hierarchical_labels = hierarchical.fit_predict(features)

    # K-Means
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans_labels = kmeans.fit_predict(features)

    return hierarchical_labels, kmeans_labels

def evaluate_clustering(true_labels, cluster_labels, method_name):
    """
    Avalia os resultados do clustering comparando com as classes reais.
    """
    ari = adjusted_rand_score(true_labels, cluster_labels)
    nmi = normalized_mutual_info_score(true_labels, cluster_labels)
    st.write(f"**M√©tricas para {method_name}:**")
    st.write(f"Adjusted Rand Index: {ari:.4f}")
    st.write(f"Normalized Mutual Information Score: {nmi:.4f}")

def visualize_clusters(features, true_labels, hierarchical_labels, kmeans_labels, classes):
    """
    Visualiza os clusters usando redu√ß√£o de dimensionalidade e inclui as classes verdadeiras com nomes de r√≥tulos.
    """
    # Redu√ß√£o de dimensionalidade com PCA para visualizar os clusters em 2D
    pca = PCA(n_components=2)
    reduced_features = pca.fit_transform(features)

    # Mapear os r√≥tulos verdadeiros para os nomes das classes
    true_labels_named = [classes[label] for label in true_labels]
    
    # Usar as cores distintas e vis√≠veis para garantir que os clusters sejam claramente separados
    color_palette = sns.color_palette("tab10", len(set(true_labels)))

    fig, axes = plt.subplots(1, 3, figsize=(21, 6))  # Agora temos 3 gr√°ficos: Hierarchical, K-Means e classes verdadeiras

    # Clustering Hier√°rquico
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=hierarchical_labels, palette="deep", ax=axes[0], legend='full')
    axes[0].set_title('Clustering Hier√°rquico')
    ari_hierarchical = adjusted_rand_score(true_labels, hierarchical_labels)
    nmi_hierarchical = normalized_mutual_info_score(true_labels, hierarchical_labels)
    axes[0].text(0.1, 0.9, f"ARI: {ari_hierarchical:.2f}\nNMI: {nmi_hierarchical:.2f}", horizontalalignment='center', verticalalignment='center', transform=axes[0].transAxes, bbox=dict(facecolor='white', alpha=0.5))

    # K-Means Clustering
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=kmeans_labels, palette="deep", ax=axes[1], legend='full')
    axes[1].set_title('K-Means Clustering')
    ari_kmeans = adjusted_rand_score(true_labels, kmeans_labels)
    nmi_kmeans = normalized_mutual_info_score(true_labels, kmeans_labels)
    axes[1].text(0.1, 0.9, f"ARI: {ari_kmeans:.2f}\nNMI: {nmi_kmeans:.2f}", horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes, bbox=dict(facecolor='white', alpha=0.5))

    # Classes verdadeiras
    sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue=true_labels_named, palette=color_palette, ax=axes[2], legend='full')
    axes[2].set_title('Classes Verdadeiras')

    # Exibir os gr√°ficos
    st.pyplot(fig)
    plt.close(fig)

def evaluate_image(model, image, classes):
    """
    Avalia uma √∫nica imagem e retorna a classe predita e a confian√ßa.
    """
    model.eval()
    image_tensor = test_transforms(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
        class_idx = predicted.item()
        class_name = classes[class_idx]
        return class_name, confidence.item()

def evaluate_image_with_statistics(model, image, classes, activation_map=None, n_bootstrap=100):
    """
    Avalia uma imagem com an√°lise estat√≠stica completa.
    
    Args:
        model: Modelo treinado
        image: Imagem PIL
        classes: Lista de nomes das classes
        activation_map: Mapa de ativa√ß√£o do Grad-CAM (opcional)
        n_bootstrap: N√∫mero de itera√ß√µes para bootstrap
    
    Returns:
        Dict com an√°lise completa incluindo estat√≠sticas e diagn√≥sticos
    """
    model.eval()
    
    # Ensure model parameters don't require gradients (in case Grad-CAM left them enabled)
    for param in model.parameters():
        param.requires_grad = False
    
    image_tensor = test_transforms(image).unsqueeze(0).to(device)
    
    # 1. Predi√ß√£o b√°sica
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        probs_array = probabilities.cpu().numpy()[0]
        confidence, predicted = torch.max(probabilities, 1)
        class_idx = predicted.item()
        class_name = classes[class_idx]
    
    # 2. Bootstrap validation
    stat_analyzer = StatisticalAnalyzer()
    bootstrap_results = stat_analyzer.bootstrap_validation(model, image_tensor, n_bootstrap)
    
    # 3. Confidence intervals
    confidence_interval = stat_analyzer.calculate_confidence_interval(
        bootstrap_results['predictions_distribution'][:, class_idx]
    )
    
    # 4. Differential diagnostics
    diag_analyzer = DiagnosticAnalyzer()
    differential_diagnoses = diag_analyzer.differential_diagnosis(
        bootstrap_results['mean_probabilities'], 
        classes, 
        top_k=5
    )
    
    # 5. Exclusion criteria
    exclusion_analysis = diag_analyzer.exclusion_criteria(
        bootstrap_results['mean_probabilities'], 
        classes
    )
    
    # 6. Distinctive features (se houver activation map)
    distinctive_features = None
    if activation_map is not None:
        distinctive_features = diag_analyzer.distinctive_features(activation_map)
    
    # 7. Uncertainty quantification
    uncertainty_analyzer = UncertaintyAnalyzer()
    uncertainty_analysis = uncertainty_analyzer.quantify_uncertainty(bootstrap_results)
    
    # 8. Error impact assessment
    error_impact = uncertainty_analyzer.assess_error_impact(
        bootstrap_results['mean_probabilities'],
        classes
    )
    
    # 9. Safety margin
    safety_analysis = uncertainty_analyzer.safety_margin(
        confidence.item(),
        min_acceptable=0.7,
        target=0.9
    )
    
    # 10. Clinical/practical impact
    clinical_impact = uncertainty_analyzer.clinical_impact_assessment(
        confidence.item(),
        class_name,
        differential_diagnoses
    )
    
    # 11. Significance test (se houver diagn√≥sticos diferenciais)
    significance_test = None
    if len(differential_diagnoses) >= 2:
        significance_test = stat_analyzer.significance_test(
            differential_diagnoses[0]['probability'],
            differential_diagnoses[1]['probability'],
            bootstrap_results['predictions_distribution']
        )
    
    return {
        # B√°sico
        'predicted_class': class_name,
        'predicted_index': class_idx,
        'confidence': confidence.item(),
        'all_probabilities': probs_array,
        
        # Estat√≠sticas
        'confidence_interval': confidence_interval,
        'bootstrap_results': bootstrap_results,
        'significance_test': significance_test,
        
        # Diagn√≥stico
        'differential_diagnoses': differential_diagnoses,
        'exclusion_analysis': exclusion_analysis,
        'distinctive_features': distinctive_features,
        
        # Incerteza e Risco
        'uncertainty_analysis': uncertainty_analysis,
        'error_impact': error_impact,
        'safety_analysis': safety_analysis,
        'clinical_impact': clinical_impact
    }

#________________________________________________

#________________________________________________

def display_statistical_analysis(analysis_results):
    """
    Exibe an√°lise estat√≠stica completa em formato organizado e acess√≠vel no Streamlit.
    Apresenta√ß√£o adaptada para p√∫blico leigo com explica√ß√µes contextualizadas.
    
    Args:
        analysis_results: Resultados da fun√ß√£o evaluate_image_with_statistics
    """
    st.write("---")
    st.write("## üìä AN√ÅLISE ESTAT√çSTICA COMPLETA")
    st.info("üí° **O que √© isso?** Esta an√°lise mostra o resultado da classifica√ß√£o da imagem e " +
            "o grau de certeza do sistema sobre essa classifica√ß√£o. Quanto maior a certeza, " +
            "mais confi√°vel √© o resultado.")
    
    # ========== PREDI√á√ÉO PRINCIPAL ==========
    st.write("### üéØ Resultado da An√°lise")
    st.write("**O que a intelig√™ncia artificial identificou na sua imagem:**")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Classifica√ß√£o Identificada", analysis_results['predicted_class'])
        st.caption("Esta √© a categoria que o sistema identificou")
    with col2:
        confidence_pct = analysis_results['confidence']
        st.metric("N√≠vel de Certeza", f"{confidence_pct:.2%}")
        if confidence_pct >= 0.90:
            st.caption("‚úÖ Certeza muito alta")
        elif confidence_pct >= 0.70:
            st.caption("‚ö†Ô∏è Certeza moderada")
        else:
            st.caption("‚ö†Ô∏è Certeza baixa - requer aten√ß√£o")
    with col3:
        safety_emoji = {
            'safe': 'üü¢',
            'unsafe': 'üî¥'
        }[analysis_results['safety_analysis']['status']]
        safety_status = 'SEGURO' if analysis_results['safety_analysis']['status'] == 'safe' else 'REQUER ATEN√á√ÉO'
        st.metric("Avalia√ß√£o de Confiabilidade", 
                 f"{safety_emoji} {safety_status}")
        st.caption("Indica se o resultado √© confi√°vel o suficiente")
    
    # ========== INTERVALOS DE CONFIAN√áA ==========
    st.write("---")
    st.write("### üìà An√°lise de Confiabilidade (Intervalo de Confian√ßa)")
    st.write("**O que significa?** O sistema testou a classifica√ß√£o v√°rias vezes para verificar " +
             "se o resultado √© consistente. Isso nos d√° uma faixa de valores onde a certeza real " +
             "provavelmente est√°.")
    
    ci = analysis_results['confidence_interval']
    st.write(f"**Certeza M√©dia (ap√≥s m√∫ltiplos testes):** {ci['mean']:.2%}")
    st.write(f"**Faixa de Confian√ßa (95%):** entre {ci['lower']:.2%} e {ci['upper']:.2%}")
    st.write(f"**Margem de Varia√ß√£o:** ¬±{ci['margin_error']:.2%}")
    
    # Progress bar visual (convert to Python float for Streamlit compatibility)
    st.progress(float(ci['mean']))
    
    # Explica√ß√£o adicional
    with st.expander("üìñ Entenda melhor este resultado"):
        st.write("""
        **Como interpretar:**
        - Se a faixa √© estreita (pequena diferen√ßa entre o menor e maior valor): o resultado √© mais est√°vel e confi√°vel
        - Se a faixa √© ampla: h√° mais incerteza e o resultado pode variar
        - A margem de varia√ß√£o mostra o quanto o resultado pode "oscilar" para mais ou para menos
        
        **Exemplo pr√°tico:** Se a certeza est√° em 65% com margem de ¬±4%, isso significa que 
        o resultado real provavelmente est√° entre 61% e 69%.
        """)
    
    # ========== DIAGN√ìSTICOS DIFERENCIAIS ==========
    st.write("---")
    st.write("### üîç Possibilidades Alternativas (Diagn√≥sticos Diferenciais)")
    st.write("**O que significa?** Al√©m da classifica√ß√£o principal, o sistema identifica outras " +
             "possibilidades que a imagem poderia representar, ordenadas por probabilidade.")
    
    diff_data = []
    for diff in analysis_results['differential_diagnoses']:
        diff_data.append({
            'Posi√ß√£o': diff['rank'],
            'Categoria': diff['class'],
            'Probabilidade': f"{diff['probability']:.2%}",
            'N√≠vel de Certeza': diff['confidence_level']
        })
    
    if diff_data:
        st.dataframe(pd.DataFrame(diff_data), width='stretch')
        st.caption("üí° A primeira linha √© a classifica√ß√£o mais prov√°vel, as demais s√£o alternativas em ordem decrescente de probabilidade")
    
    # Teste de signific√¢ncia
    if analysis_results['significance_test'] and analysis_results['significance_test']['p_value']:
        st.write("#### üìä Compara√ß√£o entre as Duas Principais Possibilidades")
        sig_test = analysis_results['significance_test']
        st.write(f"**Diferen√ßa de Probabilidade:** {sig_test['probability_diff']:.2%}")
        st.write(f"**Valor-p (teste estat√≠stico):** {sig_test['p_value']:.4f}")
        
        with st.expander("üìñ O que √© o valor-p?"):
            st.write("""
            O **valor-p** √© uma medida estat√≠stica que nos ajuda a determinar se a diferen√ßa 
            entre duas op√ß√µes √© significativa (importante) ou se pode ter ocorrido por acaso.
            
            **Regra pr√°tica:**
            - Valor-p < 0.05: A diferen√ßa √© **significativa** - h√° uma diferen√ßa real entre as duas op√ß√µes
            - Valor-p ‚â• 0.05: A diferen√ßa **n√£o √© significativa** - as duas op√ß√µes s√£o muito parecidas
            
            **Neste caso:** {}
            """.format(
                "As duas principais possibilidades s√£o **estatisticamente diferentes**, " +
                "ou seja, h√° uma clara vantagem da primeira op√ß√£o sobre a segunda." 
                if sig_test['significant'] 
                else "As duas principais possibilidades s√£o **muito semelhantes**, " +
                "o que indica que o sistema teve dificuldade em distinguir entre elas. " +
                "Recomenda-se cautela e possivelmente uma an√°lise adicional."
            ))
        
        if sig_test['significant']:
            st.success(f"‚úÖ {sig_test['interpretation']} (p < 0.05) - H√° diferen√ßa clara entre as op√ß√µes")
        else:
            st.warning(f"‚ö†Ô∏è {sig_test['interpretation']} (p ‚â• 0.05) - As op√ß√µes s√£o muito similares, dif√≠cil distinguir")
    
    # ========== CRIT√âRIOS DE EXCLUS√ÉO ==========
    st.write("---")
    st.write("### ‚ùå Categorias Descartadas (Crit√©rios de Exclus√£o)")
    st.write("**O que significa?** O sistema identificou categorias que t√™m probabilidade muito baixa " +
             "de serem a resposta correta e as descartou da an√°lise.")
    
    excl = analysis_results['exclusion_analysis']
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Categorias Descartadas", excl['excluded_count'])
        st.caption("Op√ß√µes com probabilidade muito baixa")
    with col2:
        st.metric("Categorias Consideradas", excl['remaining_count'])
        st.caption("Op√ß√µes ainda em an√°lise")
    
    if excl['excluded_classes']:
        with st.expander("Ver categorias descartadas (probabilidade muito baixa)"):
            st.write("Estas categorias foram descartadas porque a probabilidade era muito pequena:")
            for exc in excl['excluded_classes'][:5]:  # Mostrar at√© 5
                st.write(f"- **{exc['class']}**: {exc['reason']}")
    
    # ========== CARACTER√çSTICAS DISTINTIVAS ==========
    if analysis_results['distinctive_features']:
        st.write("---")
        st.write("### üé® Regi√µes Importantes da Imagem (Caracter√≠sticas Distintivas)")
        st.write("**O que significa?** O sistema analisa quais partes da imagem foram mais importantes " +
                 "para tomar a decis√£o de classifica√ß√£o.")
        
        feat = analysis_results['distinctive_features']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Ativa√ß√£o M√°xima", f"{feat['max_activation']:.3f}")
            st.caption("Intensidade m√°xima nas √°reas analisadas")
        with col2:
            st.metric("Ativa√ß√£o M√©dia", f"{feat['mean_activation']:.3f}")
            st.caption("Intensidade m√©dia geral")
        with col3:
            st.metric("√Årea de Alta Relev√¢ncia", f"{feat['high_activation_percentage']:.1f}%")
            st.caption("Porcentagem da imagem considerada importante")
        
        st.info(f"**Interpreta√ß√£o:** {feat['interpretation']}")
        
        with st.expander("üìñ Como interpretar estes valores"):
            st.write("""
            **√Åreas de ativa√ß√£o** mostram onde o sistema "prestou mais aten√ß√£o" na imagem:
            
            - **Alta ativa√ß√£o em √°rea pequena** (< 15%): O sistema focou em detalhes espec√≠ficos
            - **Alta ativa√ß√£o em √°rea m√©dia** (15-30%): An√°lise equilibrada de v√°rias caracter√≠sticas
            - **Alta ativa√ß√£o em √°rea grande** (> 30%): O sistema considerou muitas partes da imagem
            
            Valores mais altos de ativa√ß√£o indicam regi√µes que tiveram maior peso na decis√£o.
            """)
    
    # ========== AN√ÅLISE DE INCERTEZA ==========
    st.write("---")
    st.write("### üé≤ Medi√ß√£o da Incerteza (Quantifica√ß√£o de Incerteza)")
    st.write("**O que significa?** Esta an√°lise mostra o quanto o sistema est√° incerto sobre o resultado. " +
             "Maior incerteza significa que o resultado pode ser menos confi√°vel.")
    
    uncert = analysis_results['uncertainty_analysis']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("N√≠vel de Incerteza", uncert['uncertainty_level'])
        st.caption("Classifica√ß√£o geral da incerteza")
    with col2:
        st.metric("Incerteza Total", f"{uncert['total_uncertainty']:.3f}")
        st.caption("Valor combinado de todas as fontes")
    with col3:
        st.metric("Entropia Normalizada", f"{uncert['normalized_entropy']:.3f}")
        st.caption("Medida de dispers√£o das probabilidades")
    
    st.write("**Fontes de Incerteza (de onde vem a d√∫vida):**")
    st.write(f"- **Varia√ß√£o do Modelo:** {uncert['sources']['model_variation']:.3f} " +
             "(quanto o resultado varia entre m√∫ltiplas an√°lises)")
    st.write(f"- **Ambiguidade da Predi√ß√£o:** {uncert['sources']['prediction_ambiguity']:.3f} " +
             "(quanto as probabilidades est√£o distribu√≠das entre v√°rias op√ß√µes)")
    
    with st.expander("üìñ Entenda a incerteza"):
        st.write("""
        **N√≠veis de Incerteza:**
        - **Muito Baixa/Baixa**: O sistema est√° bastante confiante no resultado
        - **Moderada**: H√° alguma d√∫vida, mas o resultado ainda √© √∫til
        - **Alta/Muito Alta**: O sistema tem muita d√∫vida - cuidado ao usar este resultado
        
        **Fontes:**
        - **Varia√ß√£o do Modelo**: Se o modelo d√° resultados diferentes ao analisar a mesma imagem v√°rias vezes
        - **Ambiguidade**: Se v√°rias categorias t√™m probabilidades semelhantes, criando d√∫vida
        """)
    
    # ========== IMPACTO DE ERROS ==========
    st.write("---")
    st.write("### ‚ö†Ô∏è Risco de Erro (Avalia√ß√£o de Impacto de Erros)")
    st.write("**O que significa?** Esta an√°lise estima a probabilidade de o resultado estar errado " +
             "e qual seria o impacto de um poss√≠vel erro.")
    
    error_imp = analysis_results['error_impact']
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Probabilidade de Erro", f"{error_imp['error_probability']:.2%}")
        st.caption("Chance de a classifica√ß√£o estar incorreta")
    with col2:
        st.metric("√çndice de Impacto", f"{error_imp['impact_score']:.3f}")
        st.caption("Gravidade de um poss√≠vel erro")
    
    # Mostrar recomenda√ß√£o com cor apropriada
    if '‚ö†Ô∏è ATEN√á√ÉO' in error_imp['recommendation']:
        st.error(error_imp['recommendation'])
    elif '‚ö†Ô∏è' in error_imp['recommendation']:
        st.warning(error_imp['recommendation'])
    else:
        st.success(error_imp['recommendation'])
    
    # ========== MARGEM DE SEGURAN√áA ==========
    st.write("---")
    st.write("### üõ°Ô∏è An√°lise de Seguran√ßa (Margem de Seguran√ßa)")
    st.write("**O que significa?** Esta an√°lise compara a certeza obtida com os n√≠veis m√≠nimos " +
             "considerados seguros para uso pr√°tico do resultado.")
    
    safety = analysis_results['safety_analysis']
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Certeza Atual", f"{safety['confidence']:.2%}")
        st.caption("Confian√ßa obtida nesta an√°lise")
    with col2:
        st.metric("M√≠nimo Aceit√°vel", f"{safety['min_acceptable']:.2%}")
        st.caption("Limite m√≠nimo recomendado")
    with col3:
        st.metric("Alvo Desejado", f"{safety['target']:.2%}")
        st.caption("Valor ideal de confian√ßa")
    with col4:
        st.metric("√çndice de Seguran√ßa", f"{safety['safety_score']:.2%}")
        st.caption("Pontua√ß√£o geral de seguran√ßa")
    
    st.write(f"**Dist√¢ncia do M√≠nimo:** {safety['margin_to_minimum']:.2%} " +
             f"({'acima' if safety['margin_to_minimum'] > 0 else 'abaixo'} do limite)")
    st.write(f"**Dist√¢ncia do Alvo:** {safety['margin_to_target']:.2%} para alcan√ßar o ideal")
    
    # Interpreta√ß√£o com emoji e cores
    if 'üî¥' in safety['interpretation']:
        st.error(safety['interpretation'])
    elif 'üü°' in safety['interpretation']:
        st.warning(safety['interpretation'])
    else:
        st.success(safety['interpretation'])
    
    with st.expander("üìñ Como interpretar a seguran√ßa"):
        st.write("""
        **N√≠veis de Seguran√ßa:**
        - üü¢ **Verde (acima do alvo)**: Resultado muito confi√°vel - pode ser usado com seguran√ßa
        - üü¢ **Verde (acima do m√≠nimo)**: Resultado aceit√°vel - pode ser usado com precau√ß√£o
        - üü° **Amarelo**: Resultado pr√≥ximo ao limite - usar com extrema cautela
        - üî¥ **Vermelho**: Resultado abaixo do aceit√°vel - N√ÉO recomendado para uso sem an√°lise adicional
        
        **Recomenda√ß√£o:** Sempre busque resultados com certeza acima de 70% para aplica√ß√µes pr√°ticas.
        Para decis√µes importantes, prefira resultados acima de 90%.
        """)
    
    # ========== IMPACTO CL√çNICO/PR√ÅTICO ==========
    st.write("---")
    st.write("### üè• Impacto Pr√°tico do Resultado (Avalia√ß√£o Cl√≠nica/Pr√°tica)")
    st.write("**O que significa?** Esta se√ß√£o avalia o que fazer com o resultado obtido e " +
             "qual o n√≠vel de urg√™ncia ou import√¢ncia da classifica√ß√£o.")
    
    clinical = analysis_results['clinical_impact']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Classifica√ß√£o Principal", clinical['primary_diagnosis'])
        st.caption("Resultado mais prov√°vel")
    with col2:
        priority_color = {
            'Normal': 'üü¢',
            'M√©dia': 'üü°',
            'Alta': 'üî¥'
        }[clinical['priority_level']]
        st.metric("N√≠vel de Prioridade", f"{priority_color} {clinical['priority_level']}")
        st.caption("Urg√™ncia da a√ß√£o necess√°ria")
    with col3:
        st.metric("N√≠vel de Ambiguidade", f"{clinical['diagnostic_ambiguity']:.2%}")
        st.caption("Quanto as op√ß√µes se confundem")
    
    st.write(f"**üìã O que fazer agora:** {clinical['recommended_action']}")
    st.write(f"**üîç Outras possibilidades analisadas:** {clinical['differential_count']}")
    
    if clinical['requires_specialist']:
        st.warning("‚öïÔ∏è **Recomenda√ß√£o:** Consulta com especialista recomendada devido √† complexidade " +
                  "do caso ou n√≠vel de incerteza elevado")
    else:
        st.success("‚úÖ **Situa√ß√£o:** Este caso pode ser tratado seguindo protocolos padr√£o, " +
                  "sem necessidade imediata de consulta especializada")
    
    with st.expander("üìñ Entenda a prioridade e recomenda√ß√µes"):
        st.write("""
        **N√≠veis de Prioridade:**
        - üü¢ **Normal**: Situa√ß√£o est√°vel, seguir acompanhamento de rotina
        - üü° **M√©dia**: Requer aten√ß√£o moderada, acompanhar mais de perto
        - üî¥ **Alta**: Situa√ß√£o que requer aten√ß√£o urgente ou an√°lise mais detalhada
        
        **Ambiguidade Diagn√≥stica:**
        - Baixa (< 30%): As op√ß√µes s√£o bem distintas, decis√£o mais clara
        - Moderada (30-70%): H√° alguma sobreposi√ß√£o entre op√ß√µes
        - Alta (> 70%): As op√ß√µes s√£o muito similares, dif√≠cil distin√ß√£o
        
        **Quando procurar um especialista:**
        - Ambiguidade alta (> 70%)
        - Certeza baixa (< 75%)
        - M√∫ltiplas possibilidades com probabilidades semelhantes
        - Quando h√° implica√ß√µes importantes da decis√£o
        """)
    
    # ========== VALIDA√á√ÉO BOOTSTRAP ==========
    with st.expander("üìä Detalhes T√©cnicos - Valida√ß√£o Bootstrap (Para Usu√°rios Avan√ßados)"):
        st.write("**O que √© Bootstrap?** √â um m√©todo estat√≠stico que testa o resultado m√∫ltiplas " +
                 "vezes para verificar sua estabilidade. Quanto menor a varia√ß√£o, mais confi√°vel o resultado.")
        
        boot = analysis_results['bootstrap_results']
        st.write(f"**Certeza M√©dia (Bootstrap):** {boot['confidence_bootstrap']:.2%}")
        st.write(f"**Varia√ß√£o (Desvio Padr√£o):** {boot['uncertainty']:.4f}")
        st.caption("üí° Varia√ß√£o baixa (< 0.10) indica resultado est√°vel; alta (> 0.20) indica instabilidade")
        
        st.write("---")
        st.write("**Probabilidades M√©dias por Categoria:**")
        # Create proper dataframe for all classes
        all_classes = list(range(len(boot['mean_probabilities'])))
        prob_df = pd.DataFrame({
            '√çndice da Categoria': all_classes,
            'Probabilidade M√©dia': [f"{p:.2%}" for p in boot['mean_probabilities']],
            'Desvio Padr√£o': [f"{s:.4f}" for s in boot['std_probabilities']]
        })
        st.dataframe(prob_df.head(10), width='stretch')  # Mostrar top 10
        st.caption("As 10 categorias com maiores probabilidades")
    
    # ========== RESUMO FINAL PARA LEIGOS ==========
    st.write("---")
    st.write("## üìù RESUMO FINAL EM LINGUAGEM SIMPLES")
    st.write("### O que voc√™ precisa saber sobre este resultado:")
    
    # Criar resumo baseado nos dados da an√°lise
    confidence = analysis_results['confidence']
    predicted = analysis_results['predicted_class']
    safety_status = analysis_results['safety_analysis']['status']
    uncertainty_level = analysis_results['uncertainty_analysis']['uncertainty_level']
    error_prob = analysis_results['error_impact']['error_probability']
    
    st.write(f"**1. Resultado Principal:**")
    st.write(f"   - A imagem foi classificada como: **{predicted}**")
    st.write(f"   - N√≠vel de certeza: **{confidence:.2%}**")
    
    st.write(f"\n**2. Confiabilidade:**")
    if safety_status == 'safe' and confidence >= 0.75:
        st.success("   ‚úÖ Este resultado √© considerado **CONFI√ÅVEL** para uso.")
    elif safety_status == 'safe' or confidence >= 0.60:
        st.warning("   ‚ö†Ô∏è Este resultado √© **ACEIT√ÅVEL**, mas use com **PRECAU√á√ÉO**.")
    else:
        st.error("   ‚ö†Ô∏è Este resultado tem **BAIXA CONFIABILIDADE** - requer an√°lise adicional.")
    
    st.write(f"\n**3. N√≠vel de Incerteza:**")
    st.write(f"   - Classifica√ß√£o: **{uncertainty_level}**")
    if uncertainty_level in ['Muito Baixa', 'Baixa']:
        st.write("   - Significa: O sistema est√° bastante seguro do resultado")
    elif uncertainty_level == 'Moderada':
        st.write("   - Significa: H√° alguma d√∫vida, mas o resultado ainda √© √∫til")
    else:
        st.write("   - Significa: O sistema tem d√∫vidas significativas sobre o resultado")
    
    st.write(f"\n**4. Probabilidade de Erro:**")
    st.write(f"   - Chance de estar errado: **{error_prob:.2%}**")
    if error_prob < 0.20:
        st.write("   - Interpreta√ß√£o: Chance baixa de erro")
    elif error_prob < 0.40:
        st.write("   - Interpreta√ß√£o: Chance moderada de erro - aten√ß√£o necess√°ria")
    else:
        st.write("   - Interpreta√ß√£o: Chance alta de erro - cuidado!")
    
    st.write(f"\n**5. Recomenda√ß√£o Final:**")
    requires_specialist = analysis_results['clinical_impact']['requires_specialist']
    recommended_action = analysis_results['clinical_impact']['recommended_action']
    
    if requires_specialist:
        st.warning(f"   ‚öïÔ∏è **Consultar especialista:** Sim, recomendado")
        st.write(f"   - Motivo: {recommended_action}")
    else:
        st.success(f"   ‚úÖ **Consultar especialista:** N√£o √© urgente")
        st.write(f"   - A√ß√£o sugerida: {recommended_action}")
    
    # Adicionar gloss√°rio r√°pido
    with st.expander("üìñ Gloss√°rio - Entenda os Termos T√©cnicos"):
        st.write("""
        **Termos que voc√™ pode ter visto neste relat√≥rio:**
        
        - **Bootstrap/Valida√ß√£o Bootstrap**: M√©todo estat√≠stico que repete a an√°lise m√∫ltiplas vezes para verificar se o resultado √© est√°vel
        - **Confian√ßa/Certeza**: O quanto o sistema est√° seguro de que a classifica√ß√£o est√° correta (em porcentagem)
        - **Diagn√≥stico Diferencial**: Outras poss√≠veis classifica√ß√µes que a imagem poderia ter
        - **Entropia**: Medida de incerteza ou "desordem" - quanto maior, mais incerta √© a classifica√ß√£o
        - **Intervalo de Confian√ßa**: Faixa de valores onde o resultado verdadeiro provavelmente est√°
        - **Margem de Erro**: Quanto o valor pode variar para mais ou para menos
        - **Probabilidade**: Chance de algo ser verdade, expressa em porcentagem (0% a 100%)
        - **Signific√¢ncia Estat√≠stica**: Se uma diferen√ßa √© real ou pode ter ocorrido por acaso
        - **Valor-p**: N√∫mero que indica se uma diferen√ßa √© estatisticamente significativa (< 0.05 = significativa)
        
        **Formato ABNT (Normas Brasileiras):**
        Este relat√≥rio segue as diretrizes da Associa√ß√£o Brasileira de Normas T√©cnicas (ABNT) 
        para apresenta√ß√£o de an√°lises cient√≠ficas, garantindo qualidade acad√™mica n√≠vel A1 
        (mais alto n√≠vel de qualidade acad√™mica no Brasil).
        """)

def visualize_activations(model, image, class_names, gradcam_type='SmoothGradCAMpp'):
    """
    Visualiza as ativa√ß√µes na imagem usando diferentes variantes de Grad-CAM.
    
    Args:
        model: Modelo treinado
        image: Imagem PIL
        class_names: Lista de nomes das classes
        gradcam_type: Tipo de Grad-CAM ('GradCAM', 'GradCAMpp', 'SmoothGradCAMpp', 'LayerCAM')
    
    Returns:
        tuple: (activation_map_resized, gradcam_image_pil) onde:
            - activation_map_resized: Mapa de ativa√ß√£o normalizado ou None em caso de erro
            - gradcam_image_pil: Imagem PIL com Grad-CAM sobreposto ou None
    """
    cam_extractor = None
    original_training_mode = model.training
    try:
        # Set model to eval mode but enable gradient computation
        model.eval()
        
        # Enable gradients for all model parameters temporarily
        # This is needed for hook registration in torchcam
        for param in model.parameters():
            param.requires_grad = True
        
        # Prepare input tensor with gradient enabled
        # torchcam requires gradients to be enabled for hook registration
        input_tensor = test_transforms(image).unsqueeze(0).to(device)
        input_tensor.requires_grad = True
        
        # Verificar se o modelo √© suportado
        model_type = type(model).__name__
        if 'ResNet' in model_type:
            target_layer = model.layer4[-1]
        elif 'DenseNet' in model_type:
            target_layer = model.features.denseblock4.denselayer16
        elif 'VisionTransformer' in model_type:
            # Para ViT, usar a √∫ltima camada do encoder
            target_layer = model.encoder.layers[-1].ln_1
        else:
            st.warning(f"Modelo {model_type} pode n√£o ter suporte completo para Grad-CAM. Tentando com camada padr√£o...")
            # Tentar usar a √∫ltima camada dispon√≠vel
            try:
                if hasattr(model, 'encoder'):
                    target_layer = model.encoder.layers[-1]
                else:
                    st.error("N√£o foi poss√≠vel determinar camada para Grad-CAM.")
                    return None
            except:
                st.error("Modelo n√£o suportado para Grad-CAM.")
                return None
        
        # Criar o objeto CAM usando torchcam
        if gradcam_type == 'GradCAM':
            cam_extractor = GradCAM(model, target_layer=target_layer)
        elif gradcam_type == 'GradCAMpp':
            cam_extractor = GradCAMpp(model, target_layer=target_layer)
        elif gradcam_type == 'SmoothGradCAMpp':
            cam_extractor = SmoothGradCAMpp(model, target_layer=target_layer)
        elif gradcam_type == 'LayerCAM':
            cam_extractor = LayerCAM(model, target_layer=target_layer)
        else:
            st.error(f"Tipo de Grad-CAM n√£o suportado: {gradcam_type}")
            return None
        
        # Habilitar gradientes explicitamente
        with torch.set_grad_enabled(True):
            out = model(input_tensor)  # Faz a previs√£o
            _, pred = torch.max(out, 1)  # Obt√©m a classe predita
            pred_class = pred.item()
        
        # Gerar o mapa de ativa√ß√£o
        activation_map = cam_extractor(pred_class, out)
        
        # Obter o mapa de ativa√ß√£o da primeira imagem no lote
        activation_map = activation_map[0].cpu().detach().numpy()
        
        # Redimensionar o mapa de ativa√ß√£o para coincidir com o tamanho da imagem original
        activation_map_resized = cv2.resize(activation_map, (image.size[0], image.size[1]))
        
        # Normalizar o mapa de ativa√ß√£o para o intervalo [0, 1]
        activation_map_resized = (activation_map_resized - activation_map_resized.min()) / (activation_map_resized.max() - activation_map_resized.min() + 1e-8)
        
        # Converter a imagem para array NumPy
        image_np = np.array(image)
        
        # Converter o mapa de ativa√ß√£o em uma imagem RGB
        heatmap = cv2.applyColorMap(np.uint8(255 * activation_map_resized), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
        
        # Sobrepor o mapa de ativa√ß√£o na imagem original
        superimposed_img = heatmap * 0.4 + image_np * 0.6
        superimposed_img = np.uint8(superimposed_img)
        
        # Exibir a imagem original e o mapa de ativa√ß√£o sobreposto
        fig, ax = plt.subplots(1, 2, figsize=(10, 5))
        
        # Imagem original
        ax[0].imshow(image_np)
        ax[0].set_title('Imagem Original')
        ax[0].axis('off')
        
        # Imagem com Grad-CAM
        ax[1].imshow(superimposed_img)
        ax[1].set_title(f'{gradcam_type}')
        ax[1].axis('off')
        
        # Exibir as imagens com o Streamlit
        st.pyplot(fig)
        plt.close(fig)
        
        # Converter superimposed_img para PIL Image para retornar
        gradcam_image_pil = Image.fromarray(superimposed_img)
        
        return activation_map_resized, gradcam_image_pil
        
    except Exception as e:
        st.error(f"Erro ao gerar Grad-CAM: {str(e)}")
        st.info("Visualiza√ß√£o Grad-CAM n√£o dispon√≠vel para este modelo/configura√ß√£o.")
        return None, None
    finally:
        # CRITICAL: Remove hooks and reset model state to prevent interference with subsequent calls
        if cam_extractor is not None:
            try:
                # Try multiple cleanup methods for compatibility with different torchcam versions
                if hasattr(cam_extractor, 'remove_hooks'):
                    cam_extractor.remove_hooks()
                elif hasattr(cam_extractor, 'clear_hooks'):
                    cam_extractor.clear_hooks()
                elif hasattr(cam_extractor, 'reset_hooks'):
                    cam_extractor.reset_hooks()
            except Exception as e:
                # If hook removal fails, log it but continue
                st.warning(f"Aviso: N√£o foi poss√≠vel remover hooks: {e}")
        
        # Restore original training mode
        if original_training_mode:
            model.train()
        else:
            model.eval()




def main():

    # Definir o caminho do √≠cone
    icon_path = "logo.png"  # Verifique se o arquivo logo.png est√° no diret√≥rio correto
    
    # Verificar se o arquivo de √≠cone existe antes de configur√°-lo
    if os.path.exists(icon_path):
        st.set_page_config(page_title="Geomaker", page_icon=icon_path, layout="wide")
        logging.info(f"√çcone {icon_path} carregado com sucesso.")
    else:
        # Se o √≠cone n√£o for encontrado, carrega sem favicon
        st.set_page_config(page_title="Geomaker", layout="wide")
        logging.warning(f"√çcone {icon_path} n√£o encontrado, carregando sem favicon.")
    
    # Layout da p√°gina
    if os.path.exists('capa.png'):
        st.image('capa.png', caption='Laborat√≥rio de Educa√ß√£o e Intelig√™ncia Artificial - Geomaker. "A melhor forma de prever o futuro √© invent√°-lo." - Alan Kay', width='stretch')
    else:
        st.warning("Imagem 'capa.png' n√£o encontrada.")
    
    if os.path.exists("logo.png"):
        st.sidebar.image("logo.png", width=200)
    else:
        st.sidebar.text("Imagem do logotipo n√£o encontrada.")
    
    
  #___________________________________________________________
    st.title("Classifica√ß√£o por Imagens com Aprendizado Profundo")
    st.write("Este aplicativo permite treinar um modelo de classifica√ß√£o de imagens e aplicar algoritmos de clustering para an√°lise comparativa.")
    with st.expander("Transforma√ß√µes de Dados e Aumento de Dados no Treinamento de Redes Neurais"):
        st.write("""
        As **transforma√ß√µes de dados** e o **aumento de dados** s√£o t√©cnicas essenciais no treinamento de redes neurais profundas, principalmente em tarefas de vis√£o computacional. 
        Essas abordagens buscam melhorar a capacidade de generaliza√ß√£o dos modelos, gerando **imagens sint√©ticas** a partir dos dados de treinamento. Tais t√©cnicas s√£o particularmente 
        valiosas quando o conjunto de dados dispon√≠vel √© pequeno ou apresenta pouca diversidade. A normaliza√ß√£o, por sua vez, assegura que os valores dos pixels estejam em uma escala adequada, 
        resultando em um treinamento mais est√°vel e eficiente. Diversos estudos apontam que essas pr√°ticas s√£o eficazes para evitar **overfitting** e aumentar a robustez do modelo 
        (Shorten & Khoshgoftaar, 2019).
        """)
    
        st.write("### Aumento de Dados no Treinamento")
    
        st.write("""
        O **aumento de dados** ou *data augmentation* consiste na aplica√ß√£o de transforma√ß√µes aleat√≥rias √†s imagens do conjunto de treinamento para gerar novas amostras sint√©ticas. 
        No c√≥digo implementado, essa t√©cnica √© realizada com a classe `transforms.Compose` da biblioteca **torchvision**, que aplica uma sequ√™ncia de transforma√ß√µes.
        """)
    
        st.write("#### Transforma√ß√µes Aplicadas no Treinamento")
        
        st.write("""
        1. **RandomApply**: Aplica aleatoriamente um conjunto de transforma√ß√µes com 50% de probabilidade. Esse procedimento aumenta a variabilidade dos dados, gerando imagens diferentes a partir de uma √∫nica imagem de entrada.
       
        2. **RandomHorizontalFlip**: Realiza a invers√£o horizontal da imagem com 50% de probabilidade. Isso √© √∫til em cen√°rios onde a orienta√ß√£o horizontal da imagem n√£o altera seu significado, como em imagens de rochas ou melanomas.
    
        3. **RandomRotation(degrees=90)**: Rotaciona a imagem em at√© 90 graus, criando varia√ß√µes angulares, o que ajuda o modelo a reconhecer objetos independentemente da orienta√ß√£o.
    
        4. **ColorJitter**: Introduz varia√ß√µes de brilho, contraste, satura√ß√£o e matiz, simulando diferentes condi√ß√µes de ilumina√ß√£o e tornando o modelo mais robusto a mudan√ßas de ilumina√ß√£o.
    
        5. **RandomResizedCrop(224, scale=(0.8, 1.0))**: Realiza cortes aleat√≥rios na imagem e os redimensiona para 224x224 pixels, permitindo que diferentes partes da imagem sejam enfatizadas.
    
        6. **RandomAffine(degrees=0, shear=10)**: Aplica transforma√ß√µes afins, como cisalhamento, simulando distor√ß√µes que podem ocorrer no mundo real, como mudan√ßas de perspectiva.
    
        7. **Resize(256)**: Redimensiona a imagem para 256x256 pixels, assegurando que todas as imagens possuam a mesma dimens√£o.
    
        8. **CenterCrop(224)**: Recorta o centro da imagem, garantindo que o tamanho final seja 224x224 pixels.
    
        9. **ToTensor**: Converte a imagem para um tensor PyTorch, normalizando os valores dos pixels para o intervalo de [0,1], facilitando o processamento pelo modelo.
        """)
    
        st.write("### Gera√ß√£o de Imagens Sint√©ticas")
    
        st.write("""
        Essas transforma√ß√µes permitem que cada imagem original gere at√© **5 a 10 imagens sint√©ticas**. Por exemplo, em um conjunto de dados de 1000 imagens, 
        o processo pode expandir o conjunto para **5000 a 10000 imagens** ao longo do treinamento. Essa amplia√ß√£o artificial do conjunto de dados reduz o risco de **overfitting**, 
        permitindo que o modelo treine em um conjunto "maior" e mais diverso, o que √© crucial para melhorar a generaliza√ß√£o do modelo em dados novos.
        """)
    
        st.write("### Normaliza√ß√£o nas Imagens de Teste e Valida√ß√£o")
    
        st.write("""
        Nas imagens de **teste** e **valida√ß√£o**, o aumento de dados n√£o √© aplicado. O objetivo nesses conjuntos √© avaliar o modelo de maneira consistente, 
        utilizando imagens que representem o mais fielmente poss√≠vel os dados reais. No entanto, a normaliza√ß√£o dessas imagens √© fundamental para assegurar que seus valores de pixel 
        estejam adequados para as opera√ß√µes de aprendizado. Isso tamb√©m garante um desempenho est√°vel durante o treinamento.
        """)
    
        st.write("#### Transforma√ß√µes Aplicadas no Teste e Valida√ß√£o")
        
        st.write("""
        1. **Resize(256)**: Redimensiona a imagem para 256x256 pixels, garantindo que todas as imagens tenham o mesmo tamanho inicial.
    
        2. **CenterCrop(224)**: Realiza o corte central para que as dimens√µes da imagem sejam 224x224 pixels, correspondendo ao tamanho esperado pelo modelo.
    
        3. **ToTensor**: Converte a imagem para tensor e normaliza os valores dos pixels para o intervalo de [0,1], o que melhora a estabilidade num√©rica e a taxa de converg√™ncia do treinamento.
        """)
    
        st.write("### Import√¢ncia da Normaliza√ß√£o")
    
        st.write("""
        A **normaliza√ß√£o** garante que os valores dos pixels estejam em uma escala apropriada para as opera√ß√µes aritm√©ticas realizadas no modelo, melhorando a estabilidade e o desempenho do processo de treinamento. 
        Ela tamb√©m contribui para a estabilidade num√©rica durante o c√°lculo do gradiente e para uma converg√™ncia mais eficiente do modelo (Nguy·ªÖn et al., 2021).
        """)
    
        st.write("### Conclus√£o")
    
        st.write("""
        O c√≥digo exemplifica a implementa√ß√£o eficaz de transforma√ß√µes de dados e aumento de dados como parte da pipeline de treinamento de redes neurais profundas. 
        As transforma√ß√µes aplicadas aumentam a diversidade do conjunto de treinamento, ajudando a mitigar o **overfitting** e melhorar a generaliza√ß√£o do modelo. 
        Al√©m disso, a normaliza√ß√£o aplicada aos dados de teste e valida√ß√£o garante que o desempenho do modelo seja avaliado de forma precisa e consistente, 
        alinhada √†s melhores pr√°ticas de aprendizado profundo.
        """)
    
        st.write("### Refer√™ncias")
        
        st.write("""
        - Huang, G., Liu, Z., Maaten, L., & Weinberger, K. (2017). Densely connected convolutional networks. https://doi.org/10.1109/cvpr.2017.243
        - Li, S. (2023). Clouddensenet: lightweight ground-based cloud classification method for large-scale datasets based on reconstructed densenet. *Sensors*, 23(18), 7957. https://doi.org/10.3390/s23187957
        - Nguy·ªÖn, H., Yu, G., Shin, N., Kwon, G., Kwak, W., & Kim, J. (2021). Defective product classification system for smart factory based on deep learning. *Electronics*, 10(7), 826. https://doi.org/10.3390/electronics10070826
        - Shorten, C. & Khoshgoftaar, T. M. (2019). A survey on image data augmentation for deep learning. *Journal of Big Data*, 6(1). https://doi.org/10.1186/s40537-019-0197-0
        """)

    # Barra Lateral de Configura√ß√µes
    st.sidebar.title("Configura√ß√µes do Treinamento")
      # Imagem e Contatos___________________________
    #_______________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmulas LaTeX
    with st.sidebar:
        with st.expander("Discuss√£o sobre o N√∫mero de Classes em Modelos de Aprendizado Profundo"):
            st.write("""
            ### Introdu√ß√£o
    
            A discuss√£o sobre o n√∫mero de classes em modelos de aprendizado profundo √© fundamental para a compreens√£o da arquitetura e do desempenho de redes neurais em tarefas de classifica√ß√£o. O n√∫mero de classes refere-se ao total de categorias ou r√≥tulos que um modelo deve prever, e a configura√ß√£o correta desse par√¢metro impacta diretamente o desempenho do modelo, pois afeta a dimens√£o da sa√≠da da rede neural e a complexidade da tarefa. O n√∫mero de classes pode variar de tarefas bin√°rias, que envolvem apenas duas classes, at√© problemas com centenas ou milhares de classes, como nas classifica√ß√µes de imagens do **ImageNet** (Cheng, 2023).
            """)
    
            st.write("### Impacto do N√∫mero de Classes")
            st.write("""
            O n√∫mero de classes define a estrutura da √∫ltima camada da rede neural, que √© respons√°vel por realizar as predi√ß√µes. Para um problema de **classifica√ß√£o bin√°ria**, o modelo ter√° uma √∫nica sa√≠da que prev√™ a probabilidade de uma classe ou outra. Em contrapartida, em um problema de **classifica√ß√£o multiclasse**, o n√∫mero de sa√≠das ser√° igual ao n√∫mero de categorias poss√≠veis (Cheng, 2023). A fun√ß√£o de ativa√ß√£o utilizada na √∫ltima camada √© crucial para a interpreta√ß√£o dos resultados. A equa√ß√£o que representa essa rela√ß√£o pode ser expressa como:
            """)
            st.latex(r'''
            \mathbf{y} = \text{Softmax}(Wx + b)
            ''')
    
            st.write("""
            onde **W** e **b** s√£o os pesos e o bias, respectivamente, que conectam a camada anterior √†s classes de sa√≠da. O resultado √© passado pela fun√ß√£o **softmax**, que converte os valores em probabilidades associadas a cada classe (Petrovska et al., 2020).
            """)
    
                       
            st.write("""
            Em tarefas de classifica√ß√£o bin√°ria, o modelo tem apenas duas classes poss√≠veis, como **detec√ß√£o de fraude** ou **diagn√≥stico de doen√ßas** (positivo ou negativo). Nesse caso, a fun√ß√£o de ativa√ß√£o final √© geralmente a **sigmoide**, que retorna uma probabilidade entre 0 e 1 para cada entrada. Um limiar √© ent√£o aplicado para decidir a classe final predita pelo modelo (Cheng, 2023).
            """)
    
            st.write("### Classifica√ß√£o Multiclasse")
            st.write("""
            Em problemas de classifica√ß√£o multiclasse, o n√∫mero de classes pode variar consideravelmente. Por exemplo, em tarefas de **classifica√ß√£o de imagens geol√≥gicas**, o n√∫mero de classes pode ser pequeno, mas em aplica√ß√µes como a **classifica√ß√£o de imagens m√©dicas** ou **reconhecimento facial**, o n√∫mero de classes pode ser muito maior. A arquitetura da rede deve ser ajustada para garantir que a √∫ltima camada tenha o n√∫mero correto de sa√≠das correspondente ao n√∫mero de categorias (Cheng, 2023; Sardeshmukh, 2023).
            """)
    
            st.write("### Classifica√ß√£o Multirr√≥tulo")
            st.write("""
            Em problemas de **classifica√ß√£o multirr√≥tulo**, uma entrada pode pertencer a mais de uma classe ao mesmo tempo. Nesse cen√°rio, o n√∫mero de sa√≠das da rede neural √© igual ao n√∫mero de classes poss√≠veis, mas cada sa√≠da √© independente das demais. A fun√ß√£o de ativa√ß√£o usada √© a **sigmoide**, pois ela calcula a probabilidade de cada classe independentemente das outras (Petrovska et al., 2020).
            """)
    
            st.write("### Efeitos do N√∫mero de Classes no Desempenho")
            st.write("""
            O n√∫mero de classes influencia diretamente a complexidade do modelo e o tempo de treinamento. Conforme o n√∫mero de classes aumenta, a tarefa de classifica√ß√£o se torna mais dif√≠cil, exigindo mais par√¢metros e tempo de computa√ß√£o. Al√©m disso, um maior n√∫mero de classes aumenta o risco de **sobreajuste** (overfitting), especialmente em conjuntos de dados pequenos (Cheng, 2023; Suhana, 2022).
            """)
    
            st.write("### Conclus√£o")
            st.write("""
            O n√∫mero de classes √© um fator determinante na defini√ß√£o da arquitetura de redes neurais para tarefas de classifica√ß√£o. Seja em problemas bin√°rios, multiclasse ou multirr√≥tulo, a escolha adequada desse par√¢metro garante que a rede neural seja capaz de aprender as caracter√≠sticas relevantes de cada categoria. Em problemas com muitas classes, estrat√©gias como a **regulariza√ß√£o** e o **data augmentation** podem ser utilizadas para melhorar o desempenho do modelo, evitando o sobreajuste (Cheng, 2023; Sardeshmukh, 2023).
            """)
    
            st.write("### Refer√™ncias")
          
            st.write("""
            1. Cheng, R. (2023). Expansion of the CT-scans image set based on the pretrained DCGAN for improving the performance of the CNN. *Journal of Physics Conference Series*, 2646(1), 012015. https://doi.org/10.1088/1742-6596/2646/1/012015
            2. Petrovska, B., Atanasova-Pacemska, T., Corizzo, R., Mignone, P., Lameski, P., & Zdravevski, E. (2020). Aerial Scene Classification through Fine-Tuning with Adaptive Learning Rates and Label Smoothing. *Applied Sciences*, 10(17), 5792. https://doi.org/10.3390/app10175792
            3. Sardeshmukh, M. (2023). Crop image classification using convolutional neural network. *Multidisciplinary Science Journal*, 5(4), 2023039. https://doi.org/10.31893/multiscience.2023039
            4. Suhana, R. (2022). Fish Image Classification Using Adaptive Learning Rate In Transfer Learning Method. *Knowledge Engineering and Data Science*, 5(1), 67-77. https://doi.org/10.17977/um018v5i12022p67-77
            """)

  
    # Nota: O n√∫mero de classes ser√° detectado automaticamente do dataset
    num_classes = st.sidebar.number_input("N√∫mero de Classes (ser√° detectado automaticamente):", min_value=1, step=1, value=2, disabled=True, help="Este valor ser√° automaticamente detectado do dataset ap√≥s o upload")
    #_______________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Modelos Pr√©-Treinados: ResNet18, ResNet50 e DenseNet121:"):
            st.write("""
            ### Introdu√ß√£o
        
            As redes neurais convolucionais (CNNs) t√™m se tornado uma ferramenta essencial no campo do aprendizado profundo, especialmente em tarefas de vis√£o computacional, como a classifica√ß√£o de imagens. 
            Modelos como **ResNet18**, **ResNet50** e **DenseNet121** s√£o amplamente reconhecidos por seu desempenho superior em competi√ß√µes de classifica√ß√£o de imagens, como o **ImageNet**. Esses modelos s√£o considerados 
            **pr√©-treinados**, pois foram inicialmente treinados em grandes conjuntos de dados, permitindo que sejam reutilizados e ajustados para novas tarefas espec√≠ficas, uma pr√°tica conhecida como **transfer√™ncia de aprendizado** 
            (Cheng, 2023; Petrovska et al., 2020; Alaoui, 2023).
            """)
        
            st.write("### ResNet18 e ResNet50")
            st.write("""
            A arquitetura **ResNet** (Rede Residual) foi desenvolvida para mitigar o problema de **degrada√ß√£o** que ocorre em redes neurais muito profundas, onde o aumento do n√∫mero de camadas pode levar a uma diminui√ß√£o no desempenho.
            A inova√ß√£o dos **blocos residuais** permite que algumas camadas "saltem" conex√µes, aprendendo uma **fun√ß√£o de identidade** em vez de novas representa√ß√µes para cada camada. Essa abordagem facilita o treinamento de redes mais profundas, pois a fun√ß√£o residual pode ser aprendida de forma mais eficiente (Zhang et al., 2018; Sandotra et al., 2023; Petrovska et al., 2020).
            """)
            
            st.latex(r'''
            \mathbf{y} = \mathcal{F}(x, \{W_i\}) + x
            ''')
            
            st.write("""
            onde 
            """)
            st.latex(r'''
            \mathcal{F}(x, \{W_i\}) + x
            ''')
          
            st.write("""
            representa a fun√ß√£o aprendida e x √© a entrada. O termo x √© adicionado √† sa√≠da, o que simplifica o processo de treinamento e permite que redes mais profundas sejam treinadas com maior efic√°cia 
            ("A Framework for Flood Extent Mapping using CNN Transfer Learning", 2022; Petrovska et al., 2020).
            """)
        
            st.write("""
            O modelo **ResNet18** possui 18 camadas trein√°veis e √© uma vers√£o mais leve, adequada para aplica√ß√µes com restri√ß√µes de recursos computacionais, enquanto o **ResNet50**, com 50 camadas, √© capaz de capturar padr√µes mais complexos em imagens, sendo ideal para tarefas que exigem maior profundidade de an√°lise (Sandotra et al., 2023; Qin et al., 2019; Petrovska et al., 2020).
            """)
        
            st.write("""
            Ambos os modelos foram pr√©-treinados no conjunto de dados **ImageNet**, o que facilita a **transfer√™ncia de aprendizado** em novos dom√≠nios. As camadas iniciais desses modelos j√° s√£o capazes de identificar caracter√≠sticas gerais, acelerando o processo de treinamento em conjuntos de dados menores e espec√≠ficos, como em aplica√ß√µes m√©dicas ou de classifica√ß√£o de imagens geol√≥gicas (Cheng, 2023; Petrovska et al., 2020; Alaoui, 2023).
            """)
        
            st.write("### DenseNet121")
            st.write("""
            A arquitetura **DenseNet** (Rede Convolucional Densamente Conectada) oferece uma abordagem alternativa, onde todas as camadas est√£o interconectadas, promovendo a preserva√ß√£o do fluxo de gradiente e da informa√ß√£o original. Isso facilita a reutiliza√ß√£o das representa√ß√µes intermedi√°rias e otimiza a efici√™ncia do modelo. A equa√ß√£o que expressa essa estrutura √©:
            """)
        
            st.latex(r'''
            \mathbf{x}_l = H_l(\mathbf{x}_0, \mathbf{x}_1, \dots, \mathbf{x}_{l-1})
            ''')
        
            st.write("""
            onde
            """)
          
            st.latex(r'''
            \mathbf{x}_l 
            ''')
          
            st.write("""
            √© a sa√≠da da l-√©sima camada e 
            """)
          
            st.latex(r'''
             \mathbf{H}_l
            ''')
          
            st.write("""
            √© a fun√ß√£o aplicada. Essa configura√ß√£o otimiza o uso de gradientes e representa√ß√µes, resultando em um desempenho superior em tarefas de classifica√ß√£o 
            (Benegui & Ionescu, 2020; Varshni et al., 2019; Hamdaoui et al., 2021).
            """)
        
            st.write("""
            O modelo **DenseNet121**, que possui 121 camadas trein√°veis, √© particularmente eficaz em contextos onde a efici√™ncia √© crucial, maximizando o uso de recursos computacionais e facilitando a extra√ß√£o de caracter√≠sticas relevantes de imagens (Sardeshmukh, 2023; Hamdaoui et al., 2021).
            """)
        
            st.write("### Transfer√™ncia de Aprendizado e Ajuste Fino")
            st.write("""
            A utiliza√ß√£o de modelos pr√©-treinados, como ResNet18, ResNet50 e DenseNet121, √© uma t√©cnica de **transfer√™ncia de aprendizado** que permite que o conhecimento adquirido em tarefas anteriores seja aplicado a novos problemas. 
            Em vez de treinar um modelo do zero, o ajuste fino √© realizado nas camadas do modelo para se adaptar a um novo conjunto de dados, permitindo que caracter√≠sticas espec√≠ficas sejam aprendidas de forma mais eficiente. Por exemplo, em aplica√ß√µes de **classifica√ß√£o de melanomas** ou **an√°lise de rochas vulc√¢nicas**, as camadas mais profundas dos modelos s√£o ajustadas para entender caracter√≠sticas espec√≠ficas de imagens m√©dicas ou geol√≥gicas (Suhana, 2022; Petrovska et al., 2020).
            """)
        
            st.write("""
            Estudos demonstram que a transfer√™ncia de aprendizado √© especialmente eficaz ao se trabalhar com conjuntos de dados pequenos. O uso de modelos pr√©-treinados pode proporcionar resultados semelhantes ou at√© superiores aos de modelos treinados a partir do zero, reduzindo o tempo de treinamento e melhorando a precis√£o (Raghava et al., 2019; Alaoui, 2023; Ahmed, 2021).
            """)
        
            st.write("### Conclus√£o")
            st.write("""
            As arquiteturas **ResNet18**, **ResNet50** e **DenseNet121** s√£o ferramentas poderosas no campo do aprendizado profundo, especialmente em tarefas de classifica√ß√£o de imagens. Seu pr√©-treinamento em grandes conjuntos de dados, como o **ImageNet**, e a capacidade de serem ajustados para novas tarefas atrav√©s da transfer√™ncia de aprendizado, tornam esses modelos ideais para uma ampla gama de aplica√ß√µes, incluindo a classifica√ß√£o de imagens m√©dicas e geol√≥gicas. O uso dessas arquiteturas n√£o apenas reduz o tempo de treinamento, mas tamb√©m melhora a precis√£o e a efic√°cia em diversas √°reas de pesquisa e aplica√ß√£o pr√°tica (Zeimarani et al., 2020; "Dog Breed Identification with Fine Tuning of Pre-trained Models", 2019; Awais et al., 2020).
            """)
        
            st.write("### Refer√™ncias")
        
            st.write("""
            - (2019). Dog breed identification with fine tuning of pre-trained models. *International Journal of Recent Technology and Engineering*, 8(2S11), 3677-3680. https://doi.org/10.35940/ijrte.b1464.0982s1119
            - (2022). A framework for flood extent mapping using cnn transfer learning. https://doi.org/10.17762/ijisae.v10i3s.2426
            - Ahmed, A. (2021). Pre-trained cnns models for content based image retrieval. *International Journal of Advanced Computer Science and Applications*, 12(7). https://doi.org/10.14569/ijacsa.2021.0120723
            - Alaoui, A. (2023). Pre-trained cnns: evaluating emergency vehicle image classification. *Data & Metadata*, 2, 153. https://doi.org/10.56294/dm2023153
            - Benegui, C. and Ionescu, R. (2020). Convolutional neural networks for user identification based on motion sensors represented as images. *IEEE Access*, 8, 61255-61266. https://doi.org/10.1109/access.2020.2984214
            - Cheng, R. (2023). Expansion of the ct-scans image set based on the pretrained dcgan for improving the performance of the cnn. *Journal of Physics Conference Series*, 2646(1), 012015. https://doi.org/10.1088/1742-6596/2646/1/012015
            - Hamdaoui, H., Ben-fares, A., Boujraf, S., Chaoui, N., Alami, B., Ma√¢roufi, M., ‚Ä¶ & Qjidaa, H. (2021). High precision brain tumor classification model based on deep transfer learning and stacking concepts. *Indonesian Journal of Electrical Engineering and Computer Science*, 24(1), 167. https://doi.org/10.11591/ijeecs.v24.i1.pp167-177
            - Petrovska, B., Atanasova-Pacemska, T., Corizzo, R., Mignone, P., Lameski, P., & Zdravevski, E. (2020). Aerial scene classification through fine-tuning with adaptive learning rates and label smoothing. *Applied Sciences*, 10(17), 5792. https://doi.org/10.3390/app10175792
            - Raghava, Y., Kuthadi, V., & Rajalakshmi, S. (2019). Enhanced deep learning with featured transfer learning in identifying disguised faces. *International Journal of Innovative Technology and Exploring Engineering*, 8(10), 1257-1260. https://doi.org/10.35940/ijitee.h7286.0881019
            - Sandotra, N., Mahajan, P., Abrol, P., & Lehana, P. (2023). Analyzing performance of deep learning models under the presence of distortions in identifying plant leaf disease. *International Journal of Informatics and Communication Technology (IJ-ICT)*, 12(2), 115. https://doi.org/10.11591/ijict.v12i2.pp115-126
            - Sardeshmukh, M. (2023). Crop image classification using convolutional neural network. *Multidisciplinary Science Journal*, 5(4), 2023039. https://doi.org/10.31893/multiscience.2023039
            - Suhana, R. (2022). Fish image classification using adaptive learning rate in transfer learning method. *Knowledge Engineering and Data Science*, 5(1), 67. https://doi.org/10.17977/um018v5i12022p67-77
            - Varshni, D., Thakral, K., Agarwal, L., Nijhawan, R., & Mittal, A. (2019). Pneumonia detection using cnn based feature extraction. https://doi.org/10.1109/icecct.2019.8869364
            - Zeimarani, B., Costa, M., Nurani, N., Bianco, S., Pereira, W., & Filho, C. (2020). Breast lesion classification in ultrasound images using deep convolutional neural network. *IEEE Access*, 8, 133349-133359. https://doi.org/10.1109/access.2020.3010863
            - Zhang, B., Wang, C., Shen, Y., & Liu, Y. (2018). Fully connected conditional random fields for high-resolution remote sensing land use/land cover classification with convolutional neural networks. *Remote Sensing*, 10(12), 1889. https://doi.org/10.3390/rs10121889
            """)

    # Sele√ß√£o de Tipo de Arquitetura
    st.sidebar.write("---")
    st.sidebar.subheader("üèóÔ∏è Arquitetura do Modelo")
    
    architecture_type = st.sidebar.radio(
        "Tipo de Arquitetura:",
        options=["CNN (Convolucional)", "Transformer (ViT)"],
        help="CNN: Redes Neurais Convolucionais tradicionais | Transformer: Vision Transformers modernos"
    )
    
    if architecture_type == "CNN (Convolucional)":
        model_options = ['ResNet18', 'ResNet50', 'DenseNet121']
        st.sidebar.info("üî∑ **CNNs** s√£o excelentes para capturar padr√µes locais e hier√°rquicos em imagens atrav√©s de convolu√ß√µes.")
    else:
        model_options = ['ViT-B/16', 'ViT-B/32', 'ViT-L/16']
        if TIMM_AVAILABLE:
            model_options.extend(['ViT-B/16-timm', 'ViT-L/16-timm', 'Swin-T', 'Swin-B'])
        st.sidebar.info("üî∂ **Vision Transformers** usam mecanismos de aten√ß√£o para capturar rela√ß√µes globais na imagem. Modelos timm e Swin s√£o mais robustos!")
        st.sidebar.warning("‚ö†Ô∏è ViT requer mais mem√≥ria GPU. Use batch size menor se necess√°rio.")
    
    model_name = st.sidebar.selectbox("Modelo Pr√©-treinado:", options=model_options)
    
    # Explica√ß√£o sobre o modelo selecionado
    with st.sidebar.expander(f"‚ÑπÔ∏è Sobre {model_name}"):
        if model_name == 'ResNet18':
            st.write("**ResNet18:** 18 camadas, ~11M par√¢metros. R√°pido e eficiente para datasets menores.")
        elif model_name == 'ResNet50':
            st.write("**ResNet50:** 50 camadas, ~25M par√¢metros. Melhor precis√£o, requer mais recursos.")
        elif model_name == 'DenseNet121':
            st.write("**DenseNet121:** Conex√µes densas entre camadas, ~8M par√¢metros. Eficiente e preciso.")
        elif model_name == 'ViT-B/16':
            st.write("**ViT-B/16:** Base model, patches 16x16, ~86M par√¢metros. Melhor performance geral.")
        elif model_name == 'ViT-B/32':
            st.write("**ViT-B/32:** Base model, patches 32x32, ~88M par√¢metros. Mais r√°pido, menos preciso.")
        elif model_name == 'ViT-L/16':
            st.write("**ViT-L/16:** Large model, patches 16x16, ~307M par√¢metros. M√°xima precis√£o, requer muitos recursos.")
        elif model_name == 'ViT-B/16-timm':
            st.write("**ViT-B/16-timm:** Vers√£o timm do ViT Base. Mais robusto e melhor treinado que a vers√£o torchvision.")
        elif model_name == 'ViT-L/16-timm':
            st.write("**ViT-L/16-timm:** Vers√£o timm do ViT Large. Melhor desempenho e robustez.")
        elif model_name == 'Swin-T':
            st.write("**Swin-T:** Swin Transformer Tiny, ~28M par√¢metros. Arquitetura hier√°rquica eficiente. Melhor que ViT para muitos casos!")
        elif model_name == 'Swin-B':
            st.write("**Swin-B:** Swin Transformer Base, ~88M par√¢metros. Excelente performance, arquitetura state-of-the-art.")

    #________________________________________________________________________________________
    # Fine-Tuning Completo em Redes Neurais Profundas
    with st.sidebar:
        with st.expander("Fine-Tuning Completo em Redes Neurais Profundas:"):
            st.write("""
            ### Introdu√ß√£o
        
            O **fine-tuning** (ajuste fino) √© uma t√©cnica poderosa utilizada para ajustar redes neurais pr√©-treinadas em novos conjuntos de dados. No contexto de redes como a **ResNet18**, **ResNet50** ou **DenseNet121**, que foram inicialmente treinadas em grandes bases de dados (como o **ImageNet**), o fine-tuning permite que essas redes sejam adaptadas a novos problemas, como a **classifica√ß√£o de melanomas** ou de **rochas vulc√¢nicas e plut√¥nicas**. Ao realizar o fine-tuning, todas as camadas do modelo s√£o atualizadas para refletir as caracter√≠sticas do novo conjunto de dados, ao inv√©s de congelar as camadas iniciais, o que permite uma adapta√ß√£o mais profunda e precisa ao novo problema (Piotrowski & Napiorkowski, 2013; Friedrich et al., 2022).
            """)
        
            st.write("""
            ### Fundamenta√ß√£o Te√≥rica
        
            O conceito de fine-tuning √© baseado no princ√≠pio de **transfer√™ncia de aprendizado**, no qual um modelo pr√©-treinado em um grande conjunto de dados gen√©ricos √© reaproveitado para um novo problema espec√≠fico. Essa abordagem √© particularmente √∫til quando o novo conjunto de dados √© relativamente pequeno, pois o modelo j√° foi treinado para capturar padr√µes gerais em dados visuais (como bordas, texturas e formas), o que pode acelerar o treinamento e melhorar a precis√£o final (Al‚Äêrimy et al., 2023; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            Ao utilizar o fine-tuning completo, todas as camadas do modelo s√£o ajustadas com base nos novos dados. Isso significa que os pesos das camadas profundas do modelo, que foram aprendidos durante o treinamento inicial, s√£o atualizados para se adequar √†s caracter√≠sticas espec√≠ficas do novo conjunto de dados. Matematicamente, essa abordagem pode ser descrita como a otimiza√ß√£o da seguinte fun√ß√£o de perda:
            """)
        
            st.latex(r'''
            L_{\text{fine-tuning}} = L_{\text{original}} + \lambda \sum_{i} w_i^2
            ''')
        
            st.write("""
            Onde:
            """)
          
            st.latex(r'''
            L_{\text{fine-tuning}}
            ''')
          
            st.write("""
            √© a fun√ß√£o de perda durante o fine-tuning;
            """)
          
            st.latex(r'''
            L_{\text{original}}
            ''')
          
            st.write("""
            representa a fun√ß√£o de perda original do modelo pr√©-treinado;
            """)
          
            st.latex(r'''
            \lambda
            ''')
          
            st.write("""
            √© o coeficiente de regulariza√ß√£o (no caso de utilizar a regulariza√ß√£o L2);
            """)
          
            st.latex(r'''
            w_i
            ''')
            st.write("""
            s√£o os pesos individuais que ser√£o atualizados durante o processo de fine-tuning (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            """)
        
            st.write("""
            ### Benef√≠cios do Fine-Tuning Completo
        
            O fine-tuning completo oferece v√°rios benef√≠cios, especialmente quando o novo conjunto de dados difere substancialmente do conjunto no qual o modelo foi originalmente treinado. No caso da **classifica√ß√£o de melanomas** ou **rochas**, por exemplo, as caracter√≠sticas visuais dos dados podem ser muito diferentes das imagens do **ImageNet**, que incluem uma ampla variedade de objetos, animais e cen√°rios (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            Os principais benef√≠cios incluem:
            1. **Adapta√ß√£o Profunda**: Ao ajustar todas as camadas, o modelo consegue adaptar n√£o apenas as caracter√≠sticas gen√©ricas (como bordas e texturas), mas tamb√©m padr√µes mais complexos e espec√≠ficos do novo problema.
            2. **Melhoria da Precis√£o**: O fine-tuning completo geralmente resulta em melhorias significativas na precis√£o, especialmente quando os dados de treinamento s√£o limitados ou possuem caracter√≠sticas visuais √∫nicas (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            3. **Generaliza√ß√£o Melhorada**: O processo de fine-tuning permite que o modelo generalize melhor para novos dados, uma vez que ele √© treinado para capturar padr√µes mais espec√≠ficos do novo dom√≠nio (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            ### Compara√ß√£o com o Fine-Tuning Parcial
        
            Em contraste com o fine-tuning completo, no qual todas as camadas s√£o atualizadas, o **fine-tuning parcial** mant√©m algumas das camadas iniciais congeladas, atualizando apenas as camadas finais. Essa abordagem pode ser √∫til quando o novo conjunto de dados √© semelhante ao conjunto de dados original no qual o modelo foi treinado. No entanto, quando os dados diferem substancialmente, o fine-tuning completo tende a ser mais eficaz, pois permite uma adapta√ß√£o mais profunda e personalizada (Al‚Äêrimy et al., 2023; Sakizadeh et al., 2015).
            """)
        
            st.write("""
            ### Efeitos do Fine-Tuning em Problemas Espec√≠ficos
        
            #### Classifica√ß√£o de Melanomas
        
            No caso da **classifica√ß√£o de melanomas**, o fine-tuning completo permite que o modelo identifique padr√µes visuais sutis na pele que podem ser indicativos de c√¢ncer. Essas caracter√≠sticas visuais podem incluir varia√ß√µes de textura, cor e bordas, que s√£o espec√≠ficas de imagens m√©dicas e diferem dos objetos comuns presentes em bases de dados gen√©ricas, como o **ImageNet** (Piotrowski & Napiorkowski, 2013; Friedrich et al., 2022).
            """)
        
            st.write("""
            #### Classifica√ß√£o de Rochas
        
            Para a **classifica√ß√£o de rochas vulc√¢nicas e plut√¥nicas**, o fine-tuning completo permite que o modelo capture padr√µes geol√≥gicos e estruturais espec√≠ficos, como varia√ß√µes de granula√ß√£o e texturas minerais. Novamente, esses padr√µes s√£o significativamente diferentes dos dados de objetos comuns, tornando o fine-tuning completo uma abordagem valiosa para melhorar a precis√£o da classifica√ß√£o (Friedrich et al., 2022; Al‚Äêrimy et al., 2023).
            """)
        
            st.write("""
            ### Considera√ß√µes Pr√°ticas
        
            Durante o processo de fine-tuning, √© importante monitorar o desempenho do modelo em um conjunto de valida√ß√£o para evitar o **overfitting**. Uma t√©cnica comum √© utilizar a **regulariza√ß√£o L2** ou o **dropout** para garantir que o modelo n√£o se ajuste excessivamente aos dados de treinamento (Piotrowski & Napiorkowski, 2013; Sakizadeh et al., 2015). Al√©m disso, a taxa de aprendizado deve ser cuidadosamente ajustada. Em muitos casos, utiliza-se uma taxa de aprendizado menor durante o fine-tuning para garantir que as atualiza√ß√µes dos pesos n√£o sejam muito dr√°sticas, preservando parte das informa√ß√µes aprendidas anteriormente.
            """)
        
            st.write("""
            ### Conclus√£o
        
            O fine-tuning completo √© uma t√©cnica eficaz para ajustar modelos pr√©-treinados, como a **ResNet18**, **ResNet50** ou **DenseNet121**, a novos conjuntos de dados. Ao permitir que todas as camadas do modelo sejam atualizadas, o fine-tuning completo oferece maior flexibilidade e precis√£o em problemas que diferem substancialmente dos dados originais. Quando combinado com outras t√©cnicas de regulariza√ß√£o, como a L2, o fine-tuning pode levar a modelos robustos e capazes de generalizar para novos dados, sendo uma ferramenta essencial no arsenal de t√©cnicas de aprendizado profundo.
            """)
        
            st.write("""
            ### Refer√™ncias
        
            - Al‚ÄêRIMY, B.; SAEED, F.; AL-SAREM, M.; ALBARRAK, A.; QASEM, S. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, 13(11), 1903, 2023. https://doi.org/10.3390/diagnostics13111903
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, 32(2), 425-440, 2022. https://doi.org/10.1177/09622802221133557
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, 476, 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019
            - REZAEEZADE, A.; BATINA, L. Regularizers to the rescue: fighting overfitting in deeplearning-based side-channel analysis. 2022. https://doi.org/10.21203/rs.3.rs-2386625/v1
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, 54(1), 115-120, 2015. https://doi.org/10.1111/gwat.12317
            """)

    fine_tune = st.sidebar.checkbox("Fine-Tuning Completo", value=False)
    epochs = st.sidebar.slider("N√∫mero de √âpocas:", min_value=1, max_value=500, value=200, step=1)
    learning_rate = st.sidebar.select_slider("Taxa de Aprendizagem:", options=[0.1, 0.01, 0.001, 0.0001], value=0.0001)
    batch_size = st.sidebar.selectbox("Tamanho de Lote:", options=[4, 8, 16, 32, 64], index=2)
    train_split = st.sidebar.slider("Percentual de Treinamento:", min_value=0.5, max_value=0.9, value=0.7, step=0.05)
    valid_split = st.sidebar.slider("Percentual de Valida√ß√£o:", min_value=0.05, max_value=0.4, value=0.15, step=0.05)
    #________________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Implementa√ß√£o da T√©cnica de Regulariza√ß√£o L2 (Weight Decay):"):
            st.write("""
            ### Introdu√ß√£o
            A regulariza√ß√£o L2, frequentemente referida como *weight decay*, √© uma t√©cnica amplamente utilizada para mitigar o **overfitting** 
            em modelos de aprendizado de m√°quina, especialmente em redes neurais profundas. O *overfitting* ocorre quando o modelo se ajusta n√£o apenas 
            aos padr√µes dos dados de treinamento, mas tamb√©m ao ru√≠do presente, o que compromete sua capacidade de generaliza√ß√£o para novos dados 
            (Piotrowski & Napiorkowski, 2013). A regulariza√ß√£o L2 adiciona um termo de penaliza√ß√£o √† fun√ß√£o de perda do modelo, o que resulta em uma 
            redu√ß√£o dos valores absolutos dos pesos, promovendo, assim, modelos mais simples e generaliz√°veis (Friedrich et al., 2022).
            Esta revis√£o visa fornecer uma vis√£o clara e t√©cnica da aplica√ß√£o da regulariza√ß√£o L2, discutindo seus efeitos, a interpreta√ß√£o do coeficiente de regulariza√ß√£o 
            """)
          
            st.latex(r'''
            \lambda
            ''')
          
            st.write("""
            e as implica√ß√µes da escolha desse par√¢metro.
            """)
          
            st.latex(r'''
            L_{\text{total}} = L_{\text{original}} + \lambda \sum_{i} w_i^2
            ''')
          
            st.write("""
            Onde:
            """) 
            
            st.latex(r'''
            L_{\text{total}}
            ''')
          
            st.write("""
            √© a perda total que o modelo busca minimizar;
            """)
            
            st.latex(r'''
            L_{\text{original}}
            ''')
          
            st.write("""
            √© a fun√ß√£o de perda original (como a perda de entropia cruzada); Œª √© o coeficiente de regulariza√ß√£o, que controla a penalidade aplicada aos pesos;
            """)
          
            st.latex(r'''
            w_i
            ''')
          
            st.write(""" 
            s√£o os pesos individuais do modelo (Al‚ÄêRimy et al., 2023).
            """)
          
            st.write("""
            Este termo adicional penaliza pesos grandes, for√ßando o modelo a priorizar solu√ß√µes que utilizam pesos menores, o que √© crucial para evitar 
            que o modelo memorize os dados de treinamento, promovendo maior capacidade de generaliza√ß√£o (Sakizadeh et al., 2015).
            """)
          
            st.write("""
            ### Fundamenta√ß√£o Te√≥rica
            A regulariza√ß√£o L2 tem uma base te√≥rica s√≥lida, sendo amplamente aplicada para controlar a complexidade do modelo. Ao adicionar o termo de penaliza√ß√£o, 
            a regulariza√ß√£o L2 ajuda a evitar o overfitting e melhora a estabilidade num√©rica do modelo (Friedrich et al., 2022). Isso √© particularmente importante 
            em redes neurais profundas, onde o n√∫mero de par√¢metros pode ser grande e a complexidade do modelo alta.
            """)
          
            st.write("""
            ### Efeitos da Regulariza√ß√£o L2
            A regulariza√ß√£o L2 controla a complexidade do modelo ao penalizar pesos grandes, o que √© particularmente √∫til em cen√°rios com muitos par√¢metros 
            ou dados ruidosos (Piotrowski & Napiorkowski, 2013). Al√©m de reduzir o overfitting, a L2 promove a estabilidade no treinamento, melhorando a consist√™ncia do desempenho 
            em dados de teste (Friedrich et al., 2022).
            """)
    
            st.write("""
            ### Interpreta√ß√£o e Efeitos Pr√°ticos de Œª
            """)
          
            st.write("""        
            A escolha do valor de Œª
            """)
      
            st.write("""
            influencia diretamente o comportamento do modelo:
            """)
    
            st.write("""
            #### Œª = 0
            """)
            st.write("""
            Quando Œª = 0, a regulariza√ß√£o L2 est√° desativada. Isso permite que o modelo ajuste-se livremente aos dados de treinamento, 
            aumentando o risco de overfitting, especialmente em conjuntos de dados pequenos ou ruidosos (Friedrich et al., 2022).
            """)
    
            st.write("""
            #### Œª = 0,01
            """)
            st.write("""
            Este √© um valor moderado, que penaliza de forma equilibrada os pesos do modelo. Essa configura√ß√£o ajuda a evitar o overfitting sem comprometer a capacidade do modelo de 
            aprender padr√µes relevantes (Al‚ÄêRimy et al., 2023).
            """)
    
            st.write("""
            #### Œª = 0,02 ou Œª = 0,03
            Esses valores aumentam a intensidade da penaliza√ß√£o, sendo √∫teis em cen√°rios com dados ruidosos ou em que o n√∫mero de par√¢metros √© alto em rela√ß√£o √† quantidade de dados 
            dispon√≠veis (Piotrowski & Napiorkowski, 2013). Contudo, deve-se monitorar o desempenho do modelo, pois valores elevados de Œª podem resultar em **underfitting**, 
            comprometendo a capacidade do modelo de capturar padr√µes complexos (Friedrich et al., 2022).
            """)
    
            st.write("""
            ### Conclus√£o
            A regulariza√ß√£o L2 √© uma t√©cnica poderosa no treinamento de redes neurais profundas, ajudando a mitigar o overfitting e a melhorar a capacidade de generaliza√ß√£o do modelo. 
            Ao penalizar pesos grandes, a L2 incentiva solu√ß√µes mais simples e robustas. No entanto, a escolha do valor de Œª √© crucial para garantir que o modelo consiga capturar 
            padr√µes complexos sem se ajustar excessivamente aos dados de treinamento.
            """)
    
            st.write("""
            ### Refer√™ncias
            - AL‚ÄêRIMY, B.; SAEED, F.; AL-SAREM, M.; ALBARRAK, A.; QASEM, S. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, 13(11), 1903, 2023. https://doi.org/10.3390/diagnostics13111903
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, 32(2), 425-440, 2022. https://doi.org/10.1177/09622802221133557
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, 476, 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, 54(1), 115-120, 2015. https://doi.org/10.1111/gwat.12317
            """)
    

  
    l2_lambda = st.sidebar.number_input("L2 Regularization (Weight Decay):", min_value=0.0, max_value=0.1, value=0.01, step=0.01)
    l1_lambda = st.sidebar.number_input("L1 Regularization:", min_value=0.0, max_value=0.01, value=0.0, step=0.001, 
                                        help="Adiciona regulariza√ß√£o L1 (Lasso) ao treinamento. Promove esparsidade nos pesos.")
    
    #________________________________________________________________________________________
    # Novos par√¢metros de treinamento
    st.sidebar.write("---")
    st.sidebar.subheader("‚öôÔ∏è Configura√ß√µes Avan√ßadas")
    
    # Tipo de Aumento de Dados
    augmentation_type = st.sidebar.selectbox(
        "T√©cnica de Aumento de Dados:",
        options=['none', 'standard', 'mixup', 'cutmix'],
        index=1,
        help="None: Sem aumento | Standard: Transforma√ß√µes b√°sicas | Mixup: Mistura imagens | Cutmix: Recorta e cola regi√µes"
    )
    
    # Otimizador
    optimizer_options = ['Adam', 'AdamW', 'SGD']
    if ADVANCED_OPTIMIZERS_AVAILABLE:
        optimizer_options.extend(['Ranger', 'Lion'])
    
    optimizer_name = st.sidebar.selectbox(
        "Otimizador:",
        options=optimizer_options,
        index=0,
        help="Adam: Adaptativo padr√£o | AdamW: Adam com weight decay melhorado | SGD: Gradiente descendente com momento | Ranger: Lookahead + RAdam | Lion: Otimizador eficiente recente"
    )
    
    # Learning Rate Scheduler
    scheduler_name = st.sidebar.selectbox(
        "Agendador de Learning Rate:",
        options=['None', 'CosineAnnealingLR', 'OneCycleLR'],
        index=0,
        help="None: LR constante | CosineAnnealingLR: Reduz LR com coseno | OneCycleLR: Aumenta e depois reduz LR"
    )
    
    # Label Smoothing
    label_smoothing = st.sidebar.number_input(
        "Label Smoothing:", 
        min_value=0.0, 
        max_value=0.3, 
        value=0.1, 
        step=0.05,
        help="Suaviza os r√≥tulos para prevenir overconfidence. Valores t√≠picos: 0.1-0.2. Melhora generaliza√ß√£o especialmente em ViT."
    )
    
    # Gradient Clipping
    use_gradient_clipping = st.sidebar.checkbox(
        "Usar Gradient Clipping",
        value=True,
        help="Limita a norma dos gradientes para estabilizar o treinamento. ESSENCIAL para Vision Transformers."
    )
    
    # Exponential Moving Average
    use_ema = st.sidebar.checkbox(
        "Usar EMA (Exponential Moving Average)",
        value=True,
        help="Mant√©m m√©dia m√≥vel dos pesos. Melhora generaliza√ß√£o e estabilidade. Recomendado para todos os modelos."
    )
    
    # Reinforcement Learning
    use_rl = st.sidebar.checkbox(
        "Usar Reinforcement Learning",
        value=False,
        help="Ajusta dinamicamente learning rate usando Q-Learning baseado no desempenho. EXPERIMENTAL mas pode melhorar resultados!"
    )
    
    # CrewAI Research Agent
    use_crewai = st.sidebar.checkbox(
        "Usar Agente CrewAI (Pesquisa Web)",
        value=False,
        help="Usa agentes inteligentes para buscar estrat√©gias de treinamento na web. Requer API keys. EXPERIMENTAL."
    )
    
    # Tipo de Grad-CAM
    gradcam_type = st.sidebar.selectbox(
        "Tipo de Grad-CAM:",
        options=['GradCAM', 'GradCAMpp', 'SmoothGradCAMpp', 'LayerCAM'],
        index=2,
        help="GradCAM: B√°sico | GradCAMpp: Melhorado | SmoothGradCAMpp: Suavizado | LayerCAM: Por camada"
    )
    
    st.sidebar.write("---")
    
    #________________________________________________________________________________________
    # Sidebar com o conte√∫do explicativo e f√≥rmula LaTeX
    with st.sidebar:
        with st.expander("Implementa√ß√£o da T√©cnica de Parada Precoce - Early Stopping:"):
            st.write("""
            #### Introdu√ß√£o
            A t√©cnica de **parada precoce** (ou *early stopping*) √© amplamente utilizada para mitigar o **overfitting** no treinamento de redes neurais profundas. 
            O overfitting ocorre quando o modelo se ajusta t√£o bem aos dados de treinamento que sua capacidade de generaliza√ß√£o para novos dados √© prejudicada. 
            O princ√≠pio da parada precoce √© interromper o treinamento quando o desempenho do modelo em um conjunto de valida√ß√£o n√£o apresenta melhorias significativas 
            ap√≥s um n√∫mero predefinido de √©pocas. Essa abordagem baseia-se na observa√ß√£o de que, ap√≥s certo ponto, melhorias no desempenho do modelo em dados de treinamento 
            n√£o resultam em melhorias em dados que o modelo ainda n√£o viu (Piotrowski & Napiorkowski, 2013; Al‚ÄêRimy et al., 2023).
            """)
      
            st.write("Matematicamente, a parada precoce pode ser descrita pela seguinte condi√ß√£o de interrup√ß√£o:")
            # F√≥rmulas matem√°ticas
            st.latex(r'''
            \text{Se } L_{\text{val}}(t) \geq L_{\text{val}}(t-1)
            ''')
            st.write("""
            por (p) √©pocas consecutivas, ent√£o interrompa o treinamento. Aqui,
            """)
            st.latex(r'''
            L_{\text{val}}(t)
            ''')
    
            st.write("""
            representa o valor da **fun√ß√£o de perda** no conjunto de valida√ß√£o na √©poca (t), e (p) √© o **par√¢metro de paci√™ncia**. 
            A paci√™ncia (p) define quanto tempo o treinamento deve continuar mesmo que n√£o haja melhorias imediatas. Se a perda n√£o melhorar por (p) √©pocas consecutivas, 
            o treinamento √© interrompido.
            """)
      
            st.write("""
            #### A Import√¢ncia da Paci√™ncia
            O par√¢metro de **paci√™ncia** define o n√∫mero de √©pocas consecutivas sem melhoria na m√©trica de valida√ß√£o que o modelo pode suportar antes de o treinamento ser interrompido. 
            A escolha do valor de paci√™ncia tem impacto direto no equil√≠brio entre **evitar o overfitting** e **permitir que o modelo continue aprendendo**. 
            """)
      
            st.write("##### Paci√™ncia = 0")
            st.write("""
            Um valor de paci√™ncia igual a zero implica que o treinamento ser√° interrompido imediatamente ap√≥s a primeira ocorr√™ncia de estagna√ß√£o na m√©trica de valida√ß√£o. 
            Isso pode ser √∫til em cen√°rios onde se deseja evitar qualquer risco de *overfitting*.
            """)
      
            st.write("##### Paci√™ncia ‚â• 1")
            st.write("""
            Uma paci√™ncia maior (como 1 ou 2) permite que o modelo continue sendo treinado mesmo ap√≥s pequenas flutua√ß√µes no desempenho, 
            o que pode ser ben√©fico em conjuntos de dados ruidosos (Sakizadeh et al., 2015).
            """)
      
            st.write("""
            #### Impacto do *Early Stopping* e da Paci√™ncia
            A configura√ß√£o do par√¢metro de paci√™ncia influencia diretamente a efici√™ncia do treinamento. Com uma paci√™ncia muito baixa, o treinamento pode ser interrompido de forma prematura, 
            mesmo que o modelo ainda tenha potencial de melhoria. Por outro lado, uma paci√™ncia muito alta pode permitir que o modelo se ajuste excessivamente aos dados de treinamento, 
            levando ao *overfitting* (Sakizadeh et al., 2015).
            """)
      
            st.write("""
            #### Exemplos de Aplica√ß√£o
            Um exemplo pr√°tico de uso da parada precoce √© em tarefas de **classifica√ß√£o de imagens**. Durante o treinamento de um modelo para detec√ß√£o de melanoma, se a acur√°cia no conjunto de valida√ß√£o 
            n√£o melhorar ap√≥s um determinado n√∫mero de √©pocas, o early stopping √© acionado.
            """)
      
            st.write("""
            #### Integra√ß√£o com Outras T√©cnicas de Regulariza√ß√£o
            A parada precoce pode ser usada em conjunto com outras t√©cnicas de regulariza√ß√£o, como a **inje√ß√£o de ru√≠do** e a regulariza√ß√£o **L1/L2**, 
            para melhorar a robustez do modelo e sua capacidade de generaliza√ß√£o (Friedrich et al., 2022). 
            A combina√ß√£o dessas t√©cnicas ajuda a evitar que o modelo se ajuste excessivamente aos dados de treinamento, principalmente em cen√°rios com volumes limitados de dados.
            """)
      
            st.write("""
            #### Conclus√£o
            A **parada precoce** √© uma t√©cnica eficaz para evitar o *overfitting* no treinamento de redes neurais profundas. O valor da paci√™ncia desempenha um papel cr√≠tico, 
            permitindo o equil√≠brio entre **efici√™ncia computacional** e **capacidade de aprendizado**. Al√©m disso, a combina√ß√£o da parada precoce com outras t√©cnicas de regulariza√ß√£o 
            pode melhorar ainda mais o desempenho do modelo.
            """)
      
            st.write("""
            #### Refer√™ncias
            - PIOTROWSKI, A.; NAPIORKOWSKI, J. A comparison of methods to avoid overfitting in neural networks training in the case of catchment runoff modelling. *Journal of Hydrology*, v. 476, p. 97-111, 2013. https://doi.org/10.1016/j.jhydrol.2012.10.019.
            - AL‚ÄêRIMY, B. et al. An adaptive early stopping technique for densenet169-based knee osteoarthritis detection model. *Diagnostics*, v. 13, n. 11, p. 1903, 2023. https://doi.org/10.3390/diagnostics13111903.
            - SAKIZADEH, M.; MALIAN, A.; AHMADPOUR, E. Groundwater quality modeling with a small data set. *Ground Water*, v. 54, n. 1, p. 115-120, 2015. https://doi.org/10.1111/gwat.12317.
            - FRIEDRICH, S. et al. Regularization approaches in clinical biostatistics: a review of methods and their applications. *Statistical Methods in Medical Research*, v. 32, n. 2, p. 425-440, 2022. https://doi.org/10.1177/09622802221133557.
            """)


    #________________________________________________________________________________________
    patience = st.sidebar.number_input("Paci√™ncia para Early Stopping:", min_value=1, max_value=10, value=3, step=1)

    #____________________________________________________________________________________________
    with st.sidebar:
        with st.expander("Perda Ponderada para Classes Desbalanceadas:"):
            st.write("""
            ### Perda Ponderada para Classes Desbalanceadas
        
            A t√©cnica de **perda ponderada** para lidar com **classes desbalanceadas** √© amplamente utilizada em **aprendizado de m√°quina**, especialmente em redes neurais, para tratar problemas onde o n√∫mero de amostras entre as classes de um conjunto de dados n√£o √© equilibrado. O desbalanceamento ocorre em diversos dom√≠nios, como detec√ß√£o de fraudes, diagn√≥stico de doen√ßas e classifica√ß√£o de imagens. O principal objetivo da perda ponderada √© ajustar a fun√ß√£o de perda, atribuindo diferentes pesos √†s classes, de forma que o impacto das classes minorit√°rias (menos representadas) seja ampliado e o impacto das classes majorit√°rias seja reduzido. Isso ajuda o modelo a aprender de forma mais eficaz em cen√°rios onde o desequil√≠brio entre as classes pode levar ao **overfitting** nas classes majorit√°rias e √† **sub-representa√ß√£o** das classes minorit√°rias (Buda et al., 2018).
        
            ### Motiva√ß√£o e Justificativa Cient√≠fica
        
            Em um cen√°rio de classifica√ß√£o de imagens, se o modelo for treinado com uma quantidade muito maior de amostras de uma classe (classe majorit√°ria) em rela√ß√£o a outra (classe minorit√°ria), o modelo tende a ser enviesado para a classe majorit√°ria. Isso ocorre porque o objetivo padr√£o da maioria das fun√ß√µes de perda, como a **entropia cruzada**, √© minimizar a soma dos erros. Em um conjunto de dados desbalanceado, essa minimiza√ß√£o pode ser alcan√ßada simplesmente classificando todas as amostras como pertencentes √† classe majorit√°ria, resultando em alta acur√°cia geral, mas com desempenho ruim na classe minorit√°ria. Para resolver esse problema, atribui-se um peso maior √† classe minorit√°ria, for√ßando a fun√ß√£o de perda a penalizar mais fortemente os erros cometidos nessa classe (Buda et al., 2018).
        
            ### Implementa√ß√£o no C√≥digo
        
            No c√≥digo, a implementa√ß√£o da perda ponderada √© feita utilizando a fun√ß√£o de perda **CrossEntropyLoss** do PyTorch, que suporta a aplica√ß√£o de pesos √†s classes. Esses pesos s√£o calculados com base na **frequ√™ncia das classes** no conjunto de treinamento. Classes com menos amostras recebem pesos maiores, enquanto classes com mais amostras recebem pesos menores, balanceando o impacto de ambas durante o treinamento do modelo.
        
            """)
            
            st.write("**criterion = nn.CrossEntropyLoss(weight=class_weights)**")
            
            st.write("""
            No trecho de c√≥digo acima, o vetor `targets` coleta os r√≥tulos das amostras no conjunto de treino e a fun√ß√£o `np.bincount(targets)` conta quantas vezes cada classe aparece, resultando em um vetor `class_counts`, onde cada √≠ndice corresponde √† quantidade de amostras de uma classe espec√≠fica (Buda et al., 2018).
        
            ### Etapas do Processo
        
            1. **C√°lculo das Frequ√™ncias das Classes**: As frequ√™ncias de cada classe s√£o calculadas usando `np.bincount`. Classes menos representadas recebem pesos maiores.
            2. **Ajuste para Evitar Divis√£o por Zero**: Um pequeno valor (1e-6) √© adicionado para evitar divis√£o por zero quando uma classe n√£o tem nenhuma amostra.
            3. **C√°lculo dos Pesos Inversos**: A partir da frequ√™ncia, os pesos s√£o calculados tomando o inverso da frequ√™ncia de cada classe. Isso aumenta a penaliza√ß√£o dos erros nas classes minorit√°rias.
            4. **Fun√ß√£o de Perda Ponderada**: A fun√ß√£o de perda `nn.CrossEntropyLoss(weight=class_weights)` usa os pesos calculados, penalizando mais fortemente os erros das classes minorit√°rias.
        
            ### Impacto e Efic√°cia da Perda Ponderada
        
            A **perda ponderada** ajusta o aprendizado do modelo, incentivando a penaliza√ß√£o dos erros cometidos nas classes minorit√°rias. Estudos demonstram que essa t√©cnica √© eficaz em aumentar a **recall** das classes minorit√°rias, sem comprometer drasticamente a precis√£o das classes majorit√°rias (Buda et al., 2018). No entanto, a aplica√ß√£o da perda ponderada pode tornar o treinamento mais **sens√≠vel √† escolha dos hiperpar√¢metros**, como a **taxa de aprendizado**, pois o modelo passa a ser fortemente influenciado pelas amostras menos representativas.
        
            ### Conclus√£o
        
            A implementa√ß√£o da **perda ponderada** no c√≥digo √© uma abordagem robusta para lidar com **classes desbalanceadas**. Ao ajustar os pesos da fun√ß√£o de perda com base nas frequ√™ncias das classes, o modelo consegue equilibrar melhor o aprendizado entre as classes majorit√°rias e minorit√°rias, evitando vieses que favorecem a classe mais representada no conjunto de dados (Buda et al., 2018).
        
            ### Refer√™ncias
        
            - Buda, M., Maki, A., & Mazurowski, M. (2018). A systematic study of the class imbalance problem in convolutional neural networks. *Neural Networks*, 106, 249-259. https://doi.org/10.1016/j.neunet.2018.07.011
            """)

    use_weighted_loss = st.sidebar.checkbox("Usar Perda Ponderada para Classes Desbalanceadas", value=False)
    
    #________________________________________________________________________________________
    # API Configuration Section for AI Analysis
    st.sidebar.write("---")
    st.sidebar.subheader("üîë Configura√ß√£o de API para An√°lise IA")
    
    with st.sidebar.expander("Configurar API (Gemini/Groq)", expanded=False):
        st.write("Configure sua API para an√°lise diagn√≥stica com IA")
        
        api_provider_sidebar = st.selectbox(
            "Provedor de API:",
            options=['Nenhum', 'Gemini', 'Groq'],
            key='api_provider_sidebar',
            help="Escolha entre Google Gemini ou Groq para an√°lise com IA"
        )
        
        if api_provider_sidebar != 'Nenhum':
            if api_provider_sidebar == 'Gemini':
                model_options_sidebar = [
                    'gemini-2.5-flash',  # ‚≠ê Recommended
                    'gemini-2.5-flash-lite',
                    'gemini-2.5-pro',
                    'gemini-3-flash-preview',
                    'gemini-3-pro-preview',
                    # Legacy models (not recommended)
                    'gemini-1.5-pro-latest',
                    'gemini-1.5-flash-latest'
                ]
            else:  # Groq
                model_options_sidebar = [
                    'meta-llama/llama-4-scout-17b-16e-instruct',
                    'meta-llama/llama-4-maverick-17b-128e-instruct',
                    'mixtral-8x7b-32768',
                    'llama-3.1-70b-versatile',
                    'llama-3.1-8b-instant'
                ]
            
            ai_model_sidebar = st.selectbox(
                "Modelo:",
                options=model_options_sidebar,
                key='ai_model_sidebar',
                help="Escolha o modelo de IA para an√°lise"
            )
            
            api_key_sidebar = st.text_input(
                "API Key:",
                type="password",
                key='api_key_sidebar',
                help="Insira sua chave API (ser√° usada durante a avalia√ß√£o de imagens)"
            )
            
            if api_key_sidebar:
                st.success("‚úÖ API Key configurada!")
                st.session_state['api_configured'] = True
                st.session_state['api_provider'] = api_provider_sidebar
                st.session_state['api_model'] = ai_model_sidebar
                st.session_state['api_key'] = api_key_sidebar
            else:
                st.session_state['api_configured'] = False
        else:
            st.session_state['api_configured'] = False
            api_key_sidebar = None
            ai_model_sidebar = None
    
    st.sidebar.image("eu.ico", width=80)
   
    st.sidebar.write("""
    Produzido pelo:
    
    Projeto Geomaker + IA 
    
    https://doi.org/10.5281/zenodo.13910277
    
    - Professor: Marcelo Claro.
    
    Contatos: marceloclaro@gmail.com
    
    Whatsapp: (88)981587145
    
    Instagram: [marceloclaro.geomaker](https://www.instagram.com/marceloclaro.geomaker/)
    
    """)
     # _____________________________________________
    # Controle de √Åudio
    st.sidebar.title("Controle de √Åudio")
    
    # Dicion√°rio de arquivos de √°udio, com nomes amig√°veis mapeando para o caminho do arquivo
    mp3_files = {
        "√Åudio explicativo para Leigos": "leigo.mp3",
        "√Åudio explicativo para treinamentos de poucos dados": "bucal.mp3",
    }
    
    # Lista de arquivos MP3 para sele√ß√£o
    selected_mp3 = st.sidebar.radio("Escolha um √°udio explicativo:", options=list(mp3_files.keys()))
    
    # Controle de op√ß√£o de repeti√ß√£o
    loop = st.sidebar.checkbox("Repetir √°udio")
    
    # Bot√£o de Play para iniciar o √°udio
    play_button = st.sidebar.button("Play")
    
    # Placeholder para o player de √°udio
    audio_placeholder = st.sidebar.empty()
    
    # Fun√ß√£o para verificar se o arquivo existe
    def check_file_exists(mp3_path):
        if not os.path.exists(mp3_path):
            st.sidebar.error(f"Arquivo {mp3_path} n√£o encontrado.")
            return False
        return True
    
    # Se o bot√£o Play for pressionado e um arquivo de √°udio estiver selecionado
    if play_button and selected_mp3:
        mp3_path = mp3_files[selected_mp3]
        
        # Verifica√ß√£o da exist√™ncia do arquivo
        if check_file_exists(mp3_path):
            try:
                # Abrindo o arquivo de √°udio no modo bin√°rio
                with open(mp3_path, "rb") as audio_file:
                    audio_bytes = audio_file.read()
                    
                    # Codificando o arquivo em base64 para embutir no HTML
                    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                    
                    # Controle de loop (repeti√ß√£o)
                    loop_attr = "loop" if loop else ""
                    
                    # Gerando o player de √°udio em HTML
                    audio_html = f"""
                    <audio id="audio-player" controls autoplay {loop_attr}>
                      <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
                      Seu navegador n√£o suporta o elemento de √°udio.
                    </audio>
                    """
                    
                    # Inserindo o player de √°udio na interface
                    audio_placeholder.markdown(audio_html, unsafe_allow_html=True)
            
            except FileNotFoundError:
                st.sidebar.error(f"Arquivo {mp3_path} n√£o encontrado.")
            except Exception as e:
                st.sidebar.error(f"Erro ao carregar o arquivo: {str(e)}")
    #______________________________________________________________________________________-


    # Verificar se a soma dos splits √© v√°lida
    if train_split + valid_split > 0.95:
        st.sidebar.error("A soma dos splits de treinamento e valida√ß√£o deve ser menor ou igual a 0.95.")

    # Upload do arquivo ZIP
    
    zip_file = st.file_uploader("Upload do arquivo ZIP com as imagens", type=["zip"])

    if zip_file is not None and train_split + valid_split <= 0.95:
        temp_dir = tempfile.mkdtemp()
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        with open(zip_path, "wb") as f:
            f.write(zip_file.read())
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        data_dir = temp_dir

        # Detectar automaticamente o n√∫mero de classes do dataset
        try:
            temp_dataset = datasets.ImageFolder(root=data_dir)
            detected_num_classes = len(temp_dataset.classes)
            st.success(f"‚úÖ N√∫mero de classes detectado automaticamente: **{detected_num_classes}**")
            st.write(f"Classes encontradas: {', '.join(temp_dataset.classes)}")
            num_classes = detected_num_classes
        except Exception as e:
            st.error(f"Erro ao detectar classes: {e}")
            st.error("Certifique-se de que o ZIP cont√©m pastas com nomes de classes e imagens dentro delas.")
            shutil.rmtree(temp_dir)
            return

        st.write("Iniciando o treinamento supervisionado...")
        model_data = train_model(data_dir, num_classes, model_name, fine_tune, epochs, learning_rate, 
                                batch_size, train_split, valid_split, use_weighted_loss, l2_lambda, l1_lambda, 
                                patience, optimizer_name, scheduler_name, augmentation_type, 
                                label_smoothing, use_gradient_clipping, use_ema, use_rl, use_crewai)

        if model_data is None:
            st.error("Erro no treinamento do modelo.")
            shutil.rmtree(temp_dir)
            return

        model, classes, training_history = model_data
        st.success("Treinamento conclu√≠do!")
        
        # Store training history in session state for later use in AI analysis
        st.session_state['training_history'] = training_history
        st.session_state['trained_model_name'] = model_name
        st.session_state['training_config'] = {
            'epochs': epochs,
            'learning_rate': learning_rate,
            'batch_size': batch_size,
            'optimizer': optimizer_name,
            'scheduler': scheduler_name,
            'augmentation': augmentation_type
        }
        
        # Adicionar bot√£o de download do CSV com hist√≥rico de treinamento
        st.write("---")
        st.write("## üìä Exportar Resultados de Treinamento")
        df_training_export = pd.DataFrame(training_history)
        csv_training = export_to_csv(df_training_export, "historico_treinamento.csv")
        st.download_button(
            label="üì• Baixar CSV - Hist√≥rico de Treinamento",
            data=csv_training,
            file_name=f"historico_treinamento_{model_name}.csv",
            mime="text/csv",
            help="Download do hist√≥rico completo de treinamento (loss e accuracy por √©poca)"
        )

        # Extrair caracter√≠sticas usando o modelo pr√©-treinado (sem a camada final)
        st.write("Extraindo caracter√≠sticas para clustering...")
        # Remover a √∫ltima camada do modelo para obter embeddings
        if model_name.startswith('ResNet'):
            feature_extractor = nn.Sequential(*list(model.children())[:-1])
        elif model_name.startswith('DenseNet'):
            feature_extractor = nn.Sequential(*list(model.features))
            feature_extractor.add_module('global_pool', nn.AdaptiveAvgPool2d((1,1)))
        elif model_name.startswith('ViT'):
            # Para Vision Transformers, remover apenas a camada head
            # Mantemos o encoder completo
            class ViTFeatureExtractor(nn.Module):
                def __init__(self, vit_model):
                    super().__init__()
                    self.conv_proj = vit_model.conv_proj
                    self.encoder = vit_model.encoder
                    self.class_token = vit_model.class_token
                    
                def forward(self, x):
                    # Reshape and permute the input tensor
                    x = self.conv_proj(x)
                    x = x.flatten(2).transpose(1, 2)
                    
                    # Add class token
                    batch_size = x.shape[0]
                    class_tokens = self.class_token.expand(batch_size, -1, -1)
                    x = torch.cat([class_tokens, x], dim=1)
                    
                    # Pass through encoder
                    x = self.encoder(x)
                    
                    # Return the class token output
                    return x[:, 0]
            
            feature_extractor = ViTFeatureExtractor(model)
        else:
            st.error("Modelo n√£o suportado para extra√ß√£o de caracter√≠sticas.")
            return

        feature_extractor = feature_extractor.to(device)
        feature_extractor.eval()

        # Carregar o dataset completo para extra√ß√£o de caracter√≠sticas
        full_dataset = datasets.ImageFolder(root=data_dir, transform=test_transforms)
        features, labels = extract_features(full_dataset, feature_extractor, batch_size)

        # Aplicar algoritmos de clustering
        st.write("Aplicando algoritmos de clustering...")
        features_reshaped = features.reshape(len(features), -1)
        hierarchical_labels, kmeans_labels = perform_clustering(features_reshaped, num_classes)

        # Avaliar e exibir os resultados
        st.write("Avaliando os resultados do clustering...")
        evaluate_clustering(labels, hierarchical_labels, "Clustering Hier√°rquico")
        evaluate_clustering(labels, kmeans_labels, "K-Means Clustering")

        # Visualizar clusters
        visualize_clusters(features_reshaped, labels, hierarchical_labels, kmeans_labels, classes)
        
        # Exportar resultados de clustering para CSV
        st.write("---")
        st.write("## üìä Exportar Resultados de Clustering")
        ari_hierarchical = adjusted_rand_score(labels, hierarchical_labels)
        nmi_hierarchical = normalized_mutual_info_score(labels, hierarchical_labels)
        ari_kmeans = adjusted_rand_score(labels, kmeans_labels)
        nmi_kmeans = normalized_mutual_info_score(labels, kmeans_labels)
        
        clustering_results = {
            'sample_id': list(range(len(labels))),
            'true_label': labels,
            'true_class_name': [classes[label] for label in labels],
            'hierarchical_cluster': hierarchical_labels,
            'kmeans_cluster': kmeans_labels
        }
        df_clustering = pd.DataFrame(clustering_results)
        
        # Adicionar m√©tricas de avalia√ß√£o como linhas de resumo
        summary_data = {
            'sample_id': ['M√âTRICAS', 'M√âTRICAS'],
            'true_label': ['Hierarchical ARI', 'K-Means ARI'],
            'true_class_name': [f'{ari_hierarchical:.4f}', f'{ari_kmeans:.4f}'],
            'hierarchical_cluster': [f'NMI: {nmi_hierarchical:.4f}', ''],
            'kmeans_cluster': ['', f'NMI: {nmi_kmeans:.4f}']
        }
        df_summary = pd.DataFrame(summary_data)
        df_clustering_export = pd.concat([df_clustering, df_summary], ignore_index=True)
        
        csv_clustering = export_to_csv(df_clustering_export, "resultados_clustering.csv")
        st.download_button(
            label="üì• Baixar CSV - Resultados de Clustering",
            data=csv_clustering,
            file_name=f"clustering_{model_name}.csv",
            mime="text/csv",
            help="Download dos resultados completos de clustering"
        )
        
        # ========== OP√á√ÉO DE VISUALIZA√á√ÉO PCA ==========
        st.write("---")
        st.write("## üî¨ An√°lise PCA das Features")
        
        show_pca = st.checkbox("üìä Mostrar An√°lise PCA das Features Extra√≠das", value=True)
        
        if show_pca:
            # Op√ß√£o de escolher n√∫mero de componentes
            n_components = st.selectbox(
                "Escolha o n√∫mero de componentes principais para visualiza√ß√£o:",
                options=[2, 3],
                index=0,
                help="2 componentes: Visualiza√ß√£o 2D | 3 componentes: Visualiza√ß√£o 3D interativa com Plotly"
            )
            
            if n_components == 2:
                visualize_pca_features(features_reshaped, labels, classes, n_components=2)
            else:
                # 3D Visualization with Plotly
                st.write("### üìä Visualiza√ß√£o PCA 3D Interativa")
                if VISUALIZATION_3D_AVAILABLE:
                    try:
                        fig_3d = visualize_pca_3d(features_reshaped, labels, classes)
                        st.plotly_chart(fig_3d, width='stretch')
                        st.success("‚úÖ Visualiza√ß√£o 3D interativa gerada! Voc√™ pode rotacionar, fazer zoom e explorar.")
                    except Exception as e:
                        st.error(f"Erro ao gerar visualiza√ß√£o 3D: {str(e)}")
                        st.info("Mostrando visualiza√ß√£o 2D como alternativa")
                        visualize_pca_features(features_reshaped, labels, classes, n_components=2)
                else:
                    st.warning("‚ö†Ô∏è M√≥dulo de visualiza√ß√£o 3D n√£o dispon√≠vel. Instale com: pip install plotly")
                    st.info("Mostrando visualiza√ß√£o 2D como alternativa")
                    visualize_pca_features(features_reshaped, labels, classes, n_components=2)

        # Avalia√ß√£o de uma imagem individual
        evaluate = st.radio("Deseja avaliar uma imagem?", ("Sim", "N√£o"))
        if evaluate == "Sim":
            eval_image_file = st.file_uploader("Fa√ßa upload da imagem para avalia√ß√£o", type=["png", "jpg", "jpeg", "bmp", "gif"])
            if eval_image_file is not None:
                eval_image_file.seek(0)
                try:
                    eval_image = Image.open(eval_image_file).convert("RGB")
                except Exception as e:
                    st.error(f"Erro ao abrir a imagem: {e}")
                    return

                st.image(eval_image, caption='Imagem para avalia√ß√£o', width='stretch')
                class_name, confidence = evaluate_image(model, eval_image, classes)
                st.write(f"**Classe Predita:** {class_name}")
                st.write(f"**Confian√ßa:** {confidence:.4f}")

                # Visualizar ativa√ß√µes com o tipo de Grad-CAM selecionado
                activation_map, gradcam_image = visualize_activations(model, eval_image, classes, gradcam_type)
                
                # ========== VISUALIZA√á√ÉO 3D DO GRAD-CAM ==========
                if activation_map is not None and VISUALIZATION_3D_AVAILABLE:
                    st.write("---")
                    st.write("### üåê Visualiza√ß√£o 3D do Grad-CAM")
                    show_3d_gradcam = st.checkbox("Mostrar Grad-CAM em 3D", value=False, help="Visualiza√ß√£o interativa 3D do mapa de ativa√ß√£o")
                    if show_3d_gradcam:
                        try:
                            with st.spinner("üîÑ Gerando visualiza√ß√£o 3D do Grad-CAM..."):
                                fig_gradcam_3d = visualize_activation_heatmap_3d(activation_map)
                                st.plotly_chart(fig_gradcam_3d, width='stretch')
                                st.success("‚úÖ Visualiza√ß√£o 3D gerada! Voc√™ pode rotacionar e fazer zoom no heatmap.")
                        except Exception as e:
                            st.error(f"Erro ao gerar visualiza√ß√£o 3D do Grad-CAM: {str(e)}")
                
                # ========== AN√ÅLISE ESTAT√çSTICA COMPLETA ==========
                st.write("---")
                with st.spinner("üî¨ Realizando an√°lise estat√≠stica completa..."):
                    # An√°lise estat√≠stica com bootstrap (ajuste n_bootstrap conforme necess√°rio)
                    n_bootstrap = st.slider(
                        "N√∫mero de itera√ß√µes Bootstrap", 
                        min_value=50, 
                        max_value=500, 
                        value=100, 
                        step=50,
                        help="Mais itera√ß√µes = an√°lise mais precisa mas mais lenta"
                    )
                    
                    statistical_analysis = evaluate_image_with_statistics(
                        model, 
                        eval_image, 
                        classes, 
                        activation_map=activation_map,
                        n_bootstrap=n_bootstrap
                    )
                    
                    # Exibir an√°lise estat√≠stica
                    display_statistical_analysis(statistical_analysis)
                
                # Preparar dados para exporta√ß√£o CSV
                classification_result = {
                    'imagem': eval_image_file.name,
                    'classe_predita': class_name,
                    'confianca': confidence,
                    'modelo': model_name,
                    'tipo_gradcam': gradcam_type,
                    'epocas_treinamento': epochs,
                    'taxa_aprendizagem': learning_rate,
                    'batch_size': batch_size,
                    'augmentation_type': augmentation_type,
                    'optimizer': optimizer_name
                }
                
                # Criar DataFrame de classifica√ß√£o
                df_classification = pd.DataFrame([classification_result])
                
                # Bot√£o para exportar resultado da classifica√ß√£o
                st.write("---")
                st.write("## üìä Exportar Resultado da Classifica√ß√£o")
                csv_classification = export_to_csv(df_classification, "resultado_classificacao.csv")
                st.download_button(
                    label="üì• Baixar CSV - Resultado da Classifica√ß√£o",
                    data=csv_classification,
                    file_name=f"classificacao_{eval_image_file.name.split('.')[0]}.csv",
                    mime="text/csv",
                    help="Download do resultado da classifica√ß√£o desta imagem"
                )
                
                # ========== AI CHAT DIAGNOSTIC ANALYSIS (ENHANCED from app5) ==========
                st.write("---")
                st.write("## ü§ñ An√°lise Diagn√≥stica Avan√ßada com IA")
                
                st.info("""
                **üí° Sobre a An√°lise Diagn√≥stica com IA:**
                
                Esta an√°lise utiliza modelos de linguagem avan√ßados para fornecer:
                - üìä Interpreta√ß√£o detalhada dos resultados de classifica√ß√£o
                - üìö Correla√ß√£o com refer√™ncias acad√™micas (PubMed, arXiv, Semantic Scholar)
                - üî¨ An√°lise multi-perspectiva baseada em algoritmos gen√©ticos
                - üéØ Recomenda√ß√µes e diagn√≥sticos diferenciais
                
                **Fluxo de An√°lise:**
                1. Configura√ß√£o da API (Gemini ou Groq)
                2. Busca de refer√™ncias acad√™micas autom√°ticas
                3. Gera√ß√£o de an√°lise diagn√≥stica completa
                4. (Opcional) An√°lise multi-perspectiva com algoritmos gen√©ticos
                """)
                
                enable_ai_analysis = st.checkbox(
                    "Ativar An√°lise Diagn√≥stica Completa com IA", 
                    value=False,
                    help="An√°lise PhD-level com IA, refer√™ncias acad√™micas e interpreta√ß√£o multi-perspectiva"
                )
                
                if enable_ai_analysis and AI_CHAT_AVAILABLE:
                    st.write("### Configura√ß√£o da API")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        api_provider = st.selectbox(
                            "Provedor de API:",
                            options=['gemini', 'groq'],
                            help="Escolha entre Google Gemini ou Groq"
                        )
                    
                    with col2:
                        if api_provider == 'gemini':
                            model_options = [
                                'gemini-2.5-flash',  # ‚≠ê Recommended
                                'gemini-2.5-flash-lite',
                                'gemini-2.5-pro',
                                'gemini-3-flash-preview',
                                'gemini-3-pro-preview',
                                # Legacy models (not recommended)
                                'gemini-1.5-pro-latest',
                                'gemini-1.5-flash-latest'
                            ]
                        else:
                            model_options = [
                                'meta-llama/llama-4-scout-17b-16e-instruct',
                                'meta-llama/llama-4-maverick-17b-128e-instruct',
                                'mixtral-8x7b-32768',
                                'llama-3.1-70b-versatile',
                                'llama-3.1-8b-instant'
                            ]
                        
                        ai_model = st.selectbox(
                            "Modelo:",
                            options=model_options
                        )
                    
                    api_key = st.text_input(
                        "API Key:",
                        type="password",
                        help="Insira sua chave API (Gemini: https://ai.google.dev/ | Groq: https://console.groq.com/)"
                    )
                    
                    if api_key:
                        if st.button("üî¨ Gerar An√°lise Diagn√≥stica Completa"):
                            with st.spinner("Gerando an√°lise diagn√≥stica aprofundada..."):
                                try:
                                    # Fetch academic references with improved status
                                    with st.status("üìö Buscando refer√™ncias acad√™micas...", expanded=True) as status:
                                        references = []
                                        if ACADEMIC_REF_AVAILABLE:
                                            try:
                                                st.write("üîç Consultando bases de dados cient√≠ficas...")
                                                
                                                # Use the API configuration from the current section (not sidebar)
                                                # This ensures we use the provider and model selected by the user in this dialog
                                                # Variables api_provider, api_key, and ai_model are already defined above from user input
                                                
                                                # Initialize fetcher with AI capabilities using current section config
                                                ref_fetcher = AcademicReferenceFetcher(
                                                    ai_provider=api_provider,
                                                    ai_api_key=api_key,
                                                    ai_model=ai_model
                                                )
                                                
                                                references = ref_fetcher.get_references_for_classification(
                                                    class_name=class_name,
                                                    domain="image classification",
                                                    max_per_source=3
                                                )
                                                
                                                if references:
                                                    status.update(label=f"üìö {len(references)} refer√™ncias encontradas!", state="running")
                                                    
                                                    # Enrich references with translations and critical reviews
                                                    if api_provider and api_key:
                                                        st.write("üåê Traduzindo resumos e gerando resenhas cr√≠ticas...")
                                                        references = ref_fetcher.enrich_references_with_analysis(references)
                                                        status.update(label=f"üìö {len(references)} refer√™ncias processadas com tradu√ß√µes e resenhas!", state="complete")
                                                    else:
                                                        status.update(label=f"üìö {len(references)} refer√™ncias encontradas!", state="complete")
                                                        st.info("üí° Configure uma API de IA para obter tradu√ß√µes e resenhas cr√≠ticas dos artigos")
                                                    
                                                    with st.expander("üìö Refer√™ncias Acad√™micas Encontradas", expanded=True):
                                                        st.markdown(format_references_for_display(references))
                                                else:
                                                    status.update(label="üìö Nenhuma refer√™ncia encontrada", state="complete")
                                                    st.info("‚ÑπÔ∏è Continuando an√°lise sem refer√™ncias acad√™micas externas")
                                            except Exception as e:
                                                status.update(label="‚ö†Ô∏è Erro ao buscar refer√™ncias", state="error")
                                                st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel buscar refer√™ncias: {str(e)}")
                                        else:
                                            status.update(label="‚ö†Ô∏è M√≥dulo de refer√™ncias n√£o dispon√≠vel", state="complete")
                                            st.info("‚ÑπÔ∏è Continuando an√°lise sem refer√™ncias acad√™micas externas")
                                    
                                    # Generate Grad-CAM description
                                    gradcam_desc = ""
                                    if activation_map is not None:
                                        gradcam_desc = describe_gradcam_regions(activation_map)
                                    
                                    # Collect training statistics with more details
                                    training_stats = {
                                        "√âpocas Treinadas": epochs,
                                        "Taxa de Aprendizagem": learning_rate,
                                        "Batch Size": batch_size,
                                        "Modelo": model_name,
                                        "Tipo de Augmenta√ß√£o": augmentation_type,
                                        "Otimizador": optimizer_name,
                                        "Scheduler": scheduler_name if scheduler_name != 'None' else 'N√£o utilizado'
                                    }
                                    
                                    # Collect statistical results from training history if available
                                    statistical_results = {
                                        "Tipo de An√°lise": "M√©tricas baseadas no treinamento realizado"
                                    }
                                    
                                    if 'training_history' in st.session_state:
                                        hist = st.session_state['training_history']
                                        # Calculate final and best metrics
                                        if 'valid_accuracy' in hist and len(hist['valid_accuracy']) > 0:
                                            statistical_results["Acur√°cia Final (Valida√ß√£o)"] = f"{hist['valid_accuracy'][-1]:.4f}"
                                            statistical_results["Melhor Acur√°cia (Valida√ß√£o)"] = f"{max(hist['valid_accuracy']):.4f}"
                                        if 'train_accuracy' in hist and len(hist['train_accuracy']) > 0:
                                            statistical_results["Acur√°cia Final (Treino)"] = f"{hist['train_accuracy'][-1]:.4f}"
                                        if 'valid_loss' in hist and len(hist['valid_loss']) > 0:
                                            statistical_results["Loss Final (Valida√ß√£o)"] = f"{hist['valid_loss'][-1]:.4f}"
                                            statistical_results["Melhor Loss (Valida√ß√£o)"] = f"{min(hist['valid_loss']):.4f}"
                                        if 'train_loss' in hist and len(hist['train_loss']) > 0:
                                            statistical_results["Loss Final (Treino)"] = f"{hist['train_loss'][-1]:.4f}"
                                        
                                        # Calculate convergence metrics
                                        if 'valid_accuracy' in hist and len(hist['valid_accuracy']) > 1:
                                            # Take last N epochs (up to CONVERGENCE_CHECK_EPOCHS) for convergence analysis
                                            n_epochs_to_check = min(CONVERGENCE_CHECK_EPOCHS, len(hist['valid_accuracy']))
                                            last_n_acc = hist['valid_accuracy'][-n_epochs_to_check:]
                                            acc_variance = np.var(last_n_acc) if len(last_n_acc) > 1 else 0
                                            statistical_results["Estabilidade da Converg√™ncia"] = "Alta" if acc_variance < 0.001 else "M√©dia" if acc_variance < 0.01 else "Baixa"
                                    else:
                                        statistical_results["Nota"] = "Para an√°lise completa, avalie em conjunto de teste separado"
                                    
                                    # Add confidence-specific metrics
                                    statistical_results["Confian√ßa da Predi√ß√£o Atual"] = f"{confidence:.4f} ({confidence*100:.2f}%)"
                                    statistical_results["N√≠vel de Certeza"] = "Alto" if confidence > 0.9 else "M√©dio" if confidence > 0.7 else "Baixo"
                                    
                                    # Initialize AI analyzer
                                    ai_analyzer = AIAnalyzer(
                                        api_provider=api_provider,
                                        api_key=api_key,
                                        model_name=ai_model
                                    )
                                    
                                    # Generate comprehensive analysis
                                    st.write("üß† Gerando interpreta√ß√£o diagn√≥stica...")
                                    analysis = ai_analyzer.generate_comprehensive_analysis(
                                        predicted_class=class_name,
                                        confidence=confidence,
                                        training_stats=training_stats,
                                        statistical_results=statistical_results,
                                        gradcam_description=gradcam_desc,
                                        academic_references=references
                                    )
                                    
                                    # Display analysis
                                    st.success("‚úÖ An√°lise Diagn√≥stica Completa Gerada!")
                                    st.markdown(analysis)
                                    
                                    # ========== GENETIC ALGORITHM MULTI-PERSPECTIVE ANALYSIS ==========
                                    if GENETIC_INTERP_AVAILABLE:
                                        st.write("---")
                                        st.write("### üß¨ Interpreta√ß√£o Multi-Perspectiva com Algoritmos Gen√©ticos")
                                        
                                        use_genetic = st.checkbox(
                                            "Gerar An√°lise Multi-Perspectiva (5 √¢ngulos diferentes)",
                                            value=False,
                                            help="Usa algoritmo gen√©tico para explorar diferentes perspectivas de interpreta√ß√£o"
                                        )
                                        
                                        if use_genetic:
                                            with st.spinner("üîÑ Executando algoritmo gen√©tico para m√∫ltiplas perspectivas..."):
                                                try:
                                                    genetic_interp = GeneticDiagnosticInterpreter()
                                                    
                                                    # Generate multi-perspective report with academic references
                                                    perspectives_report = genetic_interp.generate_multi_angle_report(
                                                        predicted_class=class_name,
                                                        confidence=confidence,
                                                        academic_references=references if references else None
                                                    )
                                                    
                                                    st.markdown(perspectives_report)
                                                    st.success("‚úÖ An√°lise multi-perspectiva conclu√≠da! 5 √¢ngulos de interpreta√ß√£o gerados.")
                                                    
                                                except Exception as e:
                                                    st.error(f"Erro ao gerar an√°lise gen√©tica: {str(e)}")
                                    
                                except Exception as e:
                                    st.error(f"Erro ao gerar an√°lise com IA: {str(e)}")
                                    st.info("Verifique se a API key est√° correta e se voc√™ tem cr√©ditos dispon√≠veis.")
                
                elif enable_ai_analysis and not AI_CHAT_AVAILABLE:
                    st.warning("‚ö†Ô∏è M√≥dulo de IA n√£o dispon√≠vel. Instale com: pip install google-generativeai groq")
                
                # Op√ß√£o para an√°lise com IA se API configurada (MODO LEGADO)
                if 'api_configured' in st.session_state and st.session_state['api_configured']:
                    st.write("---")
                    st.write("## ü§ñ An√°lise Diagn√≥stica com IA (Vis√£o Computacional)")
                    # Display validated model name
                    validated_model = validate_model_name(st.session_state.get('api_model'), st.session_state.get('api_provider'))
                    st.write(f"**API Configurada:** {st.session_state['api_provider']} - {validated_model}")
                    
                    # Info about multi-image analysis
                    if gradcam_image is not None:
                        st.info("""
                        üí° **An√°lise Multi-Imagem Ativada**
                        
                        A IA receber√° e analisar√° **DUAS imagens**:
                        1. üñºÔ∏è **Imagem Original** - A imagem classificada
                        2. üî• **Grad-CAM Overlay** - Mapa de calor mostrando onde o modelo focou
                        
                        Isso permite uma an√°lise mais profunda correlacionando as caracter√≠sticas visuais 
                        com as regi√µes de aten√ß√£o da rede neural.
                        """)
                    
                    if st.button("üî¨ Gerar An√°lise Completa com IA + Vis√£o"):
                        with st.spinner("üîç Analisando imagem com IA (vis√£o computacional)..."):
                            # Gerar descri√ß√£o do Grad-CAM
                            gradcam_desc = generate_gradcam_description(activation_map) if activation_map is not None else ""
                            
                            # Validate and sanitize model name
                            api_provider = st.session_state['api_provider']
                            api_model = validate_model_name(st.session_state['api_model'], api_provider)
                            api_key = st.session_state['api_key']
                            
                            # Executar an√°lise com IA apropriada
                            if api_provider == 'Gemini':
                                if not GEMINI_AVAILABLE:
                                    st.error("‚ùå Google Generative AI n√£o est√° instalado. Execute: pip install google-generativeai")
                                    ai_analysis_text = "Erro: Biblioteca n√£o dispon√≠vel"
                                else:
                                    ai_analysis_text = analyze_image_with_gemini(
                                        eval_image,
                                        api_key,
                                        api_model,
                                        class_name,
                                        confidence,
                                        gradcam_desc,
                                        gradcam_image  # Pass the Grad-CAM overlay image
                                    )
                            else:  # Groq
                                if not GROQ_AVAILABLE:
                                    st.error("‚ùå Groq n√£o est√° instalado. Execute: pip install groq")
                                    ai_analysis_text = "Erro: Biblioteca n√£o dispon√≠vel"
                                else:
                                    ai_analysis_text = analyze_image_with_groq_vision(
                                        eval_image,
                                        api_key,
                                        api_model,
                                        class_name,
                                        confidence,
                                        gradcam_desc
                                    )
                            
                            # Exibir an√°lise
                            st.success("‚úÖ An√°lise Completa Gerada!")
                            st.write("### üìã Relat√≥rio de An√°lise com IA")
                            st.markdown(ai_analysis_text)
                            
                            # ========== MULTI-AGENT SYSTEM ANALYSIS (15 AGENTS + MANAGER) ==========
                            if MULTI_AGENT_AVAILABLE:
                                st.write("---")
                                st.write("## ü§ñ Sistema Multi-Agente (15 Agentes + 1 Gerente)")
                                
                                use_multiagent = st.checkbox("Ativar An√°lise com Sistema Multi-Agente (15 Especialistas)", value=True)
                                
                                if use_multiagent:
                                    # Op√ß√£o para usar CrewAI com o sistema multi-agente
                                    use_crewai_multiagent = False
                                    if CREWAI_AVAILABLE:
                                        use_crewai_multiagent = st.checkbox(
                                            "üöÄ Ativar An√°lise Avan√ßada com CrewAI",
                                            value=False,
                                            help="Adiciona an√°lise avan√ßada usando CrewAI para insights ainda mais profundos. EXPERIMENTAL."
                                        )
                                    
                                    spinner_text = "Coordenando an√°lise de 15 agentes especializados + 1 gerente"
                                    if use_crewai_multiagent:
                                        spinner_text += " + an√°lise avan√ßada CrewAI"
                                    spinner_text += "..."
                                    
                                    with st.spinner(spinner_text):
                                        try:
                                            manager = ManagerAgent(use_crewai=use_crewai_multiagent)
                                            
                                            # Preparar contexto
                                            agent_context = {
                                                'gradcam_description': gradcam_desc,
                                                'ai_analysis': ai_analysis_text
                                            }
                                            
                                            multi_agent_report = manager.coordinate_analysis(
                                                predicted_class=class_name,
                                                confidence=confidence,
                                                context=agent_context
                                            )
                                            
                                            st.markdown(multi_agent_report)
                                            success_msg = "‚úÖ An√°lise Multi-Agente Conclu√≠da! 15 especialistas + 1 gerente coordenador"
                                            if use_crewai_multiagent:
                                                success_msg += " + an√°lise avan√ßada CrewAI"
                                            st.success(success_msg)
                                            
                                        except Exception as e:
                                            st.error(f"Erro ao gerar an√°lise multi-agente: {str(e)}")
                            
                            # Preparar dados para exporta√ß√£o
                            ai_analysis_result = {
                                'imagem': eval_image_file.name,
                                'classe_predita': class_name,
                                'confianca': confidence,
                                'api_provider': api_provider,
                                'api_model': api_model,
                                'gradcam_description': gradcam_desc,
                                'analise_completa': ai_analysis_text,
                                'modelo_classificacao': model_name,
                                'epocas': epochs,
                                'batch_size': batch_size,
                                'learning_rate': learning_rate
                            }
                            
                            # Exportar an√°lise IA para CSV
                            df_ai_analysis = pd.DataFrame([ai_analysis_result])
                            csv_ai = export_to_csv(df_ai_analysis, "analise_ia_visao.csv")
                            
                            st.write("---")
                            st.download_button(
                                label="üì• Baixar CSV - An√°lise Completa com IA",
                                data=csv_ai,
                                file_name=f"analise_ia_visao_{eval_image_file.name.split('.')[0]}.csv",
                                mime="text/csv",
                                help="Download da an√°lise completa com IA incluindo vis√£o computacional"
                            )
                else:
                    st.info("""
                    üí° **An√°lise com IA Dispon√≠vel**
                    
                    Configure uma API (Gemini ou Groq) na barra lateral para ativar a an√°lise 
                    diagn√≥stica com IA que inclui:
                    - ‚úÖ Vis√£o Computacional (a IA pode "ver" e analisar a imagem)
                    - ‚úÖ Interpreta√ß√£o t√©cnica detalhada
                    - ‚úÖ An√°lise forense da imagem
                    - ‚úÖ Recomenda√ß√µes baseadas em an√°lise visual
                    - ‚úÖ Exporta√ß√£o completa para CSV
                    
                    **Modelos com Suporte de Vis√£o:**
                    - Gemini: gemini-2.5-flash ‚≠ê, gemini-2.5-pro, gemini-3-flash-preview
                    - Groq: Suporte limitado dependendo do modelo
                    
                    üìö Baseado no cookbook oficial: https://github.com/google-gemini/cookbook
                    """)

        # Limpar o diret√≥rio tempor√°rio
        shutil.rmtree(temp_dir)

if __name__ == "__main__":
    main()
